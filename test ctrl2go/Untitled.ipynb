{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2f8377de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:38:07.996029Z",
     "start_time": "2021-06-15T19:38:07.993028Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "179cab01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:07:19.316105Z",
     "start_time": "2021-06-15T17:07:19.252110Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.load('C:/Users/Arcry/SkillBox/Test_ctrl2go/X_train.npy')\n",
    "y_train = np.load('C:/Users/Arcry/SkillBox/Test_ctrl2go/y_train.npy')\n",
    "\n",
    "X_test = np.load('C:/Users/Arcry/SkillBox/Test_ctrl2go/X_test.npy')\n",
    "y_test = np.load('C:/Users/Arcry/SkillBox/Test_ctrl2go/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6c831d4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T16:55:25.576024Z",
     "start_time": "2021-06-15T16:55:25.570038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 6)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cae9bc7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T16:26:47.799008Z",
     "start_time": "2021-06-15T16:26:47.786009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bceb6aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T16:19:31.135406Z",
     "start_time": "2021-06-15T16:19:31.071408Z"
    }
   },
   "outputs": [],
   "source": [
    "m,n,r = X_train.shape\n",
    "out_arr = np.column_stack((np.repeat(np.arange(m),n),X_train.reshape(m*n,-1)))\n",
    "out_df = pd.DataFrame(out_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "378ab4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:53:24.530974Z",
     "start_time": "2021-06-15T17:53:24.509959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.012817</td>\n",
       "      <td>-0.123217</td>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.022859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.022833</td>\n",
       "      <td>-0.126876</td>\n",
       "      <td>0.105687</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.010316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.022028</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.013250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017877</td>\n",
       "      <td>-0.124928</td>\n",
       "      <td>0.106553</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.017751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.023680</td>\n",
       "      <td>-0.125767</td>\n",
       "      <td>0.102814</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.002553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019290</td>\n",
       "      <td>-0.126185</td>\n",
       "      <td>0.098350</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>-0.001298</td>\n",
       "      <td>0.002669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.018445</td>\n",
       "      <td>-0.124070</td>\n",
       "      <td>0.100385</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.039852</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019372</td>\n",
       "      <td>-0.122745</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.005643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021171</td>\n",
       "      <td>-0.121326</td>\n",
       "      <td>0.094987</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>-0.002270</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.018851</td>\n",
       "      <td>-0.123976</td>\n",
       "      <td>0.097930</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>-0.004688</td>\n",
       "      <td>-0.026860</td>\n",
       "      <td>0.017111</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.012268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6  \\\n",
       "0    0.0  1.012817 -0.123217  0.102934  0.000181  0.010767  0.055561   \n",
       "1    0.0  1.022833 -0.126876  0.105687  0.010139  0.006579  0.055125   \n",
       "2    0.0  1.022028 -0.124004  0.102102  0.009276  0.008929  0.048405   \n",
       "3    0.0  1.017877 -0.124928  0.106553  0.005066  0.007489  0.049775   \n",
       "4    0.0  1.023680 -0.125767  0.102814  0.010810  0.006141  0.043013   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "124  0.0  1.019290 -0.126185  0.098350 -0.000300 -0.002023  0.000359   \n",
       "125  0.0  1.018445 -0.124070  0.100385 -0.001147  0.000171  0.002648   \n",
       "126  0.0  1.019372 -0.122745  0.099874 -0.000222  0.001574  0.002381   \n",
       "127  0.0  1.021171 -0.121326  0.094987  0.001576  0.003070 -0.002270   \n",
       "128  1.0  1.018851 -0.123976  0.097930  0.001094 -0.004688 -0.026860   \n",
       "\n",
       "            7         8         9  \n",
       "0    0.030191  0.066014  0.022859  \n",
       "1    0.043711  0.042699  0.010316  \n",
       "2    0.035688  0.074850  0.013250  \n",
       "3    0.040402  0.057320  0.017751  \n",
       "4    0.047097  0.052343  0.002553  \n",
       "..        ...       ...       ...  \n",
       "124  0.032328 -0.001298  0.002669  \n",
       "125  0.039852  0.001909 -0.002170  \n",
       "126  0.037449 -0.000080 -0.005643  \n",
       "127  0.028818 -0.000038 -0.001446  \n",
       "128  0.017111  0.006123  0.012268  \n",
       "\n",
       "[129 rows x 10 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head(129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b87bf7c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:08:44.898526Z",
     "start_time": "2021-06-15T17:08:44.866527Z"
    }
   },
   "outputs": [],
   "source": [
    "m,n,r = X_test.shape\n",
    "out_arr_test = np.column_stack((np.repeat(np.arange(m),n),X_test.reshape(m*n,-1)))\n",
    "out_df_test = pd.DataFrame(out_arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec90181e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T16:34:38.090487Z",
     "start_time": "2021-06-15T16:34:38.082487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.012817, 1.022833, 1.022028, 1.017877, 1.02368 , 1.016974,\n",
       "       1.017746, 1.019263, 1.016417, 1.020745, 1.018643, 1.019521,\n",
       "       1.02026 , 1.018041, 1.020829, 1.018644, 1.019398, 1.020399,\n",
       "       1.019222, 1.022093, 1.020433, 1.020534, 1.021503, 1.019931,\n",
       "       1.02048 , 1.018945, 1.019238, 1.019989, 1.018917, 1.019762,\n",
       "       1.019021, 1.017887, 1.018136, 1.019543, 1.020242, 1.018757,\n",
       "       1.019534, 1.019862, 1.01906 , 1.020717, 1.021055, 1.020178,\n",
       "       1.018108, 1.014776, 1.015374, 1.018429, 1.019895, 1.018647,\n",
       "       1.016387, 1.017053, 1.019572, 1.021097, 1.019488, 1.017218,\n",
       "       1.019876, 1.022022, 1.020574, 1.021588, 1.022298, 1.019369,\n",
       "       1.01698 , 1.016774, 1.016079, 1.015292, 1.018851, 1.02238 ,\n",
       "       1.020781, 1.020218, 1.021344, 1.020522, 1.01979 , 1.019216,\n",
       "       1.018307, 1.017996, 1.017932, 1.018121, 1.018305, 1.018458,\n",
       "       1.018201, 1.017129, 1.017814, 1.0188  , 1.017601, 1.01797 ,\n",
       "       1.018489, 1.017787, 1.019167, 1.019789, 1.019462, 1.020433,\n",
       "       1.021189, 1.021903, 1.021936, 1.02055 , 1.018878, 1.018548,\n",
       "       1.017389, 1.015021, 1.01931 , 1.024606, 1.021863, 1.020201,\n",
       "       1.020573, 1.018729, 1.01936 , 1.019954, 1.018969, 1.019633,\n",
       "       1.019553, 1.019179, 1.019695, 1.019145, 1.018516, 1.017926,\n",
       "       1.01778 , 1.018917, 1.020606, 1.022583, 1.020981, 1.018065,\n",
       "       1.019638, 1.020017, 1.018766, 1.019815, 1.01929 , 1.018445,\n",
       "       1.019372, 1.021171])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "64c2368f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:36:14.310729Z",
     "start_time": "2021-06-15T19:35:45.789208Z"
    }
   },
   "outputs": [],
   "source": [
    "funcs = ['std','median','min', 'max',\n",
    "        'skew', pd.DataFrame.kurt]\n",
    "\n",
    "df = out_df.groupby(0).agg({1:funcs}).join(out_df.groupby(0).agg({2:funcs}))\n",
    "for i in range(3, 10):\n",
    "    df = df.join(out_df.groupby(0).agg({i:funcs}))\n",
    "    \n",
    "df_test = out_df_test.groupby(0).agg({1:funcs}).join(out_df_test.groupby(0).agg({2:funcs}))\n",
    "for i in range(3, 10):\n",
    "    df_test = df_test.join(out_df_test.groupby(0).agg({i:funcs}))\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(df)\n",
    "X_test_sc = scaler.transform(df_test)\n",
    "\n",
    "y_train_ = y_train.argmax(axis=1)\n",
    "y_test_ = y_test.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "57e9ae1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:38:33.404562Z",
     "start_time": "2021-06-15T19:38:33.400531Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "2eaecf6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:46:18.273431Z",
     "start_time": "2021-06-15T19:45:23.938436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START C=4.........................................................\n",
      "[CV 1/5; 1/4] END .......................................C=4; total time=   1.9s\n",
      "[CV 2/5; 1/4] START C=4.........................................................\n",
      "[CV 2/5; 1/4] END .......................................C=4; total time=   1.9s\n",
      "[CV 3/5; 1/4] START C=4.........................................................\n",
      "[CV 3/5; 1/4] END .......................................C=4; total time=   2.0s\n",
      "[CV 4/5; 1/4] START C=4.........................................................\n",
      "[CV 4/5; 1/4] END .......................................C=4; total time=   2.2s\n",
      "[CV 5/5; 1/4] START C=4.........................................................\n",
      "[CV 5/5; 1/4] END .......................................C=4; total time=   2.0s\n",
      "[CV 1/5; 2/4] START C=6.........................................................\n",
      "[CV 1/5; 2/4] END .......................................C=6; total time=   2.3s\n",
      "[CV 2/5; 2/4] START C=6.........................................................\n",
      "[CV 2/5; 2/4] END .......................................C=6; total time=   2.3s\n",
      "[CV 3/5; 2/4] START C=6.........................................................\n",
      "[CV 3/5; 2/4] END .......................................C=6; total time=   2.0s\n",
      "[CV 4/5; 2/4] START C=6.........................................................\n",
      "[CV 4/5; 2/4] END .......................................C=6; total time=   2.5s\n",
      "[CV 5/5; 2/4] START C=6.........................................................\n",
      "[CV 5/5; 2/4] END .......................................C=6; total time=   2.3s\n",
      "[CV 1/5; 3/4] START C=8.........................................................\n",
      "[CV 1/5; 3/4] END .......................................C=8; total time=   2.6s\n",
      "[CV 2/5; 3/4] START C=8.........................................................\n",
      "[CV 2/5; 3/4] END .......................................C=8; total time=   2.6s\n",
      "[CV 3/5; 3/4] START C=8.........................................................\n",
      "[CV 3/5; 3/4] END .......................................C=8; total time=   2.1s\n",
      "[CV 4/5; 3/4] START C=8.........................................................\n",
      "[CV 4/5; 3/4] END .......................................C=8; total time=   3.4s\n",
      "[CV 5/5; 3/4] START C=8.........................................................\n",
      "[CV 5/5; 3/4] END .......................................C=8; total time=   2.4s\n",
      "[CV 1/5; 4/4] START C=10........................................................\n",
      "[CV 1/5; 4/4] END ......................................C=10; total time=   2.7s\n",
      "[CV 2/5; 4/4] START C=10........................................................\n",
      "[CV 2/5; 4/4] END ......................................C=10; total time=   2.6s\n",
      "[CV 3/5; 4/4] START C=10........................................................\n",
      "[CV 3/5; 4/4] END ......................................C=10; total time=   2.7s\n",
      "[CV 4/5; 4/4] START C=10........................................................\n",
      "[CV 4/5; 4/4] END ......................................C=10; total time=   3.0s\n",
      "[CV 5/5; 4/4] START C=10........................................................\n",
      "[CV 5/5; 4/4] END ......................................C=10; total time=   2.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9197828299966068"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# reg = LogisticRegression(max_iter=1000, random_state=42, C=2, multi_class='multinomial')\n",
    "reg = LogisticRegression(max_iter=1500, random_state=42, multi_class='multinomial')\n",
    "params = {'C': [4, 6, 8, 10, 12]}\n",
    "reg_CV = GridSearchCV(reg, params, cv=kf, verbose=10)\n",
    "reg_CV.fit(X_train_sc, y_train_)\n",
    "pred = reg_CV.predict(X_test_sc)\n",
    "multiclass_roc_auc_score(y_test_, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8d39852d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:46:20.773504Z",
     "start_time": "2021-06-15T19:46:20.761508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "36acadbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:18:58.429776Z",
     "start_time": "2021-06-15T17:18:58.418777Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "455d0600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:20:08.442122Z",
     "start_time": "2021-06-15T17:20:08.436089Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "034f98ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:26:09.581105Z",
     "start_time": "2021-06-15T17:26:09.566108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896776382762131"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f49d6536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:09:56.065099Z",
     "start_time": "2021-06-15T17:09:55.666388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "84e60e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T17:11:40.158204Z",
     "start_time": "2021-06-15T17:11:40.154205Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9a2231bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:53:20.425912Z",
     "start_time": "2021-06-15T19:52:29.874937Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START C=8.........................................................\n",
      "[CV 1/5; 1/3] END .......................................C=8; total time=   2.6s\n",
      "[CV 2/5; 1/3] START C=8.........................................................\n",
      "[CV 2/5; 1/3] END .......................................C=8; total time=   2.8s\n",
      "[CV 3/5; 1/3] START C=8.........................................................\n",
      "[CV 3/5; 1/3] END .......................................C=8; total time=   2.5s\n",
      "[CV 4/5; 1/3] START C=8.........................................................\n",
      "[CV 4/5; 1/3] END .......................................C=8; total time=   3.4s\n",
      "[CV 5/5; 1/3] START C=8.........................................................\n",
      "[CV 5/5; 1/3] END .......................................C=8; total time=   2.7s\n",
      "[CV 1/5; 2/3] START C=10........................................................\n",
      "[CV 1/5; 2/3] END ......................................C=10; total time=   2.9s\n",
      "[CV 2/5; 2/3] START C=10........................................................\n",
      "[CV 2/5; 2/3] END ......................................C=10; total time=   2.6s\n",
      "[CV 3/5; 2/3] START C=10........................................................\n",
      "[CV 3/5; 2/3] END ......................................C=10; total time=   3.4s\n",
      "[CV 4/5; 2/3] START C=10........................................................\n",
      "[CV 4/5; 2/3] END ......................................C=10; total time=   3.7s\n",
      "[CV 5/5; 2/3] START C=10........................................................\n",
      "[CV 5/5; 2/3] END ......................................C=10; total time=   3.4s\n",
      "[CV 1/5; 3/3] START C=12........................................................\n",
      "[CV 1/5; 3/3] END ......................................C=12; total time=   3.0s\n",
      "[CV 2/5; 3/3] START C=12........................................................\n",
      "[CV 2/5; 3/3] END ......................................C=12; total time=   2.9s\n",
      "[CV 3/5; 3/3] START C=12........................................................\n",
      "[CV 3/5; 3/3] END ......................................C=12; total time=   2.8s\n",
      "[CV 4/5; 3/3] START C=12........................................................\n",
      "[CV 4/5; 3/3] END ......................................C=12; total time=   3.6s\n",
      "[CV 5/5; 3/3] START C=12........................................................\n",
      "[CV 5/5; 3/3] END ......................................C=12; total time=   3.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9218187987784189"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = OneVsRestClassifier(LinearSVC(max_iter=10000, random_state=42))\n",
    "params = {'C': [8, 10, 12]}\n",
    "svc_CV = GridSearchCV(reg, params, cv=kf, verbose=10).fit(X_train_sc, y_train_)\n",
    "pred_svc = clf.predict(X_test_sc)\n",
    "multiclass_roc_auc_score(y_test_, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "13ae7115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:53:21.337599Z",
     "start_time": "2021-06-15T19:53:21.321601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "e31e3842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:57:41.809292Z",
     "start_time": "2021-06-15T19:55:47.785681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5; 1/20] START max_depth=2, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 1/20] END .............max_depth=2, n_estimators=10; total time=   0.1s\n",
      "[CV 2/5; 1/20] START max_depth=2, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 1/20] END .............max_depth=2, n_estimators=10; total time=   0.1s\n",
      "[CV 3/5; 1/20] START max_depth=2, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 1/20] END .............max_depth=2, n_estimators=10; total time=   0.1s\n",
      "[CV 4/5; 1/20] START max_depth=2, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 1/20] END .............max_depth=2, n_estimators=10; total time=   0.1s\n",
      "[CV 5/5; 1/20] START max_depth=2, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 1/20] END .............max_depth=2, n_estimators=10; total time=   0.1s\n",
      "[CV 1/5; 2/20] START max_depth=2, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/20] END .............max_depth=2, n_estimators=20; total time=   0.3s\n",
      "[CV 2/5; 2/20] START max_depth=2, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 2/20] END .............max_depth=2, n_estimators=20; total time=   0.3s\n",
      "[CV 3/5; 2/20] START max_depth=2, n_estimators=20...............................\n",
      "building tree 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 2/20] END .............max_depth=2, n_estimators=20; total time=   0.3s\n",
      "[CV 4/5; 2/20] START max_depth=2, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 2/20] END .............max_depth=2, n_estimators=20; total time=   0.3s\n",
      "[CV 5/5; 2/20] START max_depth=2, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 2/20] END .............max_depth=2, n_estimators=20; total time=   0.3s\n",
      "[CV 1/5; 3/20] START max_depth=2, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 3/20] END .............max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV 2/5; 3/20] START max_depth=2, n_estimators=50...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 3/20] END .............max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV 3/5; 3/20] START max_depth=2, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 3/20] END .............max_depth=2, n_estimators=50; total time=   0.9s\n",
      "[CV 4/5; 3/20] START max_depth=2, n_estimators=50...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 3/20] END .............max_depth=2, n_estimators=50; total time=   0.9s\n",
      "[CV 5/5; 3/20] START max_depth=2, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 3/20] END .............max_depth=2, n_estimators=50; total time=   0.8s\n",
      "[CV 1/5; 4/20] START max_depth=2, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/20] END .............max_depth=2, n_estimators=75; total time=   1.3s\n",
      "[CV 2/5; 4/20] START max_depth=2, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/20] END .............max_depth=2, n_estimators=75; total time=   1.3s\n",
      "[CV 3/5; 4/20] START max_depth=2, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 4/20] END .............max_depth=2, n_estimators=75; total time=   1.3s\n",
      "[CV 4/5; 4/20] START max_depth=2, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 4/20] END .............max_depth=2, n_estimators=75; total time=   1.3s\n",
      "[CV 5/5; 4/20] START max_depth=2, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 4/20] END .............max_depth=2, n_estimators=75; total time=   1.3s\n",
      "[CV 1/5; 5/20] START max_depth=3, n_estimators=10...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 5/20] END .............max_depth=3, n_estimators=10; total time=   0.2s\n",
      "[CV 2/5; 5/20] START max_depth=3, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 5/20] END .............max_depth=3, n_estimators=10; total time=   0.2s\n",
      "[CV 3/5; 5/20] START max_depth=3, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 5/20] END .............max_depth=3, n_estimators=10; total time=   0.2s\n",
      "[CV 4/5; 5/20] START max_depth=3, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 5/20] END .............max_depth=3, n_estimators=10; total time=   0.1s\n",
      "[CV 5/5; 5/20] START max_depth=3, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 5/20] END .............max_depth=3, n_estimators=10; total time=   0.2s\n",
      "[CV 1/5; 6/20] START max_depth=3, n_estimators=20...............................\n",
      "building tree 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 6/20] END .............max_depth=3, n_estimators=20; total time=   0.4s\n",
      "[CV 2/5; 6/20] START max_depth=3, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 6/20] END .............max_depth=3, n_estimators=20; total time=   0.4s\n",
      "[CV 3/5; 6/20] START max_depth=3, n_estimators=20...............................\n",
      "building tree 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 6/20] END .............max_depth=3, n_estimators=20; total time=   0.4s\n",
      "[CV 4/5; 6/20] START max_depth=3, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 6/20] END .............max_depth=3, n_estimators=20; total time=   0.4s\n",
      "[CV 5/5; 6/20] START max_depth=3, n_estimators=20...............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 6/20] END .............max_depth=3, n_estimators=20; total time=   0.4s\n",
      "[CV 1/5; 7/20] START max_depth=3, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/20] END .............max_depth=3, n_estimators=50; total time=   1.1s\n",
      "[CV 2/5; 7/20] START max_depth=3, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 7/20] END .............max_depth=3, n_estimators=50; total time=   1.1s\n",
      "[CV 3/5; 7/20] START max_depth=3, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 7/20] END .............max_depth=3, n_estimators=50; total time=   1.2s\n",
      "[CV 4/5; 7/20] START max_depth=3, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 7/20] END .............max_depth=3, n_estimators=50; total time=   1.1s\n",
      "[CV 5/5; 7/20] START max_depth=3, n_estimators=50...............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 7/20] END .............max_depth=3, n_estimators=50; total time=   1.1s\n",
      "[CV 1/5; 8/20] START max_depth=3, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 8/20] END .............max_depth=3, n_estimators=75; total time=   1.6s\n",
      "[CV 2/5; 8/20] START max_depth=3, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 8/20] END .............max_depth=3, n_estimators=75; total time=   1.7s\n",
      "[CV 3/5; 8/20] START max_depth=3, n_estimators=75...............................\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 8/20] END .............max_depth=3, n_estimators=75; total time=   1.7s\n",
      "[CV 4/5; 8/20] START max_depth=3, n_estimators=75...............................\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 8/20] END .............max_depth=3, n_estimators=75; total time=   1.7s\n",
      "[CV 5/5; 8/20] START max_depth=3, n_estimators=75...............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 8/20] END .............max_depth=3, n_estimators=75; total time=   1.7s\n",
      "[CV 1/5; 9/20] START max_depth=4, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/20] END .............max_depth=4, n_estimators=10; total time=   0.2s\n",
      "[CV 2/5; 9/20] START max_depth=4, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 9/20] END .............max_depth=4, n_estimators=10; total time=   0.2s\n",
      "[CV 3/5; 9/20] START max_depth=4, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 9/20] END .............max_depth=4, n_estimators=10; total time=   0.2s\n",
      "[CV 4/5; 9/20] START max_depth=4, n_estimators=10...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 9/20] END .............max_depth=4, n_estimators=10; total time=   0.2s\n",
      "[CV 5/5; 9/20] START max_depth=4, n_estimators=10...............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 9/20] END .............max_depth=4, n_estimators=10; total time=   0.2s\n",
      "[CV 1/5; 10/20] START max_depth=4, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 10/20] END ............max_depth=4, n_estimators=20; total time=   0.5s\n",
      "[CV 2/5; 10/20] START max_depth=4, n_estimators=20..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 10/20] END ............max_depth=4, n_estimators=20; total time=   0.5s\n",
      "[CV 3/5; 10/20] START max_depth=4, n_estimators=20..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 10/20] END ............max_depth=4, n_estimators=20; total time=   0.5s\n",
      "[CV 4/5; 10/20] START max_depth=4, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 10/20] END ............max_depth=4, n_estimators=20; total time=   0.5s\n",
      "[CV 5/5; 10/20] START max_depth=4, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 10/20] END ............max_depth=4, n_estimators=20; total time=   0.5s\n",
      "[CV 1/5; 11/20] START max_depth=4, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 11/20] END ............max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV 2/5; 11/20] START max_depth=4, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 11/20] END ............max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV 3/5; 11/20] START max_depth=4, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 11/20] END ............max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV 4/5; 11/20] START max_depth=4, n_estimators=50..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 11/20] END ............max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV 5/5; 11/20] START max_depth=4, n_estimators=50..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 11/20] END ............max_depth=4, n_estimators=50; total time=   1.4s\n",
      "[CV 1/5; 12/20] START max_depth=4, n_estimators=75..............................\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/20] END ............max_depth=4, n_estimators=75; total time=   2.1s\n",
      "[CV 2/5; 12/20] START max_depth=4, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 12/20] END ............max_depth=4, n_estimators=75; total time=   2.1s\n",
      "[CV 3/5; 12/20] START max_depth=4, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 12/20] END ............max_depth=4, n_estimators=75; total time=   2.0s\n",
      "[CV 4/5; 12/20] START max_depth=4, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 12/20] END ............max_depth=4, n_estimators=75; total time=   2.0s\n",
      "[CV 5/5; 12/20] START max_depth=4, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/20] END ............max_depth=4, n_estimators=75; total time=   2.0s\n",
      "[CV 1/5; 13/20] START max_depth=5, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 13/20] END ............max_depth=5, n_estimators=10; total time=   0.2s\n",
      "[CV 2/5; 13/20] START max_depth=5, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 13/20] END ............max_depth=5, n_estimators=10; total time=   0.2s\n",
      "[CV 3/5; 13/20] START max_depth=5, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 13/20] END ............max_depth=5, n_estimators=10; total time=   0.2s\n",
      "[CV 4/5; 13/20] START max_depth=5, n_estimators=10..............................\n",
      "building tree 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 13/20] END ............max_depth=5, n_estimators=10; total time=   0.2s\n",
      "[CV 5/5; 13/20] START max_depth=5, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 13/20] END ............max_depth=5, n_estimators=10; total time=   0.2s\n",
      "[CV 1/5; 14/20] START max_depth=5, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 14/20] END ............max_depth=5, n_estimators=20; total time=   0.6s\n",
      "[CV 2/5; 14/20] START max_depth=5, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 14/20] END ............max_depth=5, n_estimators=20; total time=   0.6s\n",
      "[CV 3/5; 14/20] START max_depth=5, n_estimators=20..............................\n",
      "building tree 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 14/20] END ............max_depth=5, n_estimators=20; total time=   0.6s\n",
      "[CV 4/5; 14/20] START max_depth=5, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 14/20] END ............max_depth=5, n_estimators=20; total time=   0.6s\n",
      "[CV 5/5; 14/20] START max_depth=5, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 14/20] END ............max_depth=5, n_estimators=20; total time=   0.6s\n",
      "[CV 1/5; 15/20] START max_depth=5, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 15/20] END ............max_depth=5, n_estimators=50; total time=   1.6s\n",
      "[CV 2/5; 15/20] START max_depth=5, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 15/20] END ............max_depth=5, n_estimators=50; total time=   1.6s\n",
      "[CV 3/5; 15/20] START max_depth=5, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 15/20] END ............max_depth=5, n_estimators=50; total time=   1.5s\n",
      "[CV 4/5; 15/20] START max_depth=5, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 15/20] END ............max_depth=5, n_estimators=50; total time=   1.6s\n",
      "[CV 5/5; 15/20] START max_depth=5, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 15/20] END ............max_depth=5, n_estimators=50; total time=   1.6s\n",
      "[CV 1/5; 16/20] START max_depth=5, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 16/20] END ............max_depth=5, n_estimators=75; total time=   2.4s\n",
      "[CV 2/5; 16/20] START max_depth=5, n_estimators=75..............................\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 16/20] END ............max_depth=5, n_estimators=75; total time=   2.4s\n",
      "[CV 3/5; 16/20] START max_depth=5, n_estimators=75..............................\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 16/20] END ............max_depth=5, n_estimators=75; total time=   2.4s\n",
      "[CV 4/5; 16/20] START max_depth=5, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 16/20] END ............max_depth=5, n_estimators=75; total time=   2.3s\n",
      "[CV 5/5; 16/20] START max_depth=5, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 16/20] END ............max_depth=5, n_estimators=75; total time=   2.4s\n",
      "[CV 1/5; 17/20] START max_depth=6, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 17/20] END ............max_depth=6, n_estimators=10; total time=   0.3s\n",
      "[CV 2/5; 17/20] START max_depth=6, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 17/20] END ............max_depth=6, n_estimators=10; total time=   0.3s\n",
      "[CV 3/5; 17/20] START max_depth=6, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 17/20] END ............max_depth=6, n_estimators=10; total time=   0.3s\n",
      "[CV 4/5; 17/20] START max_depth=6, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/20] END ............max_depth=6, n_estimators=10; total time=   0.3s\n",
      "[CV 5/5; 17/20] START max_depth=6, n_estimators=10..............................\n",
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 17/20] END ............max_depth=6, n_estimators=10; total time=   0.3s\n",
      "[CV 1/5; 18/20] START max_depth=6, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 18/20] END ............max_depth=6, n_estimators=20; total time=   0.7s\n",
      "[CV 2/5; 18/20] START max_depth=6, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 18/20] END ............max_depth=6, n_estimators=20; total time=   0.7s\n",
      "[CV 3/5; 18/20] START max_depth=6, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 18/20] END ............max_depth=6, n_estimators=20; total time=   0.6s\n",
      "[CV 4/5; 18/20] START max_depth=6, n_estimators=20..............................\n",
      "building tree 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 18/20] END ............max_depth=6, n_estimators=20; total time=   0.6s\n",
      "[CV 5/5; 18/20] START max_depth=6, n_estimators=20..............................\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 18/20] END ............max_depth=6, n_estimators=20; total time=   0.7s\n",
      "[CV 1/5; 19/20] START max_depth=6, n_estimators=50..............................\n",
      "building tree 1 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 19/20] END ............max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV 2/5; 19/20] START max_depth=6, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 19/20] END ............max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV 3/5; 19/20] START max_depth=6, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 19/20] END ............max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV 4/5; 19/20] START max_depth=6, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 19/20] END ............max_depth=6, n_estimators=50; total time=   1.7s\n",
      "[CV 5/5; 19/20] START max_depth=6, n_estimators=50..............................\n",
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n",
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 19/20] END ............max_depth=6, n_estimators=50; total time=   1.8s\n",
      "[CV 1/5; 20/20] START max_depth=6, n_estimators=75..............................\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 1/5; 20/20] END ............max_depth=6, n_estimators=75; total time=   2.6s\n",
      "[CV 2/5; 20/20] START max_depth=6, n_estimators=75..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 2/5; 20/20] END ............max_depth=6, n_estimators=75; total time=   2.7s\n",
      "[CV 3/5; 20/20] START max_depth=6, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 3/5; 20/20] END ............max_depth=6, n_estimators=75; total time=   2.7s\n",
      "[CV 4/5; 20/20] START max_depth=6, n_estimators=75..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 4/5; 20/20] END ............max_depth=6, n_estimators=75; total time=   2.6s\n",
      "[CV 5/5; 20/20] START max_depth=6, n_estimators=75..............................\n",
      "building tree 1 of 75\n",
      "building tree 2 of 75\n",
      "building tree 3 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n",
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 11 of 75\n",
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n",
      "Using ThreadingBackend as joblib.Parallel backend instead of LokyBackend as the latter does not provide shared memory semantics.\n",
      "[CV 5/5; 20/20] END ............max_depth=6, n_estimators=75; total time=   2.6s\n",
      "building tree 1 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 75\n",
      "building tree 3 of 75\n",
      "building tree 4 of 75\n",
      "building tree 5 of 75\n",
      "building tree 6 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 7 of 75\n",
      "building tree 8 of 75\n",
      "building tree 9 of 75\n",
      "building tree 10 of 75\n",
      "building tree 11 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 12 of 75\n",
      "building tree 13 of 75\n",
      "building tree 14 of 75\n",
      "building tree 15 of 75\n",
      "building tree 16 of 75\n",
      "building tree 17 of 75\n",
      "building tree 18 of 75\n",
      "building tree 19 of 75\n",
      "building tree 20 of 75\n",
      "building tree 21 of 75\n",
      "building tree 22 of 75\n",
      "building tree 23 of 75\n",
      "building tree 24 of 75\n",
      "building tree 25 of 75\n",
      "building tree 26 of 75\n",
      "building tree 27 of 75\n",
      "building tree 28 of 75\n",
      "building tree 29 of 75\n",
      "building tree 30 of 75\n",
      "building tree 31 of 75\n",
      "building tree 32 of 75\n",
      "building tree 33 of 75\n",
      "building tree 34 of 75\n",
      "building tree 35 of 75\n",
      "building tree 36 of 75\n",
      "building tree 37 of 75\n",
      "building tree 38 of 75\n",
      "building tree 39 of 75\n",
      "building tree 40 of 75\n",
      "building tree 41 of 75\n",
      "building tree 42 of 75\n",
      "building tree 43 of 75\n",
      "building tree 44 of 75\n",
      "building tree 45 of 75\n",
      "building tree 46 of 75\n",
      "building tree 47 of 75\n",
      "building tree 48 of 75\n",
      "building tree 49 of 75\n",
      "building tree 50 of 75\n",
      "building tree 51 of 75\n",
      "building tree 52 of 75\n",
      "building tree 53 of 75\n",
      "building tree 54 of 75\n",
      "building tree 55 of 75\n",
      "building tree 56 of 75\n",
      "building tree 57 of 75\n",
      "building tree 58 of 75\n",
      "building tree 59 of 75\n",
      "building tree 60 of 75\n",
      "building tree 61 of 75\n",
      "building tree 62 of 75\n",
      "building tree 63 of 75\n",
      "building tree 64 of 75\n",
      "building tree 65 of 75\n",
      "building tree 66 of 75\n",
      "building tree 67 of 75\n",
      "building tree 68 of 75\n",
      "building tree 69 of 75\n",
      "building tree 70 of 75\n",
      "building tree 71 of 75\n",
      "building tree 72 of 75\n",
      "building tree 73 of 75\n",
      "building tree 74 of 75\n",
      "building tree 75 of 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5009840515778757"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(criterion='entropy', random_state=42)\n",
    "params = {'n_estimators': [10, 20, 50, 75], 'max_depth': [2, 3, 4, 5, 6]}\n",
    "clf_rfc =  GridSearchCV(rfc, params, cv=kf, verbose=10)\n",
    "clf_rfc.fit(X_train_sc, y_train_)\n",
    "pred_rfc = clf_rfc.predict(X_test_sc)\n",
    "multiclass_roc_auc_score(y_test_, pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5182e753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:57:46.384727Z",
     "start_time": "2021-06-15T19:57:46.370698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'n_estimators': 75}"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "666ea8f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:21:06.100824Z",
     "start_time": "2021-06-15T20:03:05.467784Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5; 1/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 1/5; 1/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 1/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 2/5; 1/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 1/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 3/5; 1/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 1/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 4/5; 1/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 1/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 5/5; 1/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 2/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 1/5; 2/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 2/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 2/5; 2/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 2/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 3/5; 2/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 2/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 4/5; 2/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 2/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 5/5; 2/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 3/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 1/5; 3/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 3/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 2/5; 3/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 3/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 3/5; 3/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 3/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 4/5; 3/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 3/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 5/5; 3/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 4/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 1/5; 4/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 4/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 2/5; 4/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 4/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 3/5; 4/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 4/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 4/5; 4/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 4/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 5/5; 4/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 5/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 1/5; 5/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 5/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 2/5; 5/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 5/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 3/5; 5/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 5/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 4/5; 5/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 5/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 5/5; 5/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 6/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 6/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 6/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 2/5; 6/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 6/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 3/5; 6/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 6/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 4/5; 6/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 6/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 5/5; 6/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 7/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 1/5; 7/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 7/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 2/5; 7/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 7/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 3/5; 7/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 7/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 4/5; 7/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 7/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 5/5; 7/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 8/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 1/5; 8/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 8/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 2/5; 8/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 8/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 3/5; 8/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 8/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 4/5; 8/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 8/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 5/5; 8/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 9/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 9/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 9/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 9/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 9/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 9/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 9/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 4/5; 9/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 9/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 5/5; 9/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 10/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 1/5; 10/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 10/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 2/5; 10/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 10/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 3/5; 10/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 10/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 4/5; 10/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 10/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 5/5; 10/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 11/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 1/5; 11/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 11/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 2/5; 11/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 11/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 3/5; 11/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 11/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 4/5; 11/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 11/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 5/5; 11/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 12/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 12/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 12/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 12/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 12/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 12/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 12/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 12/96] START activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 5/5; 12/96] END activation=rele,tanh, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 13/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 1/5; 13/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 13/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 2/5; 13/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 13/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 3/5; 13/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 13/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 4/5; 13/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 13/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 5/5; 13/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 14/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 1/5; 14/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 14/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 2/5; 14/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 14/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 3/5; 14/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 14/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 4/5; 14/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 14/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 5/5; 14/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 15/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 1/5; 15/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 15/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 2/5; 15/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 15/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 3/5; 15/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 15/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 4/5; 15/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 15/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 5/5; 15/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 16/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 1/5; 16/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 16/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 2/5; 16/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 16/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 3/5; 16/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 16/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 4/5; 16/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 16/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 5/5; 16/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 17/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 1/5; 17/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 17/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 2/5; 17/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 17/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 3/5; 17/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 17/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 4/5; 17/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 17/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 5/5; 17/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 18/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 18/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 18/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 2/5; 18/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 18/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 3/5; 18/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 18/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 4/5; 18/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 18/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 5/5; 18/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 19/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 1/5; 19/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 19/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 2/5; 19/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 19/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 3/5; 19/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 19/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 4/5; 19/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 19/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 5/5; 19/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 20/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 1/5; 20/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 20/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 2/5; 20/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 20/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 3/5; 20/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 20/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 4/5; 20/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 20/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 5/5; 20/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 21/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 21/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 21/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 21/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 21/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 21/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 21/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 4/5; 21/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 21/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 5/5; 21/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 22/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 1/5; 22/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 22/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 2/5; 22/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 22/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 22/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 22/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 4/5; 22/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 22/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 5/5; 22/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 23/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 1/5; 23/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 23/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 2/5; 23/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 23/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 3/5; 23/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 23/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 4/5; 23/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 23/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 5/5; 23/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 24/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 1/5; 24/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 24/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 24/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 24/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 24/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 24/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 24/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 24/96] START activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 5/5; 24/96] END activation=rele,tanh, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 25/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 1/5; 25/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 25/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 2/5; 25/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 25/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 3/5; 25/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 25/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 4/5; 25/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 25/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 5/5; 25/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 26/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 1/5; 26/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 26/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 2/5; 26/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 26/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 3/5; 26/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 26/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 4/5; 26/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 26/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 5/5; 26/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 27/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 1/5; 27/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 27/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 2/5; 27/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 27/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 3/5; 27/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 27/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 4/5; 27/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 27/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 5/5; 27/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 28/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 1/5; 28/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 28/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 2/5; 28/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 28/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 3/5; 28/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 28/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 4/5; 28/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 28/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 5/5; 28/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 29/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 1/5; 29/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 29/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 2/5; 29/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 29/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 3/5; 29/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 29/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 4/5; 29/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 29/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 5/5; 29/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 30/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 30/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 30/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 2/5; 30/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 30/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 3/5; 30/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 30/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 4/5; 30/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 30/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 5/5; 30/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 31/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 1/5; 31/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 31/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 2/5; 31/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 31/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 3/5; 31/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 31/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 4/5; 31/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 31/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 5/5; 31/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 32/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 1/5; 32/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 32/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 2/5; 32/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 32/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 3/5; 32/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 32/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 4/5; 32/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 32/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 5/5; 32/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 33/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 33/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 33/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 33/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 33/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 33/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 33/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 4/5; 33/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 33/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 33/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 34/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 1/5; 34/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 34/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 2/5; 34/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 34/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 3/5; 34/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 34/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 4/5; 34/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 34/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 5/5; 34/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 35/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 1/5; 35/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 35/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 2/5; 35/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 35/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 3/5; 35/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 35/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 4/5; 35/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 35/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 5/5; 35/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 36/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 1/5; 36/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 36/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 36/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 36/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 36/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 36/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 36/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 36/96] START activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 5/5; 36/96] END activation=rele,tanh, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 37/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 1/5; 37/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 37/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 2/5; 37/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 37/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 3/5; 37/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 37/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 4/5; 37/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 37/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n",
      "[CV 5/5; 37/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 38/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 1/5; 38/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 38/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 2/5; 38/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 38/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 3/5; 38/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 38/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 4/5; 38/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 38/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n",
      "[CV 5/5; 38/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 39/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 1/5; 39/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 39/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 2/5; 39/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 39/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 3/5; 39/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 39/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 4/5; 39/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 39/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 5/5; 39/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 40/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 1/5; 40/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 40/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 2/5; 40/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 40/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 3/5; 40/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 40/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 4/5; 40/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 40/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n",
      "[CV 5/5; 40/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 41/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 1/5; 41/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 41/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 2/5; 41/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 41/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 3/5; 41/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 41/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 4/5; 41/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 41/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 5/5; 41/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 42/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 42/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 42/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 2/5; 42/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 42/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 3/5; 42/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 42/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 4/5; 42/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 42/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 5/5; 42/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 43/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 1/5; 43/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 43/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 2/5; 43/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 43/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 3/5; 43/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 43/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 4/5; 43/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 43/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n",
      "[CV 5/5; 43/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 44/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 1/5; 44/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 44/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 2/5; 44/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 44/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 3/5; 44/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 44/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 4/5; 44/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 44/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 5/5; 44/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 45/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 45/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 45/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 45/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 45/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 45/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 45/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 673, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 357, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 450, in _validate_hyperparameters\n",
      "    % (self.activation, list(sorted(ACTIVATIONS))))\n",
      "ValueError: The activation 'rele,tanh' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 45/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 45/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 5/5; 45/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 46/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 1/5; 46/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 2/5; 46/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 2/5; 46/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 3/5; 46/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 3/5; 46/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 4/5; 46/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 4/5; 46/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 5/5; 46/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n",
      "[CV 5/5; 46/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   0.0s\n",
      "[CV 1/5; 47/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 1/5; 47/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 2/5; 47/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 2/5; 47/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 3/5; 47/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 3/5; 47/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 4/5; 47/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 4/5; 47/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 5/5; 47/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 5/5; 47/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   0.0s\n",
      "[CV 1/5; 48/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 1/5; 48/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 2/5; 48/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 48/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 3/5; 48/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 48/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 4/5; 48/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 48/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 5/5; 48/96] START activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 5/5; 48/96] END activation=rele,tanh, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   0.0s\n",
      "[CV 1/5; 49/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 49/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 2/5; 49/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 49/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   1.8s\n",
      "[CV 3/5; 49/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 49/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   2.3s\n",
      "[CV 4/5; 49/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 49/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 5/5; 49/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 49/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=100; total time=   1.8s\n",
      "[CV 1/5; 50/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 50/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   3.7s\n",
      "[CV 2/5; 50/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 50/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   3.5s\n",
      "[CV 3/5; 50/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 50/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   3.3s\n",
      "[CV 4/5; 50/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 50/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   3.5s\n",
      "[CV 5/5; 50/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 50/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=200; total time=   3.6s\n",
      "[CV 1/5; 51/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 51/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   5.3s\n",
      "[CV 2/5; 51/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 51/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   5.1s\n",
      "[CV 3/5; 51/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 51/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   5.2s\n",
      "[CV 4/5; 51/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 51/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   5.0s\n",
      "[CV 5/5; 51/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 51/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(10,), max_iter=300; total time=   5.1s\n",
      "[CV 1/5; 52/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 52/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   1.8s\n",
      "[CV 2/5; 52/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 52/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   1.8s\n",
      "[CV 3/5; 52/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 52/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   2.4s\n",
      "[CV 4/5; 52/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 52/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   1.9s\n",
      "[CV 5/5; 52/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 52/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=100; total time=   2.0s\n",
      "[CV 1/5; 53/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 53/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   4.2s\n",
      "[CV 2/5; 53/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 53/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   3.8s\n",
      "[CV 3/5; 53/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 53/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   4.0s\n",
      "[CV 4/5; 53/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 53/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   3.9s\n",
      "[CV 5/5; 53/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 53/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=200; total time=   3.7s\n",
      "[CV 1/5; 54/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 54/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   6.0s\n",
      "[CV 2/5; 54/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 54/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   5.9s\n",
      "[CV 3/5; 54/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 54/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   5.8s\n",
      "[CV 4/5; 54/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 54/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   5.7s\n",
      "[CV 5/5; 54/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 54/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(25,), max_iter=300; total time=   5.7s\n",
      "[CV 1/5; 55/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 55/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   2.4s\n",
      "[CV 2/5; 55/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 55/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   2.3s\n",
      "[CV 3/5; 55/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 55/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   2.3s\n",
      "[CV 4/5; 55/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 55/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   2.3s\n",
      "[CV 5/5; 55/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 55/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=100; total time=   2.4s\n",
      "[CV 1/5; 56/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 56/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   4.7s\n",
      "[CV 2/5; 56/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   4.8s\n",
      "[CV 3/5; 56/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 56/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   4.7s\n",
      "[CV 4/5; 56/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 56/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   4.9s\n",
      "[CV 5/5; 56/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 56/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=200; total time=   4.8s\n",
      "[CV 1/5; 57/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 57/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   7.1s\n",
      "[CV 2/5; 57/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 57/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   7.2s\n",
      "[CV 3/5; 57/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 57/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   7.3s\n",
      "[CV 4/5; 57/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 57/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   7.1s\n",
      "[CV 5/5; 57/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 57/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(50,), max_iter=300; total time=   7.3s\n",
      "[CV 1/5; 58/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 58/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   2.9s\n",
      "[CV 2/5; 58/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 58/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   2.9s\n",
      "[CV 3/5; 58/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 58/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   2.9s\n",
      "[CV 4/5; 58/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 58/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   3.1s\n",
      "[CV 5/5; 58/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 58/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=100; total time=   3.2s\n",
      "[CV 1/5; 59/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 59/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   7.2s\n",
      "[CV 2/5; 59/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 59/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   6.6s\n",
      "[CV 3/5; 59/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 59/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   7.7s\n",
      "[CV 4/5; 59/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 59/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   6.8s\n",
      "[CV 5/5; 59/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 59/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=200; total time=   7.0s\n",
      "[CV 1/5; 60/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 60/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=  10.0s\n",
      "[CV 2/5; 60/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 60/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   9.4s\n",
      "[CV 3/5; 60/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 60/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   9.2s\n",
      "[CV 4/5; 60/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 60/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=   9.5s\n",
      "[CV 5/5; 60/96] START activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 60/96] END activation=logistic, alpha=0.05, hidden_layer_sizes=(100,), max_iter=300; total time=  10.5s\n",
      "[CV 1/5; 61/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 61/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 2/5; 61/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 61/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.8s\n",
      "[CV 3/5; 61/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 61/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   2.2s\n",
      "[CV 4/5; 61/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 61/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   2.2s\n",
      "[CV 5/5; 61/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 61/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.8s\n",
      "[CV 1/5; 62/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 62/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.4s\n",
      "[CV 2/5; 62/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 62/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.5s\n",
      "[CV 3/5; 62/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 62/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.7s\n",
      "[CV 4/5; 62/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 62/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.5s\n",
      "[CV 5/5; 62/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 62/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=200; total time=   4.1s\n",
      "[CV 1/5; 63/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 63/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.6s\n",
      "[CV 2/5; 63/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 63/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.3s\n",
      "[CV 3/5; 63/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 63/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.6s\n",
      "[CV 4/5; 63/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 63/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.3s\n",
      "[CV 5/5; 63/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 63/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.1s\n",
      "[CV 1/5; 64/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 64/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   1.9s\n",
      "[CV 2/5; 64/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 64/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   1.8s\n",
      "[CV 3/5; 64/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 64/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   1.8s\n",
      "[CV 4/5; 64/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 64/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   2.0s\n",
      "[CV 5/5; 64/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 64/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=100; total time=   1.9s\n",
      "[CV 1/5; 65/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 65/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   3.8s\n",
      "[CV 2/5; 65/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 65/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   3.8s\n",
      "[CV 3/5; 65/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   4.2s\n",
      "[CV 4/5; 65/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 65/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   4.0s\n",
      "[CV 5/5; 65/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 65/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=200; total time=   4.0s\n",
      "[CV 1/5; 66/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 66/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   6.1s\n",
      "[CV 2/5; 66/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 66/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   6.1s\n",
      "[CV 3/5; 66/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 66/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   5.8s\n",
      "[CV 4/5; 66/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 66/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   5.6s\n",
      "[CV 5/5; 66/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 66/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(25,), max_iter=300; total time=   5.7s\n",
      "[CV 1/5; 67/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 67/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.2s\n",
      "[CV 2/5; 67/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 67/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.2s\n",
      "[CV 3/5; 67/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 67/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.2s\n",
      "[CV 4/5; 67/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 67/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.3s\n",
      "[CV 5/5; 67/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 67/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.3s\n",
      "[CV 1/5; 68/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 68/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   5.0s\n",
      "[CV 2/5; 68/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 68/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   5.0s\n",
      "[CV 3/5; 68/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 68/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   5.3s\n",
      "[CV 4/5; 68/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 68/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   7.2s\n",
      "[CV 5/5; 68/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 68/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=200; total time=   4.9s\n",
      "[CV 1/5; 69/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 69/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   6.1s\n",
      "[CV 2/5; 69/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 69/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   8.1s\n",
      "[CV 3/5; 69/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 69/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   7.3s\n",
      "[CV 4/5; 69/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 69/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   7.1s\n",
      "[CV 5/5; 69/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 69/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(50,), max_iter=300; total time=   7.1s\n",
      "[CV 1/5; 70/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 70/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.1s\n",
      "[CV 2/5; 70/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 70/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.2s\n",
      "[CV 3/5; 70/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 70/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.5s\n",
      "[CV 4/5; 70/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 70/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.5s\n",
      "[CV 5/5; 70/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 70/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.5s\n",
      "[CV 1/5; 71/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 71/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   6.0s\n",
      "[CV 2/5; 71/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 71/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   6.0s\n",
      "[CV 3/5; 71/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 71/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   6.3s\n",
      "[CV 4/5; 71/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 71/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   6.3s\n",
      "[CV 5/5; 71/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 71/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=200; total time=   6.0s\n",
      "[CV 1/5; 72/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 1/5; 72/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   8.1s\n",
      "[CV 2/5; 72/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 72/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   8.0s\n",
      "[CV 3/5; 72/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 72/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   8.6s\n",
      "[CV 4/5; 72/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 72/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=   8.6s\n",
      "[CV 5/5; 72/96] START activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 72/96] END activation=logistic, alpha=0.1, hidden_layer_sizes=(100,), max_iter=300; total time=  10.1s\n",
      "[CV 1/5; 73/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 73/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 2/5; 73/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 73/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 3/5; 73/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 73/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 4/5; 73/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 73/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   1.6s\n",
      "[CV 5/5; 73/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 73/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 1/5; 74/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 74/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   3.4s\n",
      "[CV 2/5; 74/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 74/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   3.4s\n",
      "[CV 3/5; 74/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 74/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   3.7s\n",
      "[CV 4/5; 74/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   4.1s\n",
      "[CV 5/5; 74/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 74/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=200; total time=   4.4s\n",
      "[CV 1/5; 75/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 75/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   6.9s\n",
      "[CV 2/5; 75/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 75/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   5.5s\n",
      "[CV 3/5; 75/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 75/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   6.1s\n",
      "[CV 4/5; 75/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 75/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   5.3s\n",
      "[CV 5/5; 75/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 5/5; 75/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(10,), max_iter=300; total time=   4.3s\n",
      "[CV 1/5; 76/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   2.5s\n",
      "[CV 2/5; 76/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 76/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   2.9s\n",
      "[CV 3/5; 76/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 76/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   4.1s\n",
      "[CV 4/5; 76/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 76/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   2.4s\n",
      "[CV 5/5; 76/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 76/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=100; total time=   2.0s\n",
      "[CV 1/5; 77/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 77/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   4.4s\n",
      "[CV 2/5; 77/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 77/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   7.2s\n",
      "[CV 3/5; 77/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 77/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   4.6s\n",
      "[CV 4/5; 77/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 77/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   5.5s\n",
      "[CV 5/5; 77/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 77/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=200; total time=   4.2s\n",
      "[CV 1/5; 78/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 78/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   5.1s\n",
      "[CV 2/5; 78/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 78/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   6.1s\n",
      "[CV 3/5; 78/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 3/5; 78/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   6.2s\n",
      "[CV 4/5; 78/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 4/5; 78/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   4.8s\n",
      "[CV 5/5; 78/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 5/5; 78/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(25,), max_iter=300; total time=   6.0s\n",
      "[CV 1/5; 79/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 79/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   2.5s\n",
      "[CV 2/5; 79/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 79/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   2.5s\n",
      "[CV 3/5; 79/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 79/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   2.5s\n",
      "[CV 4/5; 79/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 79/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   2.5s\n",
      "[CV 5/5; 79/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 79/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=100; total time=   2.7s\n",
      "[CV 1/5; 80/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 1/5; 80/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   4.8s\n",
      "[CV 2/5; 80/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 2/5; 80/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   4.0s\n",
      "[CV 3/5; 80/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 3/5; 80/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   3.2s\n",
      "[CV 4/5; 80/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 80/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   5.1s\n",
      "[CV 5/5; 80/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 80/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=200; total time=   5.1s\n",
      "[CV 1/5; 81/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 81/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   4.7s\n",
      "[CV 2/5; 81/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 81/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   4.1s\n",
      "[CV 3/5; 81/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 81/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   3.3s\n",
      "[CV 4/5; 81/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 4/5; 81/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   6.0s\n",
      "[CV 5/5; 81/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 5/5; 81/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(50,), max_iter=300; total time=   7.6s\n",
      "[CV 1/5; 82/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 82/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   3.5s\n",
      "[CV 2/5; 82/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 82/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   3.7s\n",
      "[CV 3/5; 82/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 82/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   3.5s\n",
      "[CV 4/5; 82/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 82/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   3.4s\n",
      "[CV 5/5; 82/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 82/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=100; total time=   3.4s\n",
      "[CV 1/5; 83/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 1/5; 83/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   6.4s\n",
      "[CV 2/5; 83/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 2/5; 83/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   4.6s\n",
      "[CV 3/5; 83/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 3/5; 83/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   4.3s\n",
      "[CV 4/5; 83/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 4/5; 83/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   6.0s\n",
      "[CV 5/5; 83/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=200; total time=   6.9s\n",
      "[CV 1/5; 84/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 1/5; 84/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   6.3s\n",
      "[CV 2/5; 84/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 84/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   4.9s\n",
      "[CV 3/5; 84/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 84/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   4.3s\n",
      "[CV 4/5; 84/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 84/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   6.5s\n",
      "[CV 5/5; 84/96] START activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 5/5; 84/96] END activation=logistic, alpha=0.5, hidden_layer_sizes=(100,), max_iter=300; total time=   7.5s\n",
      "[CV 1/5; 85/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 85/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 2/5; 85/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 85/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 3/5; 85/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 85/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 4/5; 85/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 85/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 5/5; 85/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 85/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=100; total time=   1.7s\n",
      "[CV 1/5; 86/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 86/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.6s\n",
      "[CV 2/5; 86/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 86/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.7s\n",
      "[CV 3/5; 86/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 86/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.6s\n",
      "[CV 4/5; 86/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 86/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.5s\n",
      "[CV 5/5; 86/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 86/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=200; total time=   3.5s\n",
      "[CV 1/5; 87/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 87/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.5s\n",
      "[CV 2/5; 87/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 87/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.6s\n",
      "[CV 3/5; 87/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 87/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.8s\n",
      "[CV 4/5; 87/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 4/5; 87/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   5.5s\n",
      "[CV 5/5; 87/96] START activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300\n",
      "[CV 5/5; 87/96] END activation=logistic, alpha=1, hidden_layer_sizes=(10,), max_iter=300; total time=   4.0s\n",
      "[CV 1/5; 88/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 88/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   2.1s\n",
      "[CV 2/5; 88/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 88/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   2.0s\n",
      "[CV 3/5; 88/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 88/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   2.1s\n",
      "[CV 4/5; 88/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 88/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   2.1s\n",
      "[CV 5/5; 88/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 88/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=100; total time=   2.0s\n",
      "[CV 1/5; 89/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 1/5; 89/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   3.9s\n",
      "[CV 2/5; 89/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 2/5; 89/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   3.6s\n",
      "[CV 3/5; 89/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 89/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   4.3s\n",
      "[CV 4/5; 89/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n",
      "[CV 4/5; 89/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   3.3s\n",
      "[CV 5/5; 89/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 89/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=200; total time=   4.2s\n",
      "[CV 1/5; 90/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 1/5; 90/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   4.1s\n",
      "[CV 2/5; 90/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 2/5; 90/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   3.5s\n",
      "[CV 3/5; 90/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 3/5; 90/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   5.4s\n",
      "[CV 4/5; 90/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 4/5; 90/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   3.3s\n",
      "[CV 5/5; 90/96] START activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300\n",
      "[CV 5/5; 90/96] END activation=logistic, alpha=1, hidden_layer_sizes=(25,), max_iter=300; total time=   5.3s\n",
      "[CV 1/5; 91/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 91/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.7s\n",
      "[CV 2/5; 91/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 91/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.6s\n",
      "[CV 3/5; 91/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 91/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.6s\n",
      "[CV 4/5; 91/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 91/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.6s\n",
      "[CV 5/5; 91/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 91/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=100; total time=   2.6s\n",
      "[CV 1/5; 92/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 1/5; 92/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   3.5s\n",
      "[CV 2/5; 92/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 2/5; 92/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   3.1s\n",
      "[CV 3/5; 92/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 3/5; 92/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   4.6s\n",
      "[CV 4/5; 92/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 92/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   5.5s\n",
      "[CV 5/5; 92/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200\n",
      "[CV 5/5; 92/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=200; total time=   4.5s\n",
      "[CV 1/5; 93/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 1/5; 93/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   3.4s\n",
      "[CV 2/5; 93/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 2/5; 93/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   3.0s\n",
      "[CV 3/5; 93/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 3/5; 93/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   4.9s\n",
      "[CV 4/5; 93/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 4/5; 93/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   5.7s\n",
      "[CV 5/5; 93/96] START activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300\n",
      "[CV 5/5; 93/96] END activation=logistic, alpha=1, hidden_layer_sizes=(50,), max_iter=300; total time=   4.5s\n",
      "[CV 1/5; 94/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 94/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.4s\n",
      "[CV 2/5; 94/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 94/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.4s\n",
      "[CV 3/5; 94/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 94/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.4s\n",
      "[CV 4/5; 94/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 94/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.3s\n",
      "[CV 5/5; 94/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 94/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=100; total time=   3.4s\n",
      "[CV 1/5; 95/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 1/5; 95/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   6.5s\n",
      "[CV 2/5; 95/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 2/5; 95/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   4.2s\n",
      "[CV 3/5; 95/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 3/5; 95/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   4.2s\n",
      "[CV 4/5; 95/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 4/5; 95/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   5.7s\n",
      "[CV 5/5; 95/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200\n",
      "[CV 5/5; 95/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=200; total time=   4.6s\n",
      "[CV 1/5; 96/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 1/5; 96/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   6.5s\n",
      "[CV 2/5; 96/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 2/5; 96/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   4.2s\n",
      "[CV 3/5; 96/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 3/5; 96/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   4.2s\n",
      "[CV 4/5; 96/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 4/5; 96/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   5.7s\n",
      "[CV 5/5; 96/96] START activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300\n",
      "[CV 5/5; 96/96] END activation=logistic, alpha=1, hidden_layer_sizes=(100,), max_iter=300; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.85037972 0.85949287 0.86085323 0.86493394 0.87132822 0.87377553\n",
      " 0.8596305  0.86343937 0.86643118 0.86847237 0.8754092  0.87486499\n",
      " 0.84915505 0.8571817  0.85826912 0.86384523 0.87064832 0.87241536\n",
      " 0.8585416  0.86044729 0.86588734 0.86629587 0.87323261 0.87364031\n",
      " 0.84071967 0.84167196 0.84208031 0.84901742 0.85228152 0.85282556\n",
      " 0.8446647  0.85092218 0.85105824 0.84860944 0.84629661 0.84724899\n",
      " 0.84071764 0.83990177 0.8396293  0.84112626 0.84425441 0.84371019\n",
      " 0.84167085 0.84330332 0.84153461 0.84316736 0.84629467 0.84629467]\n",
      "  category=UserWarning\n",
      "c:\\users\\arcry\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.914"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(learning_rate = 'adaptive', tol=1e-5, random_state=42)\n",
    "params = {'hidden_layer_sizes': [(10,), (25,), (50,), (100,)], \n",
    "          'activation': ['rele,' 'tanh', 'logistic'], \n",
    "          'alpha': [0.05, 0.1, 0.5, 1],\n",
    "          'max_iter': [100, 200, 300]}\n",
    "clf_MLP =  GridSearchCV(MLP, params, cv=kf, verbose=10)\n",
    "clf_MLP.fit(X_train_sc, y_train_)\n",
    "pred_MLP = clf_MLP.predict(X_test_sc)\n",
    "round(multiclass_roc_auc_score(y_test_, pred_MLP), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "0b46c088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T20:21:30.971860Z",
     "start_time": "2021-06-15T20:21:30.960828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic',\n",
       " 'alpha': 0.05,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'max_iter': 200}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_MLP.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "9deae896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:28:28.098283Z",
     "start_time": "2021-06-15T19:28:02.298770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9437768\ttotal: 18.9ms\tremaining: 37.8s\n",
      "1:\tlearn: 0.6796141\ttotal: 33ms\tremaining: 32.9s\n",
      "2:\tlearn: 0.5436701\ttotal: 47.3ms\tremaining: 31.5s\n",
      "3:\tlearn: 0.4701266\ttotal: 61.8ms\tremaining: 30.8s\n",
      "4:\tlearn: 0.4399633\ttotal: 74.7ms\tremaining: 29.8s\n",
      "5:\tlearn: 0.3930672\ttotal: 95.3ms\tremaining: 31.7s\n",
      "6:\tlearn: 0.3639381\ttotal: 110ms\tremaining: 31.4s\n",
      "7:\tlearn: 0.3390808\ttotal: 124ms\tremaining: 30.9s\n",
      "8:\tlearn: 0.3141234\ttotal: 137ms\tremaining: 30.4s\n",
      "9:\tlearn: 0.2977008\ttotal: 150ms\tremaining: 29.9s\n",
      "10:\tlearn: 0.2833582\ttotal: 188ms\tremaining: 34.1s\n",
      "11:\tlearn: 0.2742852\ttotal: 203ms\tremaining: 33.6s\n",
      "12:\tlearn: 0.2657333\ttotal: 219ms\tremaining: 33.5s\n",
      "13:\tlearn: 0.2560948\ttotal: 236ms\tremaining: 33.4s\n",
      "14:\tlearn: 0.2436708\ttotal: 249ms\tremaining: 33s\n",
      "15:\tlearn: 0.2367961\ttotal: 262ms\tremaining: 32.5s\n",
      "16:\tlearn: 0.2282767\ttotal: 276ms\tremaining: 32.2s\n",
      "17:\tlearn: 0.2203085\ttotal: 294ms\tremaining: 32.4s\n",
      "18:\tlearn: 0.2137680\ttotal: 326ms\tremaining: 34s\n",
      "19:\tlearn: 0.2108920\ttotal: 353ms\tremaining: 35s\n",
      "20:\tlearn: 0.2013488\ttotal: 400ms\tremaining: 37.7s\n",
      "21:\tlearn: 0.1918733\ttotal: 415ms\tremaining: 37.3s\n",
      "22:\tlearn: 0.1863555\ttotal: 432ms\tremaining: 37.1s\n",
      "23:\tlearn: 0.1803743\ttotal: 443ms\tremaining: 36.5s\n",
      "24:\tlearn: 0.1761320\ttotal: 457ms\tremaining: 36.1s\n",
      "25:\tlearn: 0.1726298\ttotal: 472ms\tremaining: 35.9s\n",
      "26:\tlearn: 0.1706930\ttotal: 488ms\tremaining: 35.7s\n",
      "27:\tlearn: 0.1662268\ttotal: 504ms\tremaining: 35.5s\n",
      "28:\tlearn: 0.1616427\ttotal: 517ms\tremaining: 35.2s\n",
      "29:\tlearn: 0.1561894\ttotal: 534ms\tremaining: 35s\n",
      "30:\tlearn: 0.1518504\ttotal: 547ms\tremaining: 34.7s\n",
      "31:\tlearn: 0.1474392\ttotal: 560ms\tremaining: 34.5s\n",
      "32:\tlearn: 0.1444255\ttotal: 574ms\tremaining: 34.2s\n",
      "33:\tlearn: 0.1396559\ttotal: 595ms\tremaining: 34.4s\n",
      "34:\tlearn: 0.1359656\ttotal: 607ms\tremaining: 34.1s\n",
      "35:\tlearn: 0.1323432\ttotal: 621ms\tremaining: 33.9s\n",
      "36:\tlearn: 0.1302003\ttotal: 635ms\tremaining: 33.7s\n",
      "37:\tlearn: 0.1257948\ttotal: 648ms\tremaining: 33.5s\n",
      "38:\tlearn: 0.1246727\ttotal: 662ms\tremaining: 33.3s\n",
      "39:\tlearn: 0.1204796\ttotal: 678ms\tremaining: 33.2s\n",
      "40:\tlearn: 0.1188242\ttotal: 692ms\tremaining: 33.1s\n",
      "41:\tlearn: 0.1165438\ttotal: 706ms\tremaining: 32.9s\n",
      "42:\tlearn: 0.1147313\ttotal: 720ms\tremaining: 32.8s\n",
      "43:\tlearn: 0.1132591\ttotal: 734ms\tremaining: 32.6s\n",
      "44:\tlearn: 0.1104646\ttotal: 747ms\tremaining: 32.5s\n",
      "45:\tlearn: 0.1079184\ttotal: 772ms\tremaining: 32.8s\n",
      "46:\tlearn: 0.1059359\ttotal: 786ms\tremaining: 32.6s\n",
      "47:\tlearn: 0.1036298\ttotal: 805ms\tremaining: 32.8s\n",
      "48:\tlearn: 0.1001266\ttotal: 819ms\tremaining: 32.6s\n",
      "49:\tlearn: 0.0997318\ttotal: 831ms\tremaining: 32.4s\n",
      "50:\tlearn: 0.0976833\ttotal: 845ms\tremaining: 32.3s\n",
      "51:\tlearn: 0.0949734\ttotal: 858ms\tremaining: 32.1s\n",
      "52:\tlearn: 0.0931262\ttotal: 873ms\tremaining: 32.1s\n",
      "53:\tlearn: 0.0922289\ttotal: 889ms\tremaining: 32s\n",
      "54:\tlearn: 0.0916184\ttotal: 911ms\tremaining: 32.2s\n",
      "55:\tlearn: 0.0903983\ttotal: 935ms\tremaining: 32.5s\n",
      "56:\tlearn: 0.0882130\ttotal: 955ms\tremaining: 32.5s\n",
      "57:\tlearn: 0.0873763\ttotal: 978ms\tremaining: 32.8s\n",
      "58:\tlearn: 0.0863615\ttotal: 999ms\tremaining: 32.9s\n",
      "59:\tlearn: 0.0839108\ttotal: 1.02s\tremaining: 32.9s\n",
      "60:\tlearn: 0.0834275\ttotal: 1.04s\tremaining: 33s\n",
      "61:\tlearn: 0.0829495\ttotal: 1.05s\tremaining: 32.9s\n",
      "62:\tlearn: 0.0824261\ttotal: 1.07s\tremaining: 32.8s\n",
      "63:\tlearn: 0.0819498\ttotal: 1.08s\tremaining: 32.7s\n",
      "64:\tlearn: 0.0816319\ttotal: 1.1s\tremaining: 32.6s\n",
      "65:\tlearn: 0.0809297\ttotal: 1.11s\tremaining: 32.5s\n",
      "66:\tlearn: 0.0799631\ttotal: 1.12s\tremaining: 32.4s\n",
      "67:\tlearn: 0.0787030\ttotal: 1.14s\tremaining: 32.3s\n",
      "68:\tlearn: 0.0777023\ttotal: 1.16s\tremaining: 32.4s\n",
      "69:\tlearn: 0.0770089\ttotal: 1.19s\tremaining: 32.9s\n",
      "70:\tlearn: 0.0761820\ttotal: 1.2s\tremaining: 32.7s\n",
      "71:\tlearn: 0.0752637\ttotal: 1.22s\tremaining: 32.6s\n",
      "72:\tlearn: 0.0746310\ttotal: 1.23s\tremaining: 32.6s\n",
      "73:\tlearn: 0.0740297\ttotal: 1.25s\tremaining: 32.5s\n",
      "74:\tlearn: 0.0732582\ttotal: 1.26s\tremaining: 32.5s\n",
      "75:\tlearn: 0.0731118\ttotal: 1.28s\tremaining: 32.4s\n",
      "76:\tlearn: 0.0725316\ttotal: 1.29s\tremaining: 32.3s\n",
      "77:\tlearn: 0.0715226\ttotal: 1.3s\tremaining: 32.2s\n",
      "78:\tlearn: 0.0706260\ttotal: 1.32s\tremaining: 32.1s\n",
      "79:\tlearn: 0.0703487\ttotal: 1.34s\tremaining: 32.1s\n",
      "80:\tlearn: 0.0699324\ttotal: 1.35s\tremaining: 32s\n",
      "81:\tlearn: 0.0688092\ttotal: 1.36s\tremaining: 31.9s\n",
      "82:\tlearn: 0.0676590\ttotal: 1.38s\tremaining: 31.8s\n",
      "83:\tlearn: 0.0669037\ttotal: 1.4s\tremaining: 32s\n",
      "84:\tlearn: 0.0664625\ttotal: 1.43s\tremaining: 32.2s\n",
      "85:\tlearn: 0.0661932\ttotal: 1.45s\tremaining: 32.3s\n",
      "86:\tlearn: 0.0661162\ttotal: 1.46s\tremaining: 32.2s\n",
      "87:\tlearn: 0.0652438\ttotal: 1.47s\tremaining: 32s\n",
      "88:\tlearn: 0.0643439\ttotal: 1.49s\tremaining: 31.9s\n",
      "89:\tlearn: 0.0639074\ttotal: 1.5s\tremaining: 31.8s\n",
      "90:\tlearn: 0.0627739\ttotal: 1.51s\tremaining: 31.7s\n",
      "91:\tlearn: 0.0615399\ttotal: 1.52s\tremaining: 31.6s\n",
      "92:\tlearn: 0.0610802\ttotal: 1.54s\tremaining: 31.5s\n",
      "93:\tlearn: 0.0606742\ttotal: 1.55s\tremaining: 31.4s\n",
      "94:\tlearn: 0.0603451\ttotal: 1.56s\tremaining: 31.2s\n",
      "95:\tlearn: 0.0599148\ttotal: 1.57s\tremaining: 31.1s\n",
      "96:\tlearn: 0.0596974\ttotal: 1.58s\tremaining: 31s\n",
      "97:\tlearn: 0.0590286\ttotal: 1.59s\tremaining: 30.9s\n",
      "98:\tlearn: 0.0581176\ttotal: 1.6s\tremaining: 30.8s\n",
      "99:\tlearn: 0.0575685\ttotal: 1.61s\tremaining: 30.7s\n",
      "100:\tlearn: 0.0568124\ttotal: 1.63s\tremaining: 30.6s\n",
      "101:\tlearn: 0.0565282\ttotal: 1.64s\tremaining: 30.5s\n",
      "102:\tlearn: 0.0563726\ttotal: 1.65s\tremaining: 30.3s\n",
      "103:\tlearn: 0.0558822\ttotal: 1.66s\tremaining: 30.2s\n",
      "104:\tlearn: 0.0552268\ttotal: 1.67s\tremaining: 30.1s\n",
      "105:\tlearn: 0.0549428\ttotal: 1.68s\tremaining: 30s\n",
      "106:\tlearn: 0.0548095\ttotal: 1.69s\tremaining: 29.9s\n",
      "107:\tlearn: 0.0543030\ttotal: 1.71s\tremaining: 29.9s\n",
      "108:\tlearn: 0.0540522\ttotal: 1.72s\tremaining: 29.8s\n",
      "109:\tlearn: 0.0535116\ttotal: 1.73s\tremaining: 29.7s\n",
      "110:\tlearn: 0.0524800\ttotal: 1.74s\tremaining: 29.6s\n",
      "111:\tlearn: 0.0521503\ttotal: 1.75s\tremaining: 29.5s\n",
      "112:\tlearn: 0.0515597\ttotal: 1.76s\tremaining: 29.4s\n",
      "113:\tlearn: 0.0513583\ttotal: 1.77s\tremaining: 29.3s\n",
      "114:\tlearn: 0.0508013\ttotal: 1.78s\tremaining: 29.3s\n",
      "115:\tlearn: 0.0500490\ttotal: 1.8s\tremaining: 29.2s\n",
      "116:\tlearn: 0.0497658\ttotal: 1.81s\tremaining: 29.1s\n",
      "117:\tlearn: 0.0496798\ttotal: 1.82s\tremaining: 29s\n",
      "118:\tlearn: 0.0491355\ttotal: 1.83s\tremaining: 28.9s\n",
      "119:\tlearn: 0.0489128\ttotal: 1.84s\tremaining: 28.8s\n",
      "120:\tlearn: 0.0486005\ttotal: 1.85s\tremaining: 28.7s\n",
      "121:\tlearn: 0.0477350\ttotal: 1.86s\tremaining: 28.6s\n",
      "122:\tlearn: 0.0476025\ttotal: 1.87s\tremaining: 28.5s\n",
      "123:\tlearn: 0.0471648\ttotal: 1.88s\tremaining: 28.4s\n",
      "124:\tlearn: 0.0464721\ttotal: 1.89s\tremaining: 28.4s\n",
      "125:\tlearn: 0.0452754\ttotal: 1.91s\tremaining: 28.4s\n",
      "126:\tlearn: 0.0451709\ttotal: 1.92s\tremaining: 28.3s\n",
      "127:\tlearn: 0.0445859\ttotal: 1.93s\tremaining: 28.2s\n",
      "128:\tlearn: 0.0442988\ttotal: 1.94s\tremaining: 28.1s\n",
      "129:\tlearn: 0.0439177\ttotal: 1.95s\tremaining: 28s\n",
      "130:\tlearn: 0.0435435\ttotal: 1.96s\tremaining: 28s\n",
      "131:\tlearn: 0.0434275\ttotal: 1.97s\tremaining: 27.9s\n",
      "132:\tlearn: 0.0432556\ttotal: 2.02s\tremaining: 28.3s\n",
      "133:\tlearn: 0.0430051\ttotal: 2.04s\tremaining: 28.4s\n",
      "134:\tlearn: 0.0425667\ttotal: 2.05s\tremaining: 28.3s\n",
      "135:\tlearn: 0.0421572\ttotal: 2.06s\tremaining: 28.2s\n",
      "136:\tlearn: 0.0418614\ttotal: 2.07s\tremaining: 28.2s\n",
      "137:\tlearn: 0.0415115\ttotal: 2.09s\tremaining: 28.2s\n",
      "138:\tlearn: 0.0410810\ttotal: 2.1s\tremaining: 28.1s\n",
      "139:\tlearn: 0.0408232\ttotal: 2.11s\tremaining: 28s\n",
      "140:\tlearn: 0.0404297\ttotal: 2.12s\tremaining: 28s\n",
      "141:\tlearn: 0.0401880\ttotal: 2.13s\tremaining: 27.9s\n",
      "142:\tlearn: 0.0397269\ttotal: 2.14s\tremaining: 27.8s\n",
      "143:\tlearn: 0.0395787\ttotal: 2.16s\tremaining: 27.8s\n",
      "144:\tlearn: 0.0392469\ttotal: 2.17s\tremaining: 27.8s\n",
      "145:\tlearn: 0.0390628\ttotal: 2.19s\tremaining: 27.8s\n",
      "146:\tlearn: 0.0389370\ttotal: 2.2s\tremaining: 27.7s\n",
      "147:\tlearn: 0.0388166\ttotal: 2.21s\tremaining: 27.7s\n",
      "148:\tlearn: 0.0385327\ttotal: 2.22s\tremaining: 27.6s\n",
      "149:\tlearn: 0.0383380\ttotal: 2.23s\tremaining: 27.5s\n",
      "150:\tlearn: 0.0382678\ttotal: 2.24s\tremaining: 27.5s\n",
      "151:\tlearn: 0.0382235\ttotal: 2.26s\tremaining: 27.4s\n",
      "152:\tlearn: 0.0378887\ttotal: 2.27s\tremaining: 27.4s\n",
      "153:\tlearn: 0.0377135\ttotal: 2.28s\tremaining: 27.3s\n",
      "154:\tlearn: 0.0376403\ttotal: 2.29s\tremaining: 27.3s\n",
      "155:\tlearn: 0.0374630\ttotal: 2.3s\tremaining: 27.2s\n",
      "156:\tlearn: 0.0372390\ttotal: 2.31s\tremaining: 27.1s\n",
      "157:\tlearn: 0.0370066\ttotal: 2.32s\tremaining: 27.1s\n",
      "158:\tlearn: 0.0368565\ttotal: 2.33s\tremaining: 27s\n",
      "159:\tlearn: 0.0367271\ttotal: 2.34s\tremaining: 26.9s\n",
      "160:\tlearn: 0.0364332\ttotal: 2.35s\tremaining: 26.9s\n",
      "161:\tlearn: 0.0361643\ttotal: 2.36s\tremaining: 26.8s\n",
      "162:\tlearn: 0.0356758\ttotal: 2.37s\tremaining: 26.7s\n",
      "163:\tlearn: 0.0355172\ttotal: 2.38s\tremaining: 26.7s\n",
      "164:\tlearn: 0.0354275\ttotal: 2.39s\tremaining: 26.6s\n",
      "165:\tlearn: 0.0353187\ttotal: 2.4s\tremaining: 26.5s\n",
      "166:\tlearn: 0.0352280\ttotal: 2.41s\tremaining: 26.5s\n",
      "167:\tlearn: 0.0350418\ttotal: 2.42s\tremaining: 26.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168:\tlearn: 0.0348368\ttotal: 2.43s\tremaining: 26.4s\n",
      "169:\tlearn: 0.0345362\ttotal: 2.45s\tremaining: 26.3s\n",
      "170:\tlearn: 0.0344450\ttotal: 2.46s\tremaining: 26.3s\n",
      "171:\tlearn: 0.0343235\ttotal: 2.47s\tremaining: 26.2s\n",
      "172:\tlearn: 0.0341459\ttotal: 2.48s\tremaining: 26.2s\n",
      "173:\tlearn: 0.0339063\ttotal: 2.49s\tremaining: 26.1s\n",
      "174:\tlearn: 0.0336142\ttotal: 2.5s\tremaining: 26.1s\n",
      "175:\tlearn: 0.0334485\ttotal: 2.51s\tremaining: 26s\n",
      "176:\tlearn: 0.0332965\ttotal: 2.52s\tremaining: 26s\n",
      "177:\tlearn: 0.0331390\ttotal: 2.53s\tremaining: 25.9s\n",
      "178:\tlearn: 0.0329395\ttotal: 2.54s\tremaining: 25.8s\n",
      "179:\tlearn: 0.0328097\ttotal: 2.55s\tremaining: 25.8s\n",
      "180:\tlearn: 0.0325829\ttotal: 2.56s\tremaining: 25.7s\n",
      "181:\tlearn: 0.0324867\ttotal: 2.57s\tremaining: 25.7s\n",
      "182:\tlearn: 0.0322868\ttotal: 2.58s\tremaining: 25.6s\n",
      "183:\tlearn: 0.0318912\ttotal: 2.59s\tremaining: 25.6s\n",
      "184:\tlearn: 0.0315875\ttotal: 2.61s\tremaining: 25.6s\n",
      "185:\tlearn: 0.0313862\ttotal: 2.62s\tremaining: 25.6s\n",
      "186:\tlearn: 0.0307040\ttotal: 2.63s\tremaining: 25.5s\n",
      "187:\tlearn: 0.0306872\ttotal: 2.64s\tremaining: 25.5s\n",
      "188:\tlearn: 0.0305767\ttotal: 2.65s\tremaining: 25.4s\n",
      "189:\tlearn: 0.0303440\ttotal: 2.66s\tremaining: 25.4s\n",
      "190:\tlearn: 0.0303200\ttotal: 2.67s\tremaining: 25.3s\n",
      "191:\tlearn: 0.0302283\ttotal: 2.69s\tremaining: 25.3s\n",
      "192:\tlearn: 0.0297846\ttotal: 2.7s\tremaining: 25.3s\n",
      "193:\tlearn: 0.0297672\ttotal: 2.71s\tremaining: 25.2s\n",
      "194:\tlearn: 0.0294563\ttotal: 2.72s\tremaining: 25.2s\n",
      "195:\tlearn: 0.0293413\ttotal: 2.73s\tremaining: 25.2s\n",
      "196:\tlearn: 0.0289627\ttotal: 2.75s\tremaining: 25.1s\n",
      "197:\tlearn: 0.0288532\ttotal: 2.76s\tremaining: 25.1s\n",
      "198:\tlearn: 0.0287698\ttotal: 2.77s\tremaining: 25s\n",
      "199:\tlearn: 0.0286775\ttotal: 2.78s\tremaining: 25s\n",
      "200:\tlearn: 0.0285783\ttotal: 2.79s\tremaining: 24.9s\n",
      "201:\tlearn: 0.0283138\ttotal: 2.8s\tremaining: 24.9s\n",
      "202:\tlearn: 0.0282053\ttotal: 2.81s\tremaining: 24.9s\n",
      "203:\tlearn: 0.0281056\ttotal: 2.83s\tremaining: 24.9s\n",
      "204:\tlearn: 0.0280438\ttotal: 2.84s\tremaining: 24.9s\n",
      "205:\tlearn: 0.0278392\ttotal: 2.86s\tremaining: 24.9s\n",
      "206:\tlearn: 0.0277125\ttotal: 2.87s\tremaining: 24.9s\n",
      "207:\tlearn: 0.0275636\ttotal: 2.89s\tremaining: 24.9s\n",
      "208:\tlearn: 0.0272480\ttotal: 2.9s\tremaining: 24.9s\n",
      "209:\tlearn: 0.0271384\ttotal: 2.92s\tremaining: 24.9s\n",
      "210:\tlearn: 0.0269313\ttotal: 2.93s\tremaining: 24.9s\n",
      "211:\tlearn: 0.0268753\ttotal: 2.95s\tremaining: 24.9s\n",
      "212:\tlearn: 0.0267821\ttotal: 2.96s\tremaining: 24.9s\n",
      "213:\tlearn: 0.0266806\ttotal: 2.98s\tremaining: 24.9s\n",
      "214:\tlearn: 0.0263098\ttotal: 2.99s\tremaining: 24.8s\n",
      "215:\tlearn: 0.0260861\ttotal: 3.01s\tremaining: 24.8s\n",
      "216:\tlearn: 0.0260073\ttotal: 3.02s\tremaining: 24.8s\n",
      "217:\tlearn: 0.0256905\ttotal: 3.04s\tremaining: 24.9s\n",
      "218:\tlearn: 0.0256519\ttotal: 3.07s\tremaining: 25s\n",
      "219:\tlearn: 0.0254118\ttotal: 3.1s\tremaining: 25.1s\n",
      "220:\tlearn: 0.0251925\ttotal: 3.11s\tremaining: 25.1s\n",
      "221:\tlearn: 0.0250090\ttotal: 3.13s\tremaining: 25.1s\n",
      "222:\tlearn: 0.0249632\ttotal: 3.15s\tremaining: 25.1s\n",
      "223:\tlearn: 0.0249244\ttotal: 3.16s\tremaining: 25s\n",
      "224:\tlearn: 0.0248499\ttotal: 3.18s\tremaining: 25.1s\n",
      "225:\tlearn: 0.0245576\ttotal: 3.19s\tremaining: 25.1s\n",
      "226:\tlearn: 0.0245074\ttotal: 3.23s\tremaining: 25.2s\n",
      "227:\tlearn: 0.0242767\ttotal: 3.25s\tremaining: 25.3s\n",
      "228:\tlearn: 0.0240669\ttotal: 3.27s\tremaining: 25.3s\n",
      "229:\tlearn: 0.0237941\ttotal: 3.29s\tremaining: 25.3s\n",
      "230:\tlearn: 0.0236824\ttotal: 3.31s\tremaining: 25.4s\n",
      "231:\tlearn: 0.0234694\ttotal: 3.34s\tremaining: 25.5s\n",
      "232:\tlearn: 0.0233778\ttotal: 3.38s\tremaining: 25.6s\n",
      "233:\tlearn: 0.0231126\ttotal: 3.4s\tremaining: 25.7s\n",
      "234:\tlearn: 0.0229777\ttotal: 3.43s\tremaining: 25.8s\n",
      "235:\tlearn: 0.0228103\ttotal: 3.45s\tremaining: 25.8s\n",
      "236:\tlearn: 0.0226487\ttotal: 3.47s\tremaining: 25.8s\n",
      "237:\tlearn: 0.0224733\ttotal: 3.49s\tremaining: 25.9s\n",
      "238:\tlearn: 0.0223363\ttotal: 3.51s\tremaining: 25.9s\n",
      "239:\tlearn: 0.0222404\ttotal: 3.53s\tremaining: 25.9s\n",
      "240:\tlearn: 0.0221683\ttotal: 3.55s\tremaining: 25.9s\n",
      "241:\tlearn: 0.0221402\ttotal: 3.57s\tremaining: 25.9s\n",
      "242:\tlearn: 0.0220088\ttotal: 3.58s\tremaining: 25.9s\n",
      "243:\tlearn: 0.0219400\ttotal: 3.62s\tremaining: 26s\n",
      "244:\tlearn: 0.0219054\ttotal: 3.63s\tremaining: 26s\n",
      "245:\tlearn: 0.0218144\ttotal: 3.65s\tremaining: 26s\n",
      "246:\tlearn: 0.0217093\ttotal: 3.67s\tremaining: 26.1s\n",
      "247:\tlearn: 0.0216502\ttotal: 3.71s\tremaining: 26.2s\n",
      "248:\tlearn: 0.0216057\ttotal: 3.74s\tremaining: 26.3s\n",
      "249:\tlearn: 0.0215259\ttotal: 3.76s\tremaining: 26.3s\n",
      "250:\tlearn: 0.0214139\ttotal: 3.77s\tremaining: 26.3s\n",
      "251:\tlearn: 0.0213307\ttotal: 3.79s\tremaining: 26.3s\n",
      "252:\tlearn: 0.0211730\ttotal: 3.81s\tremaining: 26.3s\n",
      "253:\tlearn: 0.0210961\ttotal: 3.83s\tremaining: 26.3s\n",
      "254:\tlearn: 0.0210400\ttotal: 3.84s\tremaining: 26.3s\n",
      "255:\tlearn: 0.0208554\ttotal: 3.86s\tremaining: 26.3s\n",
      "256:\tlearn: 0.0207002\ttotal: 3.88s\tremaining: 26.3s\n",
      "257:\tlearn: 0.0205740\ttotal: 3.9s\tremaining: 26.3s\n",
      "258:\tlearn: 0.0204404\ttotal: 3.91s\tremaining: 26.3s\n",
      "259:\tlearn: 0.0203554\ttotal: 3.92s\tremaining: 26.3s\n",
      "260:\tlearn: 0.0202218\ttotal: 3.93s\tremaining: 26.2s\n",
      "261:\tlearn: 0.0201793\ttotal: 3.95s\tremaining: 26.2s\n",
      "262:\tlearn: 0.0200858\ttotal: 3.96s\tremaining: 26.2s\n",
      "263:\tlearn: 0.0199745\ttotal: 3.98s\tremaining: 26.2s\n",
      "264:\tlearn: 0.0199522\ttotal: 3.99s\tremaining: 26.1s\n",
      "265:\tlearn: 0.0198504\ttotal: 4.01s\tremaining: 26.1s\n",
      "266:\tlearn: 0.0197950\ttotal: 4.02s\tremaining: 26.1s\n",
      "267:\tlearn: 0.0197529\ttotal: 4.04s\tremaining: 26.1s\n",
      "268:\tlearn: 0.0195882\ttotal: 4.05s\tremaining: 26.1s\n",
      "269:\tlearn: 0.0195565\ttotal: 4.07s\tremaining: 26.1s\n",
      "270:\tlearn: 0.0193232\ttotal: 4.08s\tremaining: 26s\n",
      "271:\tlearn: 0.0191920\ttotal: 4.09s\tremaining: 26s\n",
      "272:\tlearn: 0.0190749\ttotal: 4.11s\tremaining: 26s\n",
      "273:\tlearn: 0.0188308\ttotal: 4.13s\tremaining: 26s\n",
      "274:\tlearn: 0.0188042\ttotal: 4.15s\tremaining: 26s\n",
      "275:\tlearn: 0.0186320\ttotal: 4.17s\tremaining: 26s\n",
      "276:\tlearn: 0.0184523\ttotal: 4.18s\tremaining: 26s\n",
      "277:\tlearn: 0.0184037\ttotal: 4.2s\tremaining: 26s\n",
      "278:\tlearn: 0.0183750\ttotal: 4.22s\tremaining: 26s\n",
      "279:\tlearn: 0.0183308\ttotal: 4.24s\tremaining: 26s\n",
      "280:\tlearn: 0.0181552\ttotal: 4.25s\tremaining: 26s\n",
      "281:\tlearn: 0.0180933\ttotal: 4.27s\tremaining: 26s\n",
      "282:\tlearn: 0.0180243\ttotal: 4.29s\tremaining: 26s\n",
      "283:\tlearn: 0.0179576\ttotal: 4.31s\tremaining: 26s\n",
      "284:\tlearn: 0.0179271\ttotal: 4.33s\tremaining: 26.1s\n",
      "285:\tlearn: 0.0177162\ttotal: 4.36s\tremaining: 26.1s\n",
      "286:\tlearn: 0.0177108\ttotal: 4.37s\tremaining: 26.1s\n",
      "287:\tlearn: 0.0176808\ttotal: 4.39s\tremaining: 26.1s\n",
      "288:\tlearn: 0.0176444\ttotal: 4.4s\tremaining: 26.1s\n",
      "289:\tlearn: 0.0175218\ttotal: 4.41s\tremaining: 26s\n",
      "290:\tlearn: 0.0174069\ttotal: 4.43s\tremaining: 26s\n",
      "291:\tlearn: 0.0173286\ttotal: 4.44s\tremaining: 26s\n",
      "292:\tlearn: 0.0172809\ttotal: 4.45s\tremaining: 25.9s\n",
      "293:\tlearn: 0.0171841\ttotal: 4.46s\tremaining: 25.9s\n",
      "294:\tlearn: 0.0171350\ttotal: 4.47s\tremaining: 25.9s\n",
      "295:\tlearn: 0.0171210\ttotal: 4.48s\tremaining: 25.8s\n",
      "296:\tlearn: 0.0170985\ttotal: 4.49s\tremaining: 25.8s\n",
      "297:\tlearn: 0.0170867\ttotal: 4.5s\tremaining: 25.7s\n",
      "298:\tlearn: 0.0170389\ttotal: 4.51s\tremaining: 25.7s\n",
      "299:\tlearn: 0.0169632\ttotal: 4.53s\tremaining: 25.7s\n",
      "300:\tlearn: 0.0168884\ttotal: 4.54s\tremaining: 25.6s\n",
      "301:\tlearn: 0.0167994\ttotal: 4.55s\tremaining: 25.6s\n",
      "302:\tlearn: 0.0167289\ttotal: 4.57s\tremaining: 25.6s\n",
      "303:\tlearn: 0.0166901\ttotal: 4.58s\tremaining: 25.6s\n",
      "304:\tlearn: 0.0165914\ttotal: 4.6s\tremaining: 25.6s\n",
      "305:\tlearn: 0.0161063\ttotal: 4.62s\tremaining: 25.5s\n",
      "306:\tlearn: 0.0159306\ttotal: 4.63s\tremaining: 25.5s\n",
      "307:\tlearn: 0.0158834\ttotal: 4.64s\tremaining: 25.5s\n",
      "308:\tlearn: 0.0158574\ttotal: 4.65s\tremaining: 25.5s\n",
      "309:\tlearn: 0.0158346\ttotal: 4.67s\tremaining: 25.4s\n",
      "310:\tlearn: 0.0157587\ttotal: 4.68s\tremaining: 25.4s\n",
      "311:\tlearn: 0.0157015\ttotal: 4.69s\tremaining: 25.4s\n",
      "312:\tlearn: 0.0155098\ttotal: 4.71s\tremaining: 25.4s\n",
      "313:\tlearn: 0.0154053\ttotal: 4.73s\tremaining: 25.4s\n",
      "314:\tlearn: 0.0152983\ttotal: 4.74s\tremaining: 25.4s\n",
      "315:\tlearn: 0.0152743\ttotal: 4.75s\tremaining: 25.3s\n",
      "316:\tlearn: 0.0152446\ttotal: 4.77s\tremaining: 25.3s\n",
      "317:\tlearn: 0.0152221\ttotal: 4.78s\tremaining: 25.3s\n",
      "318:\tlearn: 0.0151259\ttotal: 4.8s\tremaining: 25.3s\n",
      "319:\tlearn: 0.0150450\ttotal: 4.81s\tremaining: 25.2s\n",
      "320:\tlearn: 0.0149911\ttotal: 4.82s\tremaining: 25.2s\n",
      "321:\tlearn: 0.0149533\ttotal: 4.83s\tremaining: 25.2s\n",
      "322:\tlearn: 0.0149099\ttotal: 4.85s\tremaining: 25.2s\n",
      "323:\tlearn: 0.0148931\ttotal: 4.86s\tremaining: 25.1s\n",
      "324:\tlearn: 0.0147151\ttotal: 4.87s\tremaining: 25.1s\n",
      "325:\tlearn: 0.0145387\ttotal: 4.89s\tremaining: 25.1s\n",
      "326:\tlearn: 0.0144411\ttotal: 4.91s\tremaining: 25.1s\n",
      "327:\tlearn: 0.0143322\ttotal: 4.92s\tremaining: 25.1s\n",
      "328:\tlearn: 0.0143184\ttotal: 4.93s\tremaining: 25s\n",
      "329:\tlearn: 0.0142891\ttotal: 4.94s\tremaining: 25s\n",
      "330:\tlearn: 0.0141716\ttotal: 4.96s\tremaining: 25s\n",
      "331:\tlearn: 0.0140876\ttotal: 4.97s\tremaining: 25s\n",
      "332:\tlearn: 0.0138882\ttotal: 4.99s\tremaining: 25s\n",
      "333:\tlearn: 0.0137615\ttotal: 5.01s\tremaining: 25s\n",
      "334:\tlearn: 0.0137010\ttotal: 5.02s\tremaining: 25s\n",
      "335:\tlearn: 0.0136872\ttotal: 5.04s\tremaining: 24.9s\n",
      "336:\tlearn: 0.0136613\ttotal: 5.05s\tremaining: 24.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337:\tlearn: 0.0136002\ttotal: 5.07s\tremaining: 24.9s\n",
      "338:\tlearn: 0.0135241\ttotal: 5.08s\tremaining: 24.9s\n",
      "339:\tlearn: 0.0134334\ttotal: 5.09s\tremaining: 24.9s\n",
      "340:\tlearn: 0.0134049\ttotal: 5.11s\tremaining: 24.8s\n",
      "341:\tlearn: 0.0133333\ttotal: 5.13s\tremaining: 24.8s\n",
      "342:\tlearn: 0.0133257\ttotal: 5.14s\tremaining: 24.9s\n",
      "343:\tlearn: 0.0132798\ttotal: 5.16s\tremaining: 24.8s\n",
      "344:\tlearn: 0.0132510\ttotal: 5.18s\tremaining: 24.9s\n",
      "345:\tlearn: 0.0132147\ttotal: 5.2s\tremaining: 24.8s\n",
      "346:\tlearn: 0.0131747\ttotal: 5.21s\tremaining: 24.8s\n",
      "347:\tlearn: 0.0131501\ttotal: 5.23s\tremaining: 24.8s\n",
      "348:\tlearn: 0.0130721\ttotal: 5.24s\tremaining: 24.8s\n",
      "349:\tlearn: 0.0129992\ttotal: 5.25s\tremaining: 24.8s\n",
      "350:\tlearn: 0.0129757\ttotal: 5.27s\tremaining: 24.8s\n",
      "351:\tlearn: 0.0129126\ttotal: 5.28s\tremaining: 24.7s\n",
      "352:\tlearn: 0.0128229\ttotal: 5.3s\tremaining: 24.7s\n",
      "353:\tlearn: 0.0128038\ttotal: 5.31s\tremaining: 24.7s\n",
      "354:\tlearn: 0.0127826\ttotal: 5.33s\tremaining: 24.7s\n",
      "355:\tlearn: 0.0127644\ttotal: 5.34s\tremaining: 24.7s\n",
      "356:\tlearn: 0.0126982\ttotal: 5.35s\tremaining: 24.6s\n",
      "357:\tlearn: 0.0123887\ttotal: 5.36s\tremaining: 24.6s\n",
      "358:\tlearn: 0.0123680\ttotal: 5.38s\tremaining: 24.6s\n",
      "359:\tlearn: 0.0123130\ttotal: 5.39s\tremaining: 24.6s\n",
      "360:\tlearn: 0.0123032\ttotal: 5.4s\tremaining: 24.5s\n",
      "361:\tlearn: 0.0122466\ttotal: 5.41s\tremaining: 24.5s\n",
      "362:\tlearn: 0.0121937\ttotal: 5.42s\tremaining: 24.5s\n",
      "363:\tlearn: 0.0121127\ttotal: 5.44s\tremaining: 24.4s\n",
      "364:\tlearn: 0.0121009\ttotal: 5.45s\tremaining: 24.4s\n",
      "365:\tlearn: 0.0120544\ttotal: 5.46s\tremaining: 24.4s\n",
      "366:\tlearn: 0.0120293\ttotal: 5.47s\tremaining: 24.3s\n",
      "367:\tlearn: 0.0120245\ttotal: 5.48s\tremaining: 24.3s\n",
      "368:\tlearn: 0.0118744\ttotal: 5.49s\tremaining: 24.3s\n",
      "369:\tlearn: 0.0118625\ttotal: 5.5s\tremaining: 24.2s\n",
      "370:\tlearn: 0.0118300\ttotal: 5.51s\tremaining: 24.2s\n",
      "371:\tlearn: 0.0117301\ttotal: 5.53s\tremaining: 24.2s\n",
      "372:\tlearn: 0.0116125\ttotal: 5.54s\tremaining: 24.2s\n",
      "373:\tlearn: 0.0115944\ttotal: 5.55s\tremaining: 24.1s\n",
      "374:\tlearn: 0.0115785\ttotal: 5.56s\tremaining: 24.1s\n",
      "375:\tlearn: 0.0115399\ttotal: 5.57s\tremaining: 24.1s\n",
      "376:\tlearn: 0.0115127\ttotal: 5.58s\tremaining: 24s\n",
      "377:\tlearn: 0.0114768\ttotal: 5.59s\tremaining: 24s\n",
      "378:\tlearn: 0.0114310\ttotal: 5.6s\tremaining: 24s\n",
      "379:\tlearn: 0.0113448\ttotal: 5.62s\tremaining: 23.9s\n",
      "380:\tlearn: 0.0113286\ttotal: 5.63s\tremaining: 23.9s\n",
      "381:\tlearn: 0.0113165\ttotal: 5.64s\tremaining: 23.9s\n",
      "382:\tlearn: 0.0113008\ttotal: 5.65s\tremaining: 23.9s\n",
      "383:\tlearn: 0.0112351\ttotal: 5.67s\tremaining: 23.8s\n",
      "384:\tlearn: 0.0111686\ttotal: 5.68s\tremaining: 23.8s\n",
      "385:\tlearn: 0.0111355\ttotal: 5.7s\tremaining: 23.8s\n",
      "386:\tlearn: 0.0110949\ttotal: 5.71s\tremaining: 23.8s\n",
      "387:\tlearn: 0.0110252\ttotal: 5.73s\tremaining: 23.8s\n",
      "388:\tlearn: 0.0109517\ttotal: 5.74s\tremaining: 23.8s\n",
      "389:\tlearn: 0.0109427\ttotal: 5.75s\tremaining: 23.7s\n",
      "390:\tlearn: 0.0109009\ttotal: 5.76s\tremaining: 23.7s\n",
      "391:\tlearn: 0.0108657\ttotal: 5.78s\tremaining: 23.7s\n",
      "392:\tlearn: 0.0108484\ttotal: 5.79s\tremaining: 23.7s\n",
      "393:\tlearn: 0.0108402\ttotal: 5.8s\tremaining: 23.7s\n",
      "394:\tlearn: 0.0108090\ttotal: 5.81s\tremaining: 23.6s\n",
      "395:\tlearn: 0.0107974\ttotal: 5.83s\tremaining: 23.6s\n",
      "396:\tlearn: 0.0107860\ttotal: 5.84s\tremaining: 23.6s\n",
      "397:\tlearn: 0.0107136\ttotal: 5.85s\tremaining: 23.6s\n",
      "398:\tlearn: 0.0106862\ttotal: 5.86s\tremaining: 23.5s\n",
      "399:\tlearn: 0.0106637\ttotal: 5.88s\tremaining: 23.5s\n",
      "400:\tlearn: 0.0106247\ttotal: 5.89s\tremaining: 23.5s\n",
      "401:\tlearn: 0.0105934\ttotal: 5.9s\tremaining: 23.5s\n",
      "402:\tlearn: 0.0105885\ttotal: 5.91s\tremaining: 23.4s\n",
      "403:\tlearn: 0.0105641\ttotal: 5.92s\tremaining: 23.4s\n",
      "404:\tlearn: 0.0105511\ttotal: 5.93s\tremaining: 23.4s\n",
      "405:\tlearn: 0.0105298\ttotal: 5.95s\tremaining: 23.3s\n",
      "406:\tlearn: 0.0104556\ttotal: 5.96s\tremaining: 23.3s\n",
      "407:\tlearn: 0.0104080\ttotal: 5.97s\tremaining: 23.3s\n",
      "408:\tlearn: 0.0103841\ttotal: 5.98s\tremaining: 23.3s\n",
      "409:\tlearn: 0.0103378\ttotal: 5.99s\tremaining: 23.2s\n",
      "410:\tlearn: 0.0102372\ttotal: 6s\tremaining: 23.2s\n",
      "411:\tlearn: 0.0102187\ttotal: 6.02s\tremaining: 23.2s\n",
      "412:\tlearn: 0.0101924\ttotal: 6.03s\tremaining: 23.2s\n",
      "413:\tlearn: 0.0101643\ttotal: 6.04s\tremaining: 23.1s\n",
      "414:\tlearn: 0.0101334\ttotal: 6.05s\tremaining: 23.1s\n",
      "415:\tlearn: 0.0101139\ttotal: 6.07s\tremaining: 23.1s\n",
      "416:\tlearn: 0.0100850\ttotal: 6.08s\tremaining: 23.1s\n",
      "417:\tlearn: 0.0100734\ttotal: 6.09s\tremaining: 23s\n",
      "418:\tlearn: 0.0100577\ttotal: 6.1s\tremaining: 23s\n",
      "419:\tlearn: 0.0100512\ttotal: 6.11s\tremaining: 23s\n",
      "420:\tlearn: 0.0100304\ttotal: 6.12s\tremaining: 23s\n",
      "421:\tlearn: 0.0099767\ttotal: 6.14s\tremaining: 22.9s\n",
      "422:\tlearn: 0.0099500\ttotal: 6.15s\tremaining: 22.9s\n",
      "423:\tlearn: 0.0099130\ttotal: 6.17s\tremaining: 22.9s\n",
      "424:\tlearn: 0.0098591\ttotal: 6.18s\tremaining: 22.9s\n",
      "425:\tlearn: 0.0098480\ttotal: 6.19s\tremaining: 22.9s\n",
      "426:\tlearn: 0.0097939\ttotal: 6.2s\tremaining: 22.8s\n",
      "427:\tlearn: 0.0097730\ttotal: 6.21s\tremaining: 22.8s\n",
      "428:\tlearn: 0.0097495\ttotal: 6.22s\tremaining: 22.8s\n",
      "429:\tlearn: 0.0097437\ttotal: 6.23s\tremaining: 22.8s\n",
      "430:\tlearn: 0.0097353\ttotal: 6.25s\tremaining: 22.7s\n",
      "431:\tlearn: 0.0097313\ttotal: 6.26s\tremaining: 22.7s\n",
      "432:\tlearn: 0.0096313\ttotal: 6.27s\tremaining: 22.7s\n",
      "433:\tlearn: 0.0096207\ttotal: 6.28s\tremaining: 22.7s\n",
      "434:\tlearn: 0.0095532\ttotal: 6.29s\tremaining: 22.6s\n",
      "435:\tlearn: 0.0095322\ttotal: 6.3s\tremaining: 22.6s\n",
      "436:\tlearn: 0.0095249\ttotal: 6.31s\tremaining: 22.6s\n",
      "437:\tlearn: 0.0094934\ttotal: 6.32s\tremaining: 22.5s\n",
      "438:\tlearn: 0.0094902\ttotal: 6.33s\tremaining: 22.5s\n",
      "439:\tlearn: 0.0094794\ttotal: 6.34s\tremaining: 22.5s\n",
      "440:\tlearn: 0.0094614\ttotal: 6.36s\tremaining: 22.5s\n",
      "441:\tlearn: 0.0094443\ttotal: 6.37s\tremaining: 22.4s\n",
      "442:\tlearn: 0.0094371\ttotal: 6.38s\tremaining: 22.4s\n",
      "443:\tlearn: 0.0093958\ttotal: 6.39s\tremaining: 22.4s\n",
      "444:\tlearn: 0.0093402\ttotal: 6.41s\tremaining: 22.4s\n",
      "445:\tlearn: 0.0093026\ttotal: 6.42s\tremaining: 22.4s\n",
      "446:\tlearn: 0.0092814\ttotal: 6.43s\tremaining: 22.4s\n",
      "447:\tlearn: 0.0092719\ttotal: 6.45s\tremaining: 22.3s\n",
      "448:\tlearn: 0.0092401\ttotal: 6.46s\tremaining: 22.3s\n",
      "449:\tlearn: 0.0091909\ttotal: 6.47s\tremaining: 22.3s\n",
      "450:\tlearn: 0.0091607\ttotal: 6.49s\tremaining: 22.3s\n",
      "451:\tlearn: 0.0091012\ttotal: 6.5s\tremaining: 22.3s\n",
      "452:\tlearn: 0.0090776\ttotal: 6.52s\tremaining: 22.3s\n",
      "453:\tlearn: 0.0090422\ttotal: 6.53s\tremaining: 22.2s\n",
      "454:\tlearn: 0.0090173\ttotal: 6.54s\tremaining: 22.2s\n",
      "455:\tlearn: 0.0090058\ttotal: 6.55s\tremaining: 22.2s\n",
      "456:\tlearn: 0.0089878\ttotal: 6.56s\tremaining: 22.2s\n",
      "457:\tlearn: 0.0088930\ttotal: 6.57s\tremaining: 22.1s\n",
      "458:\tlearn: 0.0088852\ttotal: 6.58s\tremaining: 22.1s\n",
      "459:\tlearn: 0.0088503\ttotal: 6.59s\tremaining: 22.1s\n",
      "460:\tlearn: 0.0087916\ttotal: 6.6s\tremaining: 22s\n",
      "461:\tlearn: 0.0087771\ttotal: 6.61s\tremaining: 22s\n",
      "462:\tlearn: 0.0087496\ttotal: 6.63s\tremaining: 22s\n",
      "463:\tlearn: 0.0087279\ttotal: 6.64s\tremaining: 22s\n",
      "464:\tlearn: 0.0087161\ttotal: 6.65s\tremaining: 22s\n",
      "465:\tlearn: 0.0087089\ttotal: 6.67s\tremaining: 21.9s\n",
      "466:\tlearn: 0.0086857\ttotal: 6.68s\tremaining: 21.9s\n",
      "467:\tlearn: 0.0086806\ttotal: 6.69s\tremaining: 21.9s\n",
      "468:\tlearn: 0.0086733\ttotal: 6.71s\tremaining: 21.9s\n",
      "469:\tlearn: 0.0086591\ttotal: 6.72s\tremaining: 21.9s\n",
      "470:\tlearn: 0.0086297\ttotal: 6.73s\tremaining: 21.9s\n",
      "471:\tlearn: 0.0086009\ttotal: 6.74s\tremaining: 21.8s\n",
      "472:\tlearn: 0.0085606\ttotal: 6.75s\tremaining: 21.8s\n",
      "473:\tlearn: 0.0085479\ttotal: 6.76s\tremaining: 21.8s\n",
      "474:\tlearn: 0.0085123\ttotal: 6.78s\tremaining: 21.8s\n",
      "475:\tlearn: 0.0084780\ttotal: 6.79s\tremaining: 21.7s\n",
      "476:\tlearn: 0.0084688\ttotal: 6.8s\tremaining: 21.7s\n",
      "477:\tlearn: 0.0084518\ttotal: 6.81s\tremaining: 21.7s\n",
      "478:\tlearn: 0.0084037\ttotal: 6.82s\tremaining: 21.7s\n",
      "479:\tlearn: 0.0083482\ttotal: 6.84s\tremaining: 21.7s\n",
      "480:\tlearn: 0.0083134\ttotal: 6.85s\tremaining: 21.6s\n",
      "481:\tlearn: 0.0083107\ttotal: 6.86s\tremaining: 21.6s\n",
      "482:\tlearn: 0.0082931\ttotal: 6.87s\tremaining: 21.6s\n",
      "483:\tlearn: 0.0082859\ttotal: 6.89s\tremaining: 21.6s\n",
      "484:\tlearn: 0.0082720\ttotal: 6.9s\tremaining: 21.6s\n",
      "485:\tlearn: 0.0082620\ttotal: 6.92s\tremaining: 21.5s\n",
      "486:\tlearn: 0.0082228\ttotal: 6.92s\tremaining: 21.5s\n",
      "487:\tlearn: 0.0082083\ttotal: 6.94s\tremaining: 21.5s\n",
      "488:\tlearn: 0.0081604\ttotal: 6.95s\tremaining: 21.5s\n",
      "489:\tlearn: 0.0081550\ttotal: 6.96s\tremaining: 21.5s\n",
      "490:\tlearn: 0.0080683\ttotal: 6.97s\tremaining: 21.4s\n",
      "491:\tlearn: 0.0080547\ttotal: 6.99s\tremaining: 21.4s\n",
      "492:\tlearn: 0.0080163\ttotal: 7s\tremaining: 21.4s\n",
      "493:\tlearn: 0.0079527\ttotal: 7.01s\tremaining: 21.4s\n",
      "494:\tlearn: 0.0079237\ttotal: 7.02s\tremaining: 21.3s\n",
      "495:\tlearn: 0.0078941\ttotal: 7.03s\tremaining: 21.3s\n",
      "496:\tlearn: 0.0078861\ttotal: 7.04s\tremaining: 21.3s\n",
      "497:\tlearn: 0.0078794\ttotal: 7.07s\tremaining: 21.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498:\tlearn: 0.0078719\ttotal: 7.09s\tremaining: 21.3s\n",
      "499:\tlearn: 0.0078657\ttotal: 7.1s\tremaining: 21.3s\n",
      "500:\tlearn: 0.0078537\ttotal: 7.11s\tremaining: 21.3s\n",
      "501:\tlearn: 0.0078286\ttotal: 7.12s\tremaining: 21.3s\n",
      "502:\tlearn: 0.0077555\ttotal: 7.13s\tremaining: 21.2s\n",
      "503:\tlearn: 0.0077513\ttotal: 7.14s\tremaining: 21.2s\n",
      "504:\tlearn: 0.0077377\ttotal: 7.16s\tremaining: 21.2s\n",
      "505:\tlearn: 0.0077344\ttotal: 7.17s\tremaining: 21.2s\n",
      "506:\tlearn: 0.0077096\ttotal: 7.18s\tremaining: 21.1s\n",
      "507:\tlearn: 0.0076945\ttotal: 7.19s\tremaining: 21.1s\n",
      "508:\tlearn: 0.0076660\ttotal: 7.21s\tremaining: 21.1s\n",
      "509:\tlearn: 0.0075991\ttotal: 7.22s\tremaining: 21.1s\n",
      "510:\tlearn: 0.0075899\ttotal: 7.23s\tremaining: 21.1s\n",
      "511:\tlearn: 0.0075690\ttotal: 7.24s\tremaining: 21.1s\n",
      "512:\tlearn: 0.0075378\ttotal: 7.26s\tremaining: 21s\n",
      "513:\tlearn: 0.0074807\ttotal: 7.28s\tremaining: 21s\n",
      "514:\tlearn: 0.0074664\ttotal: 7.29s\tremaining: 21s\n",
      "515:\tlearn: 0.0074616\ttotal: 7.31s\tremaining: 21s\n",
      "516:\tlearn: 0.0074524\ttotal: 7.36s\tremaining: 21.1s\n",
      "517:\tlearn: 0.0074449\ttotal: 7.38s\tremaining: 21.1s\n",
      "518:\tlearn: 0.0074304\ttotal: 7.39s\tremaining: 21.1s\n",
      "519:\tlearn: 0.0074270\ttotal: 7.4s\tremaining: 21.1s\n",
      "520:\tlearn: 0.0074065\ttotal: 7.42s\tremaining: 21.1s\n",
      "521:\tlearn: 0.0074043\ttotal: 7.44s\tremaining: 21.1s\n",
      "522:\tlearn: 0.0073834\ttotal: 7.45s\tremaining: 21s\n",
      "523:\tlearn: 0.0073618\ttotal: 7.47s\tremaining: 21s\n",
      "524:\tlearn: 0.0073571\ttotal: 7.48s\tremaining: 21s\n",
      "525:\tlearn: 0.0073458\ttotal: 7.5s\tremaining: 21s\n",
      "526:\tlearn: 0.0073405\ttotal: 7.51s\tremaining: 21s\n",
      "527:\tlearn: 0.0073194\ttotal: 7.52s\tremaining: 21s\n",
      "528:\tlearn: 0.0072771\ttotal: 7.54s\tremaining: 21s\n",
      "529:\tlearn: 0.0072645\ttotal: 7.55s\tremaining: 20.9s\n",
      "530:\tlearn: 0.0071941\ttotal: 7.56s\tremaining: 20.9s\n",
      "531:\tlearn: 0.0071514\ttotal: 7.57s\tremaining: 20.9s\n",
      "532:\tlearn: 0.0071356\ttotal: 7.58s\tremaining: 20.9s\n",
      "533:\tlearn: 0.0071200\ttotal: 7.6s\tremaining: 20.9s\n",
      "534:\tlearn: 0.0071080\ttotal: 7.62s\tremaining: 20.9s\n",
      "535:\tlearn: 0.0070935\ttotal: 7.63s\tremaining: 20.9s\n",
      "536:\tlearn: 0.0070825\ttotal: 7.65s\tremaining: 20.8s\n",
      "537:\tlearn: 0.0070485\ttotal: 7.66s\tremaining: 20.8s\n",
      "538:\tlearn: 0.0070316\ttotal: 7.67s\tremaining: 20.8s\n",
      "539:\tlearn: 0.0070128\ttotal: 7.68s\tremaining: 20.8s\n",
      "540:\tlearn: 0.0070070\ttotal: 7.69s\tremaining: 20.7s\n",
      "541:\tlearn: 0.0069631\ttotal: 7.71s\tremaining: 20.7s\n",
      "542:\tlearn: 0.0069585\ttotal: 7.72s\tremaining: 20.7s\n",
      "543:\tlearn: 0.0069471\ttotal: 7.73s\tremaining: 20.7s\n",
      "544:\tlearn: 0.0069396\ttotal: 7.74s\tremaining: 20.7s\n",
      "545:\tlearn: 0.0069368\ttotal: 7.75s\tremaining: 20.6s\n",
      "546:\tlearn: 0.0069147\ttotal: 7.76s\tremaining: 20.6s\n",
      "547:\tlearn: 0.0069063\ttotal: 7.78s\tremaining: 20.6s\n",
      "548:\tlearn: 0.0068985\ttotal: 7.79s\tremaining: 20.6s\n",
      "549:\tlearn: 0.0068578\ttotal: 7.79s\tremaining: 20.6s\n",
      "550:\tlearn: 0.0068485\ttotal: 7.8s\tremaining: 20.5s\n",
      "551:\tlearn: 0.0068406\ttotal: 7.82s\tremaining: 20.5s\n",
      "552:\tlearn: 0.0068372\ttotal: 7.83s\tremaining: 20.5s\n",
      "553:\tlearn: 0.0068276\ttotal: 7.84s\tremaining: 20.5s\n",
      "554:\tlearn: 0.0067881\ttotal: 7.84s\tremaining: 20.4s\n",
      "555:\tlearn: 0.0067758\ttotal: 7.86s\tremaining: 20.4s\n",
      "556:\tlearn: 0.0067620\ttotal: 7.86s\tremaining: 20.4s\n",
      "557:\tlearn: 0.0067597\ttotal: 7.87s\tremaining: 20.3s\n",
      "558:\tlearn: 0.0067084\ttotal: 7.88s\tremaining: 20.3s\n",
      "559:\tlearn: 0.0067014\ttotal: 7.89s\tremaining: 20.3s\n",
      "560:\tlearn: 0.0066940\ttotal: 7.9s\tremaining: 20.3s\n",
      "561:\tlearn: 0.0066894\ttotal: 7.91s\tremaining: 20.2s\n",
      "562:\tlearn: 0.0066806\ttotal: 7.92s\tremaining: 20.2s\n",
      "563:\tlearn: 0.0066657\ttotal: 7.93s\tremaining: 20.2s\n",
      "564:\tlearn: 0.0066622\ttotal: 7.94s\tremaining: 20.2s\n",
      "565:\tlearn: 0.0066538\ttotal: 7.95s\tremaining: 20.2s\n",
      "566:\tlearn: 0.0066369\ttotal: 7.97s\tremaining: 20.1s\n",
      "567:\tlearn: 0.0066299\ttotal: 7.98s\tremaining: 20.1s\n",
      "568:\tlearn: 0.0066134\ttotal: 7.99s\tremaining: 20.1s\n",
      "569:\tlearn: 0.0066034\ttotal: 8s\tremaining: 20.1s\n",
      "570:\tlearn: 0.0065942\ttotal: 8.01s\tremaining: 20.1s\n",
      "571:\tlearn: 0.0065641\ttotal: 8.02s\tremaining: 20s\n",
      "572:\tlearn: 0.0065562\ttotal: 8.04s\tremaining: 20s\n",
      "573:\tlearn: 0.0065509\ttotal: 8.05s\tremaining: 20s\n",
      "574:\tlearn: 0.0064902\ttotal: 8.06s\tremaining: 20s\n",
      "575:\tlearn: 0.0064650\ttotal: 8.07s\tremaining: 19.9s\n",
      "576:\tlearn: 0.0064520\ttotal: 8.08s\tremaining: 19.9s\n",
      "577:\tlearn: 0.0064158\ttotal: 8.09s\tremaining: 19.9s\n",
      "578:\tlearn: 0.0064061\ttotal: 8.1s\tremaining: 19.9s\n",
      "579:\tlearn: 0.0063990\ttotal: 8.11s\tremaining: 19.9s\n",
      "580:\tlearn: 0.0063513\ttotal: 8.12s\tremaining: 19.8s\n",
      "581:\tlearn: 0.0063424\ttotal: 8.13s\tremaining: 19.8s\n",
      "582:\tlearn: 0.0063229\ttotal: 8.14s\tremaining: 19.8s\n",
      "583:\tlearn: 0.0063096\ttotal: 8.15s\tremaining: 19.8s\n",
      "584:\tlearn: 0.0062873\ttotal: 8.16s\tremaining: 19.7s\n",
      "585:\tlearn: 0.0062690\ttotal: 8.17s\tremaining: 19.7s\n",
      "586:\tlearn: 0.0062497\ttotal: 8.18s\tremaining: 19.7s\n",
      "587:\tlearn: 0.0062344\ttotal: 8.19s\tremaining: 19.7s\n",
      "588:\tlearn: 0.0062217\ttotal: 8.2s\tremaining: 19.6s\n",
      "589:\tlearn: 0.0061981\ttotal: 8.21s\tremaining: 19.6s\n",
      "590:\tlearn: 0.0061823\ttotal: 8.22s\tremaining: 19.6s\n",
      "591:\tlearn: 0.0061713\ttotal: 8.23s\tremaining: 19.6s\n",
      "592:\tlearn: 0.0061405\ttotal: 8.24s\tremaining: 19.5s\n",
      "593:\tlearn: 0.0061233\ttotal: 8.25s\tremaining: 19.5s\n",
      "594:\tlearn: 0.0061074\ttotal: 8.26s\tremaining: 19.5s\n",
      "595:\tlearn: 0.0060864\ttotal: 8.27s\tremaining: 19.5s\n",
      "596:\tlearn: 0.0060666\ttotal: 8.28s\tremaining: 19.4s\n",
      "597:\tlearn: 0.0060603\ttotal: 8.29s\tremaining: 19.4s\n",
      "598:\tlearn: 0.0060540\ttotal: 8.3s\tremaining: 19.4s\n",
      "599:\tlearn: 0.0060448\ttotal: 8.3s\tremaining: 19.4s\n",
      "600:\tlearn: 0.0060244\ttotal: 8.31s\tremaining: 19.4s\n",
      "601:\tlearn: 0.0060145\ttotal: 8.33s\tremaining: 19.3s\n",
      "602:\tlearn: 0.0060083\ttotal: 8.34s\tremaining: 19.3s\n",
      "603:\tlearn: 0.0060034\ttotal: 8.34s\tremaining: 19.3s\n",
      "604:\tlearn: 0.0059835\ttotal: 8.36s\tremaining: 19.3s\n",
      "605:\tlearn: 0.0059764\ttotal: 8.37s\tremaining: 19.2s\n",
      "606:\tlearn: 0.0059658\ttotal: 8.38s\tremaining: 19.2s\n",
      "607:\tlearn: 0.0059509\ttotal: 8.39s\tremaining: 19.2s\n",
      "608:\tlearn: 0.0059260\ttotal: 8.4s\tremaining: 19.2s\n",
      "609:\tlearn: 0.0059188\ttotal: 8.41s\tremaining: 19.2s\n",
      "610:\tlearn: 0.0059168\ttotal: 8.42s\tremaining: 19.2s\n",
      "611:\tlearn: 0.0058867\ttotal: 8.44s\tremaining: 19.1s\n",
      "612:\tlearn: 0.0058785\ttotal: 8.44s\tremaining: 19.1s\n",
      "613:\tlearn: 0.0058240\ttotal: 8.46s\tremaining: 19.1s\n",
      "614:\tlearn: 0.0057907\ttotal: 8.47s\tremaining: 19.1s\n",
      "615:\tlearn: 0.0057692\ttotal: 8.48s\tremaining: 19s\n",
      "616:\tlearn: 0.0057491\ttotal: 8.49s\tremaining: 19s\n",
      "617:\tlearn: 0.0057332\ttotal: 8.5s\tremaining: 19s\n",
      "618:\tlearn: 0.0057262\ttotal: 8.51s\tremaining: 19s\n",
      "619:\tlearn: 0.0057174\ttotal: 8.52s\tremaining: 19s\n",
      "620:\tlearn: 0.0057018\ttotal: 8.53s\tremaining: 18.9s\n",
      "621:\tlearn: 0.0056938\ttotal: 8.54s\tremaining: 18.9s\n",
      "622:\tlearn: 0.0056597\ttotal: 8.55s\tremaining: 18.9s\n",
      "623:\tlearn: 0.0056384\ttotal: 8.57s\tremaining: 18.9s\n",
      "624:\tlearn: 0.0056287\ttotal: 8.58s\tremaining: 18.9s\n",
      "625:\tlearn: 0.0055808\ttotal: 8.59s\tremaining: 18.9s\n",
      "626:\tlearn: 0.0055770\ttotal: 8.6s\tremaining: 18.8s\n",
      "627:\tlearn: 0.0055692\ttotal: 8.61s\tremaining: 18.8s\n",
      "628:\tlearn: 0.0055623\ttotal: 8.62s\tremaining: 18.8s\n",
      "629:\tlearn: 0.0055411\ttotal: 8.63s\tremaining: 18.8s\n",
      "630:\tlearn: 0.0055369\ttotal: 8.64s\tremaining: 18.7s\n",
      "631:\tlearn: 0.0055232\ttotal: 8.65s\tremaining: 18.7s\n",
      "632:\tlearn: 0.0055139\ttotal: 8.66s\tremaining: 18.7s\n",
      "633:\tlearn: 0.0055118\ttotal: 8.67s\tremaining: 18.7s\n",
      "634:\tlearn: 0.0054918\ttotal: 8.68s\tremaining: 18.7s\n",
      "635:\tlearn: 0.0054749\ttotal: 8.69s\tremaining: 18.6s\n",
      "636:\tlearn: 0.0054708\ttotal: 8.7s\tremaining: 18.6s\n",
      "637:\tlearn: 0.0054570\ttotal: 8.71s\tremaining: 18.6s\n",
      "638:\tlearn: 0.0054503\ttotal: 8.72s\tremaining: 18.6s\n",
      "639:\tlearn: 0.0054414\ttotal: 8.73s\tremaining: 18.6s\n",
      "640:\tlearn: 0.0054336\ttotal: 8.74s\tremaining: 18.5s\n",
      "641:\tlearn: 0.0054313\ttotal: 8.75s\tremaining: 18.5s\n",
      "642:\tlearn: 0.0054183\ttotal: 8.76s\tremaining: 18.5s\n",
      "643:\tlearn: 0.0053975\ttotal: 8.77s\tremaining: 18.5s\n",
      "644:\tlearn: 0.0053906\ttotal: 8.78s\tremaining: 18.4s\n",
      "645:\tlearn: 0.0053763\ttotal: 8.79s\tremaining: 18.4s\n",
      "646:\tlearn: 0.0053484\ttotal: 8.8s\tremaining: 18.4s\n",
      "647:\tlearn: 0.0053356\ttotal: 8.81s\tremaining: 18.4s\n",
      "648:\tlearn: 0.0053055\ttotal: 8.82s\tremaining: 18.4s\n",
      "649:\tlearn: 0.0053040\ttotal: 8.83s\tremaining: 18.3s\n",
      "650:\tlearn: 0.0052924\ttotal: 8.84s\tremaining: 18.3s\n",
      "651:\tlearn: 0.0052765\ttotal: 8.85s\tremaining: 18.3s\n",
      "652:\tlearn: 0.0052687\ttotal: 8.86s\tremaining: 18.3s\n",
      "653:\tlearn: 0.0052520\ttotal: 8.87s\tremaining: 18.3s\n",
      "654:\tlearn: 0.0052435\ttotal: 8.88s\tremaining: 18.2s\n",
      "655:\tlearn: 0.0052308\ttotal: 8.89s\tremaining: 18.2s\n",
      "656:\tlearn: 0.0052288\ttotal: 8.9s\tremaining: 18.2s\n",
      "657:\tlearn: 0.0052066\ttotal: 8.91s\tremaining: 18.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658:\tlearn: 0.0052045\ttotal: 8.92s\tremaining: 18.1s\n",
      "659:\tlearn: 0.0052009\ttotal: 8.93s\tremaining: 18.1s\n",
      "660:\tlearn: 0.0051990\ttotal: 8.94s\tremaining: 18.1s\n",
      "661:\tlearn: 0.0051733\ttotal: 8.95s\tremaining: 18.1s\n",
      "662:\tlearn: 0.0051515\ttotal: 8.96s\tremaining: 18.1s\n",
      "663:\tlearn: 0.0051425\ttotal: 8.97s\tremaining: 18s\n",
      "664:\tlearn: 0.0051307\ttotal: 8.97s\tremaining: 18s\n",
      "665:\tlearn: 0.0051161\ttotal: 8.98s\tremaining: 18s\n",
      "666:\tlearn: 0.0051053\ttotal: 8.99s\tremaining: 18s\n",
      "667:\tlearn: 0.0050772\ttotal: 9.01s\tremaining: 18s\n",
      "668:\tlearn: 0.0050637\ttotal: 9.02s\tremaining: 17.9s\n",
      "669:\tlearn: 0.0050572\ttotal: 9.03s\tremaining: 17.9s\n",
      "670:\tlearn: 0.0050552\ttotal: 9.04s\tremaining: 17.9s\n",
      "671:\tlearn: 0.0050520\ttotal: 9.05s\tremaining: 17.9s\n",
      "672:\tlearn: 0.0050364\ttotal: 9.06s\tremaining: 17.9s\n",
      "673:\tlearn: 0.0050123\ttotal: 9.07s\tremaining: 17.8s\n",
      "674:\tlearn: 0.0050032\ttotal: 9.08s\tremaining: 17.8s\n",
      "675:\tlearn: 0.0049931\ttotal: 9.1s\tremaining: 17.8s\n",
      "676:\tlearn: 0.0049812\ttotal: 9.11s\tremaining: 17.8s\n",
      "677:\tlearn: 0.0049729\ttotal: 9.12s\tremaining: 17.8s\n",
      "678:\tlearn: 0.0049658\ttotal: 9.13s\tremaining: 17.8s\n",
      "679:\tlearn: 0.0049510\ttotal: 9.14s\tremaining: 17.7s\n",
      "680:\tlearn: 0.0049321\ttotal: 9.15s\tremaining: 17.7s\n",
      "681:\tlearn: 0.0049266\ttotal: 9.16s\tremaining: 17.7s\n",
      "682:\tlearn: 0.0048902\ttotal: 9.17s\tremaining: 17.7s\n",
      "683:\tlearn: 0.0048734\ttotal: 9.18s\tremaining: 17.7s\n",
      "684:\tlearn: 0.0048543\ttotal: 9.19s\tremaining: 17.6s\n",
      "685:\tlearn: 0.0048490\ttotal: 9.2s\tremaining: 17.6s\n",
      "686:\tlearn: 0.0048325\ttotal: 9.21s\tremaining: 17.6s\n",
      "687:\tlearn: 0.0048290\ttotal: 9.22s\tremaining: 17.6s\n",
      "688:\tlearn: 0.0048276\ttotal: 9.23s\tremaining: 17.6s\n",
      "689:\tlearn: 0.0048006\ttotal: 9.24s\tremaining: 17.5s\n",
      "690:\tlearn: 0.0047879\ttotal: 9.27s\tremaining: 17.6s\n",
      "691:\tlearn: 0.0047855\ttotal: 9.29s\tremaining: 17.6s\n",
      "692:\tlearn: 0.0047729\ttotal: 9.3s\tremaining: 17.5s\n",
      "693:\tlearn: 0.0047704\ttotal: 9.31s\tremaining: 17.5s\n",
      "694:\tlearn: 0.0047681\ttotal: 9.32s\tremaining: 17.5s\n",
      "695:\tlearn: 0.0047602\ttotal: 9.33s\tremaining: 17.5s\n",
      "696:\tlearn: 0.0047525\ttotal: 9.34s\tremaining: 17.5s\n",
      "697:\tlearn: 0.0047424\ttotal: 9.35s\tremaining: 17.4s\n",
      "698:\tlearn: 0.0047386\ttotal: 9.36s\tremaining: 17.4s\n",
      "699:\tlearn: 0.0047232\ttotal: 9.37s\tremaining: 17.4s\n",
      "700:\tlearn: 0.0047183\ttotal: 9.38s\tremaining: 17.4s\n",
      "701:\tlearn: 0.0047133\ttotal: 9.39s\tremaining: 17.4s\n",
      "702:\tlearn: 0.0047044\ttotal: 9.4s\tremaining: 17.3s\n",
      "703:\tlearn: 0.0047013\ttotal: 9.41s\tremaining: 17.3s\n",
      "704:\tlearn: 0.0046951\ttotal: 9.42s\tremaining: 17.3s\n",
      "705:\tlearn: 0.0046890\ttotal: 9.43s\tremaining: 17.3s\n",
      "706:\tlearn: 0.0046673\ttotal: 9.44s\tremaining: 17.3s\n",
      "707:\tlearn: 0.0046426\ttotal: 9.45s\tremaining: 17.2s\n",
      "708:\tlearn: 0.0046405\ttotal: 9.47s\tremaining: 17.3s\n",
      "709:\tlearn: 0.0046381\ttotal: 9.48s\tremaining: 17.2s\n",
      "710:\tlearn: 0.0046341\ttotal: 9.49s\tremaining: 17.2s\n",
      "711:\tlearn: 0.0045994\ttotal: 9.51s\tremaining: 17.2s\n",
      "712:\tlearn: 0.0045769\ttotal: 9.52s\tremaining: 17.2s\n",
      "713:\tlearn: 0.0045683\ttotal: 9.53s\tremaining: 17.2s\n",
      "714:\tlearn: 0.0045629\ttotal: 9.54s\tremaining: 17.1s\n",
      "715:\tlearn: 0.0045542\ttotal: 9.55s\tremaining: 17.1s\n",
      "716:\tlearn: 0.0045329\ttotal: 9.56s\tremaining: 17.1s\n",
      "717:\tlearn: 0.0045257\ttotal: 9.57s\tremaining: 17.1s\n",
      "718:\tlearn: 0.0045181\ttotal: 9.59s\tremaining: 17.1s\n",
      "719:\tlearn: 0.0045104\ttotal: 9.6s\tremaining: 17.1s\n",
      "720:\tlearn: 0.0044941\ttotal: 9.61s\tremaining: 17s\n",
      "721:\tlearn: 0.0044767\ttotal: 9.62s\tremaining: 17s\n",
      "722:\tlearn: 0.0044653\ttotal: 9.63s\tremaining: 17s\n",
      "723:\tlearn: 0.0044520\ttotal: 9.64s\tremaining: 17s\n",
      "724:\tlearn: 0.0044491\ttotal: 9.65s\tremaining: 17s\n",
      "725:\tlearn: 0.0044369\ttotal: 9.67s\tremaining: 17s\n",
      "726:\tlearn: 0.0044296\ttotal: 9.68s\tremaining: 17s\n",
      "727:\tlearn: 0.0044018\ttotal: 9.69s\tremaining: 16.9s\n",
      "728:\tlearn: 0.0043949\ttotal: 9.71s\tremaining: 16.9s\n",
      "729:\tlearn: 0.0043772\ttotal: 9.72s\tremaining: 16.9s\n",
      "730:\tlearn: 0.0043672\ttotal: 9.73s\tremaining: 16.9s\n",
      "731:\tlearn: 0.0043578\ttotal: 9.74s\tremaining: 16.9s\n",
      "732:\tlearn: 0.0043340\ttotal: 9.76s\tremaining: 16.9s\n",
      "733:\tlearn: 0.0043085\ttotal: 9.77s\tremaining: 16.9s\n",
      "734:\tlearn: 0.0043063\ttotal: 9.78s\tremaining: 16.8s\n",
      "735:\tlearn: 0.0042880\ttotal: 9.79s\tremaining: 16.8s\n",
      "736:\tlearn: 0.0042804\ttotal: 9.81s\tremaining: 16.8s\n",
      "737:\tlearn: 0.0042720\ttotal: 9.82s\tremaining: 16.8s\n",
      "738:\tlearn: 0.0042698\ttotal: 9.83s\tremaining: 16.8s\n",
      "739:\tlearn: 0.0042546\ttotal: 9.84s\tremaining: 16.8s\n",
      "740:\tlearn: 0.0042532\ttotal: 9.85s\tremaining: 16.7s\n",
      "741:\tlearn: 0.0042455\ttotal: 9.89s\tremaining: 16.8s\n",
      "742:\tlearn: 0.0042306\ttotal: 9.91s\tremaining: 16.8s\n",
      "743:\tlearn: 0.0042179\ttotal: 9.92s\tremaining: 16.7s\n",
      "744:\tlearn: 0.0042117\ttotal: 9.93s\tremaining: 16.7s\n",
      "745:\tlearn: 0.0042080\ttotal: 9.94s\tremaining: 16.7s\n",
      "746:\tlearn: 0.0041947\ttotal: 9.95s\tremaining: 16.7s\n",
      "747:\tlearn: 0.0041843\ttotal: 9.96s\tremaining: 16.7s\n",
      "748:\tlearn: 0.0041793\ttotal: 9.97s\tremaining: 16.7s\n",
      "749:\tlearn: 0.0041718\ttotal: 9.98s\tremaining: 16.6s\n",
      "750:\tlearn: 0.0041699\ttotal: 9.99s\tremaining: 16.6s\n",
      "751:\tlearn: 0.0041655\ttotal: 10s\tremaining: 16.6s\n",
      "752:\tlearn: 0.0041513\ttotal: 10s\tremaining: 16.6s\n",
      "753:\tlearn: 0.0041491\ttotal: 10s\tremaining: 16.6s\n",
      "754:\tlearn: 0.0041376\ttotal: 10s\tremaining: 16.6s\n",
      "755:\tlearn: 0.0041346\ttotal: 10s\tremaining: 16.5s\n",
      "756:\tlearn: 0.0041305\ttotal: 10.1s\tremaining: 16.5s\n",
      "757:\tlearn: 0.0041256\ttotal: 10.1s\tremaining: 16.5s\n",
      "758:\tlearn: 0.0041188\ttotal: 10.1s\tremaining: 16.5s\n",
      "759:\tlearn: 0.0041127\ttotal: 10.1s\tremaining: 16.5s\n",
      "760:\tlearn: 0.0040963\ttotal: 10.1s\tremaining: 16.5s\n",
      "761:\tlearn: 0.0040951\ttotal: 10.1s\tremaining: 16.4s\n",
      "762:\tlearn: 0.0040745\ttotal: 10.1s\tremaining: 16.4s\n",
      "763:\tlearn: 0.0040688\ttotal: 10.1s\tremaining: 16.4s\n",
      "764:\tlearn: 0.0040658\ttotal: 10.2s\tremaining: 16.4s\n",
      "765:\tlearn: 0.0040539\ttotal: 10.2s\tremaining: 16.4s\n",
      "766:\tlearn: 0.0040527\ttotal: 10.2s\tremaining: 16.4s\n",
      "767:\tlearn: 0.0040214\ttotal: 10.2s\tremaining: 16.3s\n",
      "768:\tlearn: 0.0040145\ttotal: 10.2s\tremaining: 16.3s\n",
      "769:\tlearn: 0.0040074\ttotal: 10.2s\tremaining: 16.3s\n",
      "770:\tlearn: 0.0039666\ttotal: 10.2s\tremaining: 16.3s\n",
      "771:\tlearn: 0.0039647\ttotal: 10.2s\tremaining: 16.3s\n",
      "772:\tlearn: 0.0039622\ttotal: 10.2s\tremaining: 16.2s\n",
      "773:\tlearn: 0.0039564\ttotal: 10.2s\tremaining: 16.2s\n",
      "774:\tlearn: 0.0039425\ttotal: 10.3s\tremaining: 16.2s\n",
      "775:\tlearn: 0.0039419\ttotal: 10.3s\tremaining: 16.2s\n",
      "776:\tlearn: 0.0039387\ttotal: 10.3s\tremaining: 16.2s\n",
      "777:\tlearn: 0.0039205\ttotal: 10.3s\tremaining: 16.2s\n",
      "778:\tlearn: 0.0039181\ttotal: 10.3s\tremaining: 16.1s\n",
      "779:\tlearn: 0.0039159\ttotal: 10.3s\tremaining: 16.1s\n",
      "780:\tlearn: 0.0039044\ttotal: 10.3s\tremaining: 16.1s\n",
      "781:\tlearn: 0.0039032\ttotal: 10.3s\tremaining: 16.1s\n",
      "782:\tlearn: 0.0039015\ttotal: 10.3s\tremaining: 16.1s\n",
      "783:\tlearn: 0.0038966\ttotal: 10.3s\tremaining: 16s\n",
      "784:\tlearn: 0.0038946\ttotal: 10.4s\tremaining: 16s\n",
      "785:\tlearn: 0.0038826\ttotal: 10.4s\tremaining: 16s\n",
      "786:\tlearn: 0.0038507\ttotal: 10.4s\tremaining: 16s\n",
      "787:\tlearn: 0.0038470\ttotal: 10.4s\tremaining: 16s\n",
      "788:\tlearn: 0.0038374\ttotal: 10.4s\tremaining: 16s\n",
      "789:\tlearn: 0.0038365\ttotal: 10.4s\tremaining: 15.9s\n",
      "790:\tlearn: 0.0038332\ttotal: 10.4s\tremaining: 15.9s\n",
      "791:\tlearn: 0.0038326\ttotal: 10.4s\tremaining: 15.9s\n",
      "792:\tlearn: 0.0038296\ttotal: 10.4s\tremaining: 15.9s\n",
      "793:\tlearn: 0.0038291\ttotal: 10.5s\tremaining: 15.9s\n",
      "794:\tlearn: 0.0038228\ttotal: 10.5s\tremaining: 15.9s\n",
      "795:\tlearn: 0.0038215\ttotal: 10.5s\tremaining: 15.8s\n",
      "796:\tlearn: 0.0038176\ttotal: 10.5s\tremaining: 15.8s\n",
      "797:\tlearn: 0.0038021\ttotal: 10.5s\tremaining: 15.8s\n",
      "798:\tlearn: 0.0037972\ttotal: 10.5s\tremaining: 15.8s\n",
      "799:\tlearn: 0.0037909\ttotal: 10.5s\tremaining: 15.8s\n",
      "800:\tlearn: 0.0037828\ttotal: 10.5s\tremaining: 15.7s\n",
      "801:\tlearn: 0.0037763\ttotal: 10.5s\tremaining: 15.7s\n",
      "802:\tlearn: 0.0037701\ttotal: 10.5s\tremaining: 15.7s\n",
      "803:\tlearn: 0.0037615\ttotal: 10.6s\tremaining: 15.7s\n",
      "804:\tlearn: 0.0037541\ttotal: 10.6s\tremaining: 15.7s\n",
      "805:\tlearn: 0.0037521\ttotal: 10.6s\tremaining: 15.7s\n",
      "806:\tlearn: 0.0037503\ttotal: 10.6s\tremaining: 15.6s\n",
      "807:\tlearn: 0.0037475\ttotal: 10.6s\tremaining: 15.6s\n",
      "808:\tlearn: 0.0037446\ttotal: 10.6s\tremaining: 15.6s\n",
      "809:\tlearn: 0.0037341\ttotal: 10.6s\tremaining: 15.6s\n",
      "810:\tlearn: 0.0037219\ttotal: 10.6s\tremaining: 15.6s\n",
      "811:\tlearn: 0.0037209\ttotal: 10.6s\tremaining: 15.6s\n",
      "812:\tlearn: 0.0037157\ttotal: 10.6s\tremaining: 15.5s\n",
      "813:\tlearn: 0.0037118\ttotal: 10.7s\tremaining: 15.5s\n",
      "814:\tlearn: 0.0036998\ttotal: 10.7s\tremaining: 15.5s\n",
      "815:\tlearn: 0.0036939\ttotal: 10.7s\tremaining: 15.5s\n",
      "816:\tlearn: 0.0036913\ttotal: 10.7s\tremaining: 15.5s\n",
      "817:\tlearn: 0.0036847\ttotal: 10.7s\tremaining: 15.5s\n",
      "818:\tlearn: 0.0036817\ttotal: 10.7s\tremaining: 15.4s\n",
      "819:\tlearn: 0.0036776\ttotal: 10.7s\tremaining: 15.4s\n",
      "820:\tlearn: 0.0036691\ttotal: 10.7s\tremaining: 15.4s\n",
      "821:\tlearn: 0.0036638\ttotal: 10.7s\tremaining: 15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822:\tlearn: 0.0036586\ttotal: 10.8s\tremaining: 15.4s\n",
      "823:\tlearn: 0.0036390\ttotal: 10.8s\tremaining: 15.4s\n",
      "824:\tlearn: 0.0036371\ttotal: 10.8s\tremaining: 15.3s\n",
      "825:\tlearn: 0.0036359\ttotal: 10.8s\tremaining: 15.3s\n",
      "826:\tlearn: 0.0036337\ttotal: 10.8s\tremaining: 15.3s\n",
      "827:\tlearn: 0.0036179\ttotal: 10.8s\tremaining: 15.3s\n",
      "828:\tlearn: 0.0035980\ttotal: 10.8s\tremaining: 15.3s\n",
      "829:\tlearn: 0.0035948\ttotal: 10.8s\tremaining: 15.3s\n",
      "830:\tlearn: 0.0035911\ttotal: 10.8s\tremaining: 15.2s\n",
      "831:\tlearn: 0.0035874\ttotal: 10.8s\tremaining: 15.2s\n",
      "832:\tlearn: 0.0035819\ttotal: 10.9s\tremaining: 15.2s\n",
      "833:\tlearn: 0.0035795\ttotal: 10.9s\tremaining: 15.2s\n",
      "834:\tlearn: 0.0035751\ttotal: 10.9s\tremaining: 15.2s\n",
      "835:\tlearn: 0.0035669\ttotal: 10.9s\tremaining: 15.2s\n",
      "836:\tlearn: 0.0035654\ttotal: 10.9s\tremaining: 15.1s\n",
      "837:\tlearn: 0.0035592\ttotal: 10.9s\tremaining: 15.1s\n",
      "838:\tlearn: 0.0035564\ttotal: 10.9s\tremaining: 15.1s\n",
      "839:\tlearn: 0.0035550\ttotal: 10.9s\tremaining: 15.1s\n",
      "840:\tlearn: 0.0035468\ttotal: 10.9s\tremaining: 15.1s\n",
      "841:\tlearn: 0.0035421\ttotal: 11s\tremaining: 15.1s\n",
      "842:\tlearn: 0.0035329\ttotal: 11s\tremaining: 15.1s\n",
      "843:\tlearn: 0.0035306\ttotal: 11s\tremaining: 15s\n",
      "844:\tlearn: 0.0035298\ttotal: 11s\tremaining: 15s\n",
      "845:\tlearn: 0.0035184\ttotal: 11s\tremaining: 15s\n",
      "846:\tlearn: 0.0035173\ttotal: 11s\tremaining: 15s\n",
      "847:\tlearn: 0.0035094\ttotal: 11s\tremaining: 15s\n",
      "848:\tlearn: 0.0035045\ttotal: 11s\tremaining: 15s\n",
      "849:\tlearn: 0.0035012\ttotal: 11.1s\tremaining: 14.9s\n",
      "850:\tlearn: 0.0034886\ttotal: 11.1s\tremaining: 14.9s\n",
      "851:\tlearn: 0.0034699\ttotal: 11.1s\tremaining: 14.9s\n",
      "852:\tlearn: 0.0034674\ttotal: 11.1s\tremaining: 14.9s\n",
      "853:\tlearn: 0.0034645\ttotal: 11.1s\tremaining: 14.9s\n",
      "854:\tlearn: 0.0034506\ttotal: 11.1s\tremaining: 14.9s\n",
      "855:\tlearn: 0.0034349\ttotal: 11.1s\tremaining: 14.9s\n",
      "856:\tlearn: 0.0034342\ttotal: 11.1s\tremaining: 14.8s\n",
      "857:\tlearn: 0.0034299\ttotal: 11.1s\tremaining: 14.8s\n",
      "858:\tlearn: 0.0034249\ttotal: 11.1s\tremaining: 14.8s\n",
      "859:\tlearn: 0.0034210\ttotal: 11.2s\tremaining: 14.8s\n",
      "860:\tlearn: 0.0034175\ttotal: 11.2s\tremaining: 14.8s\n",
      "861:\tlearn: 0.0034123\ttotal: 11.2s\tremaining: 14.8s\n",
      "862:\tlearn: 0.0034095\ttotal: 11.2s\tremaining: 14.7s\n",
      "863:\tlearn: 0.0034062\ttotal: 11.2s\tremaining: 14.7s\n",
      "864:\tlearn: 0.0033967\ttotal: 11.2s\tremaining: 14.7s\n",
      "865:\tlearn: 0.0033939\ttotal: 11.2s\tremaining: 14.7s\n",
      "866:\tlearn: 0.0033859\ttotal: 11.2s\tremaining: 14.7s\n",
      "867:\tlearn: 0.0033806\ttotal: 11.2s\tremaining: 14.7s\n",
      "868:\tlearn: 0.0033739\ttotal: 11.2s\tremaining: 14.6s\n",
      "869:\tlearn: 0.0033672\ttotal: 11.3s\tremaining: 14.6s\n",
      "870:\tlearn: 0.0033413\ttotal: 11.3s\tremaining: 14.6s\n",
      "871:\tlearn: 0.0033383\ttotal: 11.3s\tremaining: 14.6s\n",
      "872:\tlearn: 0.0033262\ttotal: 11.3s\tremaining: 14.6s\n",
      "873:\tlearn: 0.0033240\ttotal: 11.3s\tremaining: 14.6s\n",
      "874:\tlearn: 0.0033209\ttotal: 11.3s\tremaining: 14.5s\n",
      "875:\tlearn: 0.0033173\ttotal: 11.3s\tremaining: 14.5s\n",
      "876:\tlearn: 0.0033166\ttotal: 11.3s\tremaining: 14.5s\n",
      "877:\tlearn: 0.0033113\ttotal: 11.3s\tremaining: 14.5s\n",
      "878:\tlearn: 0.0033037\ttotal: 11.4s\tremaining: 14.5s\n",
      "879:\tlearn: 0.0032992\ttotal: 11.4s\tremaining: 14.5s\n",
      "880:\tlearn: 0.0032967\ttotal: 11.4s\tremaining: 14.5s\n",
      "881:\tlearn: 0.0032923\ttotal: 11.4s\tremaining: 14.4s\n",
      "882:\tlearn: 0.0032863\ttotal: 11.4s\tremaining: 14.4s\n",
      "883:\tlearn: 0.0032841\ttotal: 11.4s\tremaining: 14.4s\n",
      "884:\tlearn: 0.0032796\ttotal: 11.4s\tremaining: 14.4s\n",
      "885:\tlearn: 0.0032680\ttotal: 11.4s\tremaining: 14.4s\n",
      "886:\tlearn: 0.0032522\ttotal: 11.5s\tremaining: 14.4s\n",
      "887:\tlearn: 0.0032483\ttotal: 11.5s\tremaining: 14.4s\n",
      "888:\tlearn: 0.0032468\ttotal: 11.5s\tremaining: 14.4s\n",
      "889:\tlearn: 0.0032422\ttotal: 11.5s\tremaining: 14.3s\n",
      "890:\tlearn: 0.0032371\ttotal: 11.5s\tremaining: 14.3s\n",
      "891:\tlearn: 0.0032351\ttotal: 11.5s\tremaining: 14.3s\n",
      "892:\tlearn: 0.0032301\ttotal: 11.5s\tremaining: 14.3s\n",
      "893:\tlearn: 0.0032275\ttotal: 11.5s\tremaining: 14.3s\n",
      "894:\tlearn: 0.0032179\ttotal: 11.6s\tremaining: 14.3s\n",
      "895:\tlearn: 0.0032126\ttotal: 11.6s\tremaining: 14.3s\n",
      "896:\tlearn: 0.0032109\ttotal: 11.6s\tremaining: 14.3s\n",
      "897:\tlearn: 0.0032096\ttotal: 11.6s\tremaining: 14.2s\n",
      "898:\tlearn: 0.0032084\ttotal: 11.6s\tremaining: 14.2s\n",
      "899:\tlearn: 0.0032061\ttotal: 11.6s\tremaining: 14.2s\n",
      "900:\tlearn: 0.0032030\ttotal: 11.6s\tremaining: 14.2s\n",
      "901:\tlearn: 0.0032015\ttotal: 11.6s\tremaining: 14.2s\n",
      "902:\tlearn: 0.0031835\ttotal: 11.7s\tremaining: 14.2s\n",
      "903:\tlearn: 0.0031808\ttotal: 11.7s\tremaining: 14.2s\n",
      "904:\tlearn: 0.0031741\ttotal: 11.7s\tremaining: 14.2s\n",
      "905:\tlearn: 0.0031735\ttotal: 11.7s\tremaining: 14.1s\n",
      "906:\tlearn: 0.0031732\ttotal: 11.7s\tremaining: 14.1s\n",
      "907:\tlearn: 0.0031718\ttotal: 11.7s\tremaining: 14.1s\n",
      "908:\tlearn: 0.0031696\ttotal: 11.8s\tremaining: 14.1s\n",
      "909:\tlearn: 0.0031641\ttotal: 11.8s\tremaining: 14.1s\n",
      "910:\tlearn: 0.0031604\ttotal: 11.8s\tremaining: 14.1s\n",
      "911:\tlearn: 0.0031574\ttotal: 11.8s\tremaining: 14.1s\n",
      "912:\tlearn: 0.0031569\ttotal: 11.8s\tremaining: 14.1s\n",
      "913:\tlearn: 0.0031562\ttotal: 11.8s\tremaining: 14.1s\n",
      "914:\tlearn: 0.0031535\ttotal: 11.9s\tremaining: 14.1s\n",
      "915:\tlearn: 0.0031507\ttotal: 11.9s\tremaining: 14s\n",
      "916:\tlearn: 0.0031461\ttotal: 11.9s\tremaining: 14s\n",
      "917:\tlearn: 0.0031413\ttotal: 11.9s\tremaining: 14s\n",
      "918:\tlearn: 0.0031330\ttotal: 11.9s\tremaining: 14s\n",
      "919:\tlearn: 0.0031324\ttotal: 11.9s\tremaining: 14s\n",
      "920:\tlearn: 0.0031268\ttotal: 11.9s\tremaining: 14s\n",
      "921:\tlearn: 0.0031234\ttotal: 11.9s\tremaining: 14s\n",
      "922:\tlearn: 0.0031212\ttotal: 12s\tremaining: 14s\n",
      "923:\tlearn: 0.0031171\ttotal: 12s\tremaining: 13.9s\n",
      "924:\tlearn: 0.0030982\ttotal: 12s\tremaining: 13.9s\n",
      "925:\tlearn: 0.0030964\ttotal: 12s\tremaining: 13.9s\n",
      "926:\tlearn: 0.0030920\ttotal: 12s\tremaining: 13.9s\n",
      "927:\tlearn: 0.0030883\ttotal: 12s\tremaining: 13.9s\n",
      "928:\tlearn: 0.0030811\ttotal: 12s\tremaining: 13.9s\n",
      "929:\tlearn: 0.0030738\ttotal: 12.1s\tremaining: 13.9s\n",
      "930:\tlearn: 0.0030699\ttotal: 12.1s\tremaining: 13.9s\n",
      "931:\tlearn: 0.0030685\ttotal: 12.1s\tremaining: 13.8s\n",
      "932:\tlearn: 0.0030680\ttotal: 12.1s\tremaining: 13.8s\n",
      "933:\tlearn: 0.0030363\ttotal: 12.1s\tremaining: 13.8s\n",
      "934:\tlearn: 0.0030344\ttotal: 12.1s\tremaining: 13.8s\n",
      "935:\tlearn: 0.0030257\ttotal: 12.1s\tremaining: 13.8s\n",
      "936:\tlearn: 0.0030242\ttotal: 12.2s\tremaining: 13.8s\n",
      "937:\tlearn: 0.0030225\ttotal: 12.2s\tremaining: 13.8s\n",
      "938:\tlearn: 0.0030151\ttotal: 12.2s\tremaining: 13.8s\n",
      "939:\tlearn: 0.0030147\ttotal: 12.2s\tremaining: 13.8s\n",
      "940:\tlearn: 0.0030118\ttotal: 12.2s\tremaining: 13.8s\n",
      "941:\tlearn: 0.0030102\ttotal: 12.2s\tremaining: 13.7s\n",
      "942:\tlearn: 0.0030058\ttotal: 12.3s\tremaining: 13.7s\n",
      "943:\tlearn: 0.0030029\ttotal: 12.3s\tremaining: 13.7s\n",
      "944:\tlearn: 0.0029977\ttotal: 12.3s\tremaining: 13.7s\n",
      "945:\tlearn: 0.0029955\ttotal: 12.3s\tremaining: 13.7s\n",
      "946:\tlearn: 0.0029847\ttotal: 12.3s\tremaining: 13.7s\n",
      "947:\tlearn: 0.0029804\ttotal: 12.4s\tremaining: 13.7s\n",
      "948:\tlearn: 0.0029783\ttotal: 12.4s\tremaining: 13.7s\n",
      "949:\tlearn: 0.0029704\ttotal: 12.4s\tremaining: 13.7s\n",
      "950:\tlearn: 0.0029659\ttotal: 12.4s\tremaining: 13.7s\n",
      "951:\tlearn: 0.0029621\ttotal: 12.4s\tremaining: 13.7s\n",
      "952:\tlearn: 0.0029591\ttotal: 12.4s\tremaining: 13.6s\n",
      "953:\tlearn: 0.0029547\ttotal: 12.4s\tremaining: 13.6s\n",
      "954:\tlearn: 0.0029530\ttotal: 12.4s\tremaining: 13.6s\n",
      "955:\tlearn: 0.0029448\ttotal: 12.5s\tremaining: 13.6s\n",
      "956:\tlearn: 0.0029421\ttotal: 12.5s\tremaining: 13.6s\n",
      "957:\tlearn: 0.0029376\ttotal: 12.5s\tremaining: 13.6s\n",
      "958:\tlearn: 0.0029369\ttotal: 12.5s\tremaining: 13.6s\n",
      "959:\tlearn: 0.0029326\ttotal: 12.5s\tremaining: 13.5s\n",
      "960:\tlearn: 0.0029265\ttotal: 12.5s\tremaining: 13.5s\n",
      "961:\tlearn: 0.0029242\ttotal: 12.5s\tremaining: 13.5s\n",
      "962:\tlearn: 0.0029193\ttotal: 12.5s\tremaining: 13.5s\n",
      "963:\tlearn: 0.0029130\ttotal: 12.6s\tremaining: 13.5s\n",
      "964:\tlearn: 0.0029092\ttotal: 12.6s\tremaining: 13.5s\n",
      "965:\tlearn: 0.0028986\ttotal: 12.6s\tremaining: 13.5s\n",
      "966:\tlearn: 0.0028964\ttotal: 12.6s\tremaining: 13.5s\n",
      "967:\tlearn: 0.0028891\ttotal: 12.6s\tremaining: 13.4s\n",
      "968:\tlearn: 0.0028758\ttotal: 12.6s\tremaining: 13.4s\n",
      "969:\tlearn: 0.0028738\ttotal: 12.6s\tremaining: 13.4s\n",
      "970:\tlearn: 0.0028709\ttotal: 12.6s\tremaining: 13.4s\n",
      "971:\tlearn: 0.0028686\ttotal: 12.7s\tremaining: 13.4s\n",
      "972:\tlearn: 0.0028674\ttotal: 12.7s\tremaining: 13.4s\n",
      "973:\tlearn: 0.0028582\ttotal: 12.7s\tremaining: 13.4s\n",
      "974:\tlearn: 0.0028552\ttotal: 12.7s\tremaining: 13.3s\n",
      "975:\tlearn: 0.0028544\ttotal: 12.7s\tremaining: 13.3s\n",
      "976:\tlearn: 0.0028524\ttotal: 12.7s\tremaining: 13.3s\n",
      "977:\tlearn: 0.0028501\ttotal: 12.7s\tremaining: 13.3s\n",
      "978:\tlearn: 0.0028495\ttotal: 12.7s\tremaining: 13.3s\n",
      "979:\tlearn: 0.0028464\ttotal: 12.8s\tremaining: 13.3s\n",
      "980:\tlearn: 0.0028446\ttotal: 12.8s\tremaining: 13.3s\n",
      "981:\tlearn: 0.0028376\ttotal: 12.8s\tremaining: 13.2s\n",
      "982:\tlearn: 0.0028370\ttotal: 12.8s\tremaining: 13.2s\n",
      "983:\tlearn: 0.0028329\ttotal: 12.8s\tremaining: 13.2s\n",
      "984:\tlearn: 0.0028317\ttotal: 12.8s\tremaining: 13.2s\n",
      "985:\tlearn: 0.0028250\ttotal: 12.8s\tremaining: 13.2s\n",
      "986:\tlearn: 0.0028172\ttotal: 12.8s\tremaining: 13.2s\n",
      "987:\tlearn: 0.0028159\ttotal: 12.8s\tremaining: 13.2s\n",
      "988:\tlearn: 0.0028103\ttotal: 12.9s\tremaining: 13.1s\n",
      "989:\tlearn: 0.0028084\ttotal: 12.9s\tremaining: 13.1s\n",
      "990:\tlearn: 0.0027979\ttotal: 12.9s\tremaining: 13.1s\n",
      "991:\tlearn: 0.0027945\ttotal: 12.9s\tremaining: 13.1s\n",
      "992:\tlearn: 0.0027891\ttotal: 12.9s\tremaining: 13.1s\n",
      "993:\tlearn: 0.0027818\ttotal: 12.9s\tremaining: 13.1s\n",
      "994:\tlearn: 0.0027780\ttotal: 12.9s\tremaining: 13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995:\tlearn: 0.0027710\ttotal: 12.9s\tremaining: 13.1s\n",
      "996:\tlearn: 0.0027681\ttotal: 13s\tremaining: 13s\n",
      "997:\tlearn: 0.0027675\ttotal: 13s\tremaining: 13s\n",
      "998:\tlearn: 0.0027643\ttotal: 13s\tremaining: 13s\n",
      "999:\tlearn: 0.0027603\ttotal: 13s\tremaining: 13s\n",
      "1000:\tlearn: 0.0027550\ttotal: 13s\tremaining: 13s\n",
      "1001:\tlearn: 0.0027525\ttotal: 13s\tremaining: 13s\n",
      "1002:\tlearn: 0.0027476\ttotal: 13s\tremaining: 13s\n",
      "1003:\tlearn: 0.0027448\ttotal: 13s\tremaining: 12.9s\n",
      "1004:\tlearn: 0.0027396\ttotal: 13.1s\tremaining: 12.9s\n",
      "1005:\tlearn: 0.0027384\ttotal: 13.1s\tremaining: 12.9s\n",
      "1006:\tlearn: 0.0027379\ttotal: 13.1s\tremaining: 12.9s\n",
      "1007:\tlearn: 0.0027290\ttotal: 13.1s\tremaining: 12.9s\n",
      "1008:\tlearn: 0.0027285\ttotal: 13.1s\tremaining: 12.9s\n",
      "1009:\tlearn: 0.0027240\ttotal: 13.1s\tremaining: 12.9s\n",
      "1010:\tlearn: 0.0027233\ttotal: 13.1s\tremaining: 12.8s\n",
      "1011:\tlearn: 0.0027210\ttotal: 13.1s\tremaining: 12.8s\n",
      "1012:\tlearn: 0.0027198\ttotal: 13.2s\tremaining: 12.8s\n",
      "1013:\tlearn: 0.0027118\ttotal: 13.2s\tremaining: 12.8s\n",
      "1014:\tlearn: 0.0027066\ttotal: 13.2s\tremaining: 12.8s\n",
      "1015:\tlearn: 0.0027060\ttotal: 13.2s\tremaining: 12.8s\n",
      "1016:\tlearn: 0.0027045\ttotal: 13.2s\tremaining: 12.8s\n",
      "1017:\tlearn: 0.0027039\ttotal: 13.2s\tremaining: 12.8s\n",
      "1018:\tlearn: 0.0026996\ttotal: 13.2s\tremaining: 12.7s\n",
      "1019:\tlearn: 0.0026955\ttotal: 13.3s\tremaining: 12.7s\n",
      "1020:\tlearn: 0.0026933\ttotal: 13.3s\tremaining: 12.7s\n",
      "1021:\tlearn: 0.0026916\ttotal: 13.3s\tremaining: 12.7s\n",
      "1022:\tlearn: 0.0026628\ttotal: 13.3s\tremaining: 12.7s\n",
      "1023:\tlearn: 0.0026578\ttotal: 13.3s\tremaining: 12.7s\n",
      "1024:\tlearn: 0.0026569\ttotal: 13.3s\tremaining: 12.7s\n",
      "1025:\tlearn: 0.0026472\ttotal: 13.3s\tremaining: 12.7s\n",
      "1026:\tlearn: 0.0026455\ttotal: 13.3s\tremaining: 12.6s\n",
      "1027:\tlearn: 0.0026388\ttotal: 13.3s\tremaining: 12.6s\n",
      "1028:\tlearn: 0.0026375\ttotal: 13.4s\tremaining: 12.6s\n",
      "1029:\tlearn: 0.0026367\ttotal: 13.4s\tremaining: 12.6s\n",
      "1030:\tlearn: 0.0026351\ttotal: 13.4s\tremaining: 12.6s\n",
      "1031:\tlearn: 0.0026298\ttotal: 13.4s\tremaining: 12.6s\n",
      "1032:\tlearn: 0.0026205\ttotal: 13.4s\tremaining: 12.5s\n",
      "1033:\tlearn: 0.0026175\ttotal: 13.4s\tremaining: 12.5s\n",
      "1034:\tlearn: 0.0026111\ttotal: 13.4s\tremaining: 12.5s\n",
      "1035:\tlearn: 0.0026103\ttotal: 13.4s\tremaining: 12.5s\n",
      "1036:\tlearn: 0.0026007\ttotal: 13.5s\tremaining: 12.5s\n",
      "1037:\tlearn: 0.0025970\ttotal: 13.5s\tremaining: 12.5s\n",
      "1038:\tlearn: 0.0025739\ttotal: 13.5s\tremaining: 12.5s\n",
      "1039:\tlearn: 0.0025637\ttotal: 13.5s\tremaining: 12.5s\n",
      "1040:\tlearn: 0.0025602\ttotal: 13.5s\tremaining: 12.4s\n",
      "1041:\tlearn: 0.0025576\ttotal: 13.5s\tremaining: 12.4s\n",
      "1042:\tlearn: 0.0025516\ttotal: 13.5s\tremaining: 12.4s\n",
      "1043:\tlearn: 0.0025385\ttotal: 13.6s\tremaining: 12.4s\n",
      "1044:\tlearn: 0.0025350\ttotal: 13.6s\tremaining: 12.4s\n",
      "1045:\tlearn: 0.0025348\ttotal: 13.6s\tremaining: 12.4s\n",
      "1046:\tlearn: 0.0025268\ttotal: 13.6s\tremaining: 12.4s\n",
      "1047:\tlearn: 0.0025231\ttotal: 13.6s\tremaining: 12.4s\n",
      "1048:\tlearn: 0.0025215\ttotal: 13.6s\tremaining: 12.3s\n",
      "1049:\tlearn: 0.0025179\ttotal: 13.6s\tremaining: 12.3s\n",
      "1050:\tlearn: 0.0025163\ttotal: 13.6s\tremaining: 12.3s\n",
      "1051:\tlearn: 0.0025097\ttotal: 13.6s\tremaining: 12.3s\n",
      "1052:\tlearn: 0.0025065\ttotal: 13.7s\tremaining: 12.3s\n",
      "1053:\tlearn: 0.0025045\ttotal: 13.7s\tremaining: 12.3s\n",
      "1054:\tlearn: 0.0025032\ttotal: 13.7s\tremaining: 12.3s\n",
      "1055:\tlearn: 0.0024988\ttotal: 13.7s\tremaining: 12.2s\n",
      "1056:\tlearn: 0.0024965\ttotal: 13.7s\tremaining: 12.2s\n",
      "1057:\tlearn: 0.0024922\ttotal: 13.7s\tremaining: 12.2s\n",
      "1058:\tlearn: 0.0024827\ttotal: 13.7s\tremaining: 12.2s\n",
      "1059:\tlearn: 0.0024787\ttotal: 13.7s\tremaining: 12.2s\n",
      "1060:\tlearn: 0.0024773\ttotal: 13.7s\tremaining: 12.2s\n",
      "1061:\tlearn: 0.0024764\ttotal: 13.8s\tremaining: 12.2s\n",
      "1062:\tlearn: 0.0024739\ttotal: 13.8s\tremaining: 12.1s\n",
      "1063:\tlearn: 0.0024726\ttotal: 13.8s\tremaining: 12.1s\n",
      "1064:\tlearn: 0.0024717\ttotal: 13.8s\tremaining: 12.1s\n",
      "1065:\tlearn: 0.0024701\ttotal: 13.8s\tremaining: 12.1s\n",
      "1066:\tlearn: 0.0024610\ttotal: 13.8s\tremaining: 12.1s\n",
      "1067:\tlearn: 0.0024598\ttotal: 13.8s\tremaining: 12.1s\n",
      "1068:\tlearn: 0.0024554\ttotal: 13.9s\tremaining: 12.1s\n",
      "1069:\tlearn: 0.0024521\ttotal: 13.9s\tremaining: 12.1s\n",
      "1070:\tlearn: 0.0024396\ttotal: 13.9s\tremaining: 12s\n",
      "1071:\tlearn: 0.0024382\ttotal: 13.9s\tremaining: 12s\n",
      "1072:\tlearn: 0.0024359\ttotal: 13.9s\tremaining: 12s\n",
      "1073:\tlearn: 0.0024344\ttotal: 13.9s\tremaining: 12s\n",
      "1074:\tlearn: 0.0024340\ttotal: 13.9s\tremaining: 12s\n",
      "1075:\tlearn: 0.0024323\ttotal: 14s\tremaining: 12s\n",
      "1076:\tlearn: 0.0024314\ttotal: 14s\tremaining: 12s\n",
      "1077:\tlearn: 0.0024306\ttotal: 14s\tremaining: 12s\n",
      "1078:\tlearn: 0.0024253\ttotal: 14s\tremaining: 11.9s\n",
      "1079:\tlearn: 0.0024219\ttotal: 14s\tremaining: 11.9s\n",
      "1080:\tlearn: 0.0024188\ttotal: 14s\tremaining: 11.9s\n",
      "1081:\tlearn: 0.0024171\ttotal: 14s\tremaining: 11.9s\n",
      "1082:\tlearn: 0.0024142\ttotal: 14.1s\tremaining: 11.9s\n",
      "1083:\tlearn: 0.0024077\ttotal: 14.1s\tremaining: 11.9s\n",
      "1084:\tlearn: 0.0024034\ttotal: 14.1s\tremaining: 11.9s\n",
      "1085:\tlearn: 0.0023999\ttotal: 14.1s\tremaining: 11.9s\n",
      "1086:\tlearn: 0.0023947\ttotal: 14.1s\tremaining: 11.8s\n",
      "1087:\tlearn: 0.0023909\ttotal: 14.1s\tremaining: 11.8s\n",
      "1088:\tlearn: 0.0023884\ttotal: 14.1s\tremaining: 11.8s\n",
      "1089:\tlearn: 0.0023879\ttotal: 14.1s\tremaining: 11.8s\n",
      "1090:\tlearn: 0.0023829\ttotal: 14.1s\tremaining: 11.8s\n",
      "1091:\tlearn: 0.0023736\ttotal: 14.2s\tremaining: 11.8s\n",
      "1092:\tlearn: 0.0023708\ttotal: 14.2s\tremaining: 11.8s\n",
      "1093:\tlearn: 0.0023693\ttotal: 14.2s\tremaining: 11.7s\n",
      "1094:\tlearn: 0.0023656\ttotal: 14.2s\tremaining: 11.7s\n",
      "1095:\tlearn: 0.0023645\ttotal: 14.2s\tremaining: 11.7s\n",
      "1096:\tlearn: 0.0023619\ttotal: 14.2s\tremaining: 11.7s\n",
      "1097:\tlearn: 0.0023602\ttotal: 14.2s\tremaining: 11.7s\n",
      "1098:\tlearn: 0.0023507\ttotal: 14.2s\tremaining: 11.7s\n",
      "1099:\tlearn: 0.0023466\ttotal: 14.2s\tremaining: 11.7s\n",
      "1100:\tlearn: 0.0023329\ttotal: 14.3s\tremaining: 11.6s\n",
      "1101:\tlearn: 0.0023309\ttotal: 14.3s\tremaining: 11.6s\n",
      "1102:\tlearn: 0.0023271\ttotal: 14.3s\tremaining: 11.6s\n",
      "1103:\tlearn: 0.0023259\ttotal: 14.3s\tremaining: 11.6s\n",
      "1104:\tlearn: 0.0023243\ttotal: 14.3s\tremaining: 11.6s\n",
      "1105:\tlearn: 0.0023181\ttotal: 14.3s\tremaining: 11.6s\n",
      "1106:\tlearn: 0.0023168\ttotal: 14.3s\tremaining: 11.6s\n",
      "1107:\tlearn: 0.0023158\ttotal: 14.3s\tremaining: 11.5s\n",
      "1108:\tlearn: 0.0023137\ttotal: 14.4s\tremaining: 11.5s\n",
      "1109:\tlearn: 0.0023123\ttotal: 14.4s\tremaining: 11.5s\n",
      "1110:\tlearn: 0.0023092\ttotal: 14.4s\tremaining: 11.5s\n",
      "1111:\tlearn: 0.0023072\ttotal: 14.4s\tremaining: 11.5s\n",
      "1112:\tlearn: 0.0023004\ttotal: 14.4s\tremaining: 11.5s\n",
      "1113:\tlearn: 0.0022934\ttotal: 14.4s\tremaining: 11.5s\n",
      "1114:\tlearn: 0.0022922\ttotal: 14.4s\tremaining: 11.5s\n",
      "1115:\tlearn: 0.0022905\ttotal: 14.4s\tremaining: 11.4s\n",
      "1116:\tlearn: 0.0022872\ttotal: 14.4s\tremaining: 11.4s\n",
      "1117:\tlearn: 0.0022861\ttotal: 14.5s\tremaining: 11.4s\n",
      "1118:\tlearn: 0.0022832\ttotal: 14.5s\tremaining: 11.4s\n",
      "1119:\tlearn: 0.0022801\ttotal: 14.5s\tremaining: 11.4s\n",
      "1120:\tlearn: 0.0022763\ttotal: 14.5s\tremaining: 11.4s\n",
      "1121:\tlearn: 0.0022683\ttotal: 14.5s\tremaining: 11.4s\n",
      "1122:\tlearn: 0.0022655\ttotal: 14.5s\tremaining: 11.3s\n",
      "1123:\tlearn: 0.0022603\ttotal: 14.5s\tremaining: 11.3s\n",
      "1124:\tlearn: 0.0022550\ttotal: 14.5s\tremaining: 11.3s\n",
      "1125:\tlearn: 0.0022484\ttotal: 14.6s\tremaining: 11.3s\n",
      "1126:\tlearn: 0.0022469\ttotal: 14.6s\tremaining: 11.3s\n",
      "1127:\tlearn: 0.0022445\ttotal: 14.6s\tremaining: 11.3s\n",
      "1128:\tlearn: 0.0022435\ttotal: 14.6s\tremaining: 11.3s\n",
      "1129:\tlearn: 0.0022375\ttotal: 14.6s\tremaining: 11.2s\n",
      "1130:\tlearn: 0.0022364\ttotal: 14.6s\tremaining: 11.2s\n",
      "1131:\tlearn: 0.0022327\ttotal: 14.6s\tremaining: 11.2s\n",
      "1132:\tlearn: 0.0022293\ttotal: 14.6s\tremaining: 11.2s\n",
      "1133:\tlearn: 0.0022268\ttotal: 14.6s\tremaining: 11.2s\n",
      "1134:\tlearn: 0.0022202\ttotal: 14.7s\tremaining: 11.2s\n",
      "1135:\tlearn: 0.0022195\ttotal: 14.7s\tremaining: 11.2s\n",
      "1136:\tlearn: 0.0022177\ttotal: 14.7s\tremaining: 11.1s\n",
      "1137:\tlearn: 0.0022171\ttotal: 14.7s\tremaining: 11.1s\n",
      "1138:\tlearn: 0.0022150\ttotal: 14.7s\tremaining: 11.1s\n",
      "1139:\tlearn: 0.0022132\ttotal: 14.7s\tremaining: 11.1s\n",
      "1140:\tlearn: 0.0022121\ttotal: 14.7s\tremaining: 11.1s\n",
      "1141:\tlearn: 0.0022102\ttotal: 14.7s\tremaining: 11.1s\n",
      "1142:\tlearn: 0.0022040\ttotal: 14.7s\tremaining: 11.1s\n",
      "1143:\tlearn: 0.0021996\ttotal: 14.8s\tremaining: 11s\n",
      "1144:\tlearn: 0.0021992\ttotal: 14.8s\tremaining: 11s\n",
      "1145:\tlearn: 0.0021948\ttotal: 14.8s\tremaining: 11s\n",
      "1146:\tlearn: 0.0021934\ttotal: 14.8s\tremaining: 11s\n",
      "1147:\tlearn: 0.0021882\ttotal: 14.8s\tremaining: 11s\n",
      "1148:\tlearn: 0.0021839\ttotal: 14.8s\tremaining: 11s\n",
      "1149:\tlearn: 0.0021828\ttotal: 14.8s\tremaining: 11s\n",
      "1150:\tlearn: 0.0021817\ttotal: 14.8s\tremaining: 11s\n",
      "1151:\tlearn: 0.0021807\ttotal: 14.9s\tremaining: 10.9s\n",
      "1152:\tlearn: 0.0021755\ttotal: 14.9s\tremaining: 10.9s\n",
      "1153:\tlearn: 0.0021743\ttotal: 14.9s\tremaining: 10.9s\n",
      "1154:\tlearn: 0.0021712\ttotal: 14.9s\tremaining: 10.9s\n",
      "1155:\tlearn: 0.0021667\ttotal: 14.9s\tremaining: 10.9s\n",
      "1156:\tlearn: 0.0021639\ttotal: 14.9s\tremaining: 10.9s\n",
      "1157:\tlearn: 0.0021579\ttotal: 15s\tremaining: 10.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158:\tlearn: 0.0021548\ttotal: 15s\tremaining: 10.9s\n",
      "1159:\tlearn: 0.0021526\ttotal: 15s\tremaining: 10.9s\n",
      "1160:\tlearn: 0.0021510\ttotal: 15s\tremaining: 10.8s\n",
      "1161:\tlearn: 0.0021436\ttotal: 15s\tremaining: 10.8s\n",
      "1162:\tlearn: 0.0021410\ttotal: 15s\tremaining: 10.8s\n",
      "1163:\tlearn: 0.0021372\ttotal: 15s\tremaining: 10.8s\n",
      "1164:\tlearn: 0.0021352\ttotal: 15.1s\tremaining: 10.8s\n",
      "1165:\tlearn: 0.0021343\ttotal: 15.1s\tremaining: 10.8s\n",
      "1166:\tlearn: 0.0021335\ttotal: 15.1s\tremaining: 10.8s\n",
      "1167:\tlearn: 0.0021285\ttotal: 15.1s\tremaining: 10.8s\n",
      "1168:\tlearn: 0.0021240\ttotal: 15.1s\tremaining: 10.7s\n",
      "1169:\tlearn: 0.0021235\ttotal: 15.1s\tremaining: 10.7s\n",
      "1170:\tlearn: 0.0021209\ttotal: 15.1s\tremaining: 10.7s\n",
      "1171:\tlearn: 0.0021206\ttotal: 15.1s\tremaining: 10.7s\n",
      "1172:\tlearn: 0.0021163\ttotal: 15.2s\tremaining: 10.7s\n",
      "1173:\tlearn: 0.0021139\ttotal: 15.2s\tremaining: 10.7s\n",
      "1174:\tlearn: 0.0021105\ttotal: 15.2s\tremaining: 10.7s\n",
      "1175:\tlearn: 0.0021084\ttotal: 15.2s\tremaining: 10.7s\n",
      "1176:\tlearn: 0.0021070\ttotal: 15.2s\tremaining: 10.6s\n",
      "1177:\tlearn: 0.0021054\ttotal: 15.2s\tremaining: 10.6s\n",
      "1178:\tlearn: 0.0021003\ttotal: 15.2s\tremaining: 10.6s\n",
      "1179:\tlearn: 0.0020968\ttotal: 15.3s\tremaining: 10.6s\n",
      "1180:\tlearn: 0.0020886\ttotal: 15.3s\tremaining: 10.6s\n",
      "1181:\tlearn: 0.0020872\ttotal: 15.3s\tremaining: 10.6s\n",
      "1182:\tlearn: 0.0020831\ttotal: 15.3s\tremaining: 10.6s\n",
      "1183:\tlearn: 0.0020811\ttotal: 15.3s\tremaining: 10.5s\n",
      "1184:\tlearn: 0.0020798\ttotal: 15.3s\tremaining: 10.5s\n",
      "1185:\tlearn: 0.0020796\ttotal: 15.3s\tremaining: 10.5s\n",
      "1186:\tlearn: 0.0020783\ttotal: 15.3s\tremaining: 10.5s\n",
      "1187:\tlearn: 0.0020743\ttotal: 15.3s\tremaining: 10.5s\n",
      "1188:\tlearn: 0.0020738\ttotal: 15.4s\tremaining: 10.5s\n",
      "1189:\tlearn: 0.0020687\ttotal: 15.4s\tremaining: 10.5s\n",
      "1190:\tlearn: 0.0020682\ttotal: 15.4s\tremaining: 10.4s\n",
      "1191:\tlearn: 0.0020674\ttotal: 15.4s\tremaining: 10.4s\n",
      "1192:\tlearn: 0.0020663\ttotal: 15.4s\tremaining: 10.4s\n",
      "1193:\tlearn: 0.0020659\ttotal: 15.4s\tremaining: 10.4s\n",
      "1194:\tlearn: 0.0020650\ttotal: 15.4s\tremaining: 10.4s\n",
      "1195:\tlearn: 0.0020611\ttotal: 15.4s\tremaining: 10.4s\n",
      "1196:\tlearn: 0.0020594\ttotal: 15.4s\tremaining: 10.4s\n",
      "1197:\tlearn: 0.0020575\ttotal: 15.5s\tremaining: 10.3s\n",
      "1198:\tlearn: 0.0020516\ttotal: 15.5s\tremaining: 10.3s\n",
      "1199:\tlearn: 0.0020481\ttotal: 15.5s\tremaining: 10.3s\n",
      "1200:\tlearn: 0.0020469\ttotal: 15.5s\tremaining: 10.3s\n",
      "1201:\tlearn: 0.0020434\ttotal: 15.5s\tremaining: 10.3s\n",
      "1202:\tlearn: 0.0020348\ttotal: 15.5s\tremaining: 10.3s\n",
      "1203:\tlearn: 0.0020311\ttotal: 15.5s\tremaining: 10.3s\n",
      "1204:\tlearn: 0.0020296\ttotal: 15.5s\tremaining: 10.3s\n",
      "1205:\tlearn: 0.0020272\ttotal: 15.6s\tremaining: 10.2s\n",
      "1206:\tlearn: 0.0020263\ttotal: 15.6s\tremaining: 10.2s\n",
      "1207:\tlearn: 0.0020254\ttotal: 15.6s\tremaining: 10.2s\n",
      "1208:\tlearn: 0.0020226\ttotal: 15.6s\tremaining: 10.2s\n",
      "1209:\tlearn: 0.0020217\ttotal: 15.6s\tremaining: 10.2s\n",
      "1210:\tlearn: 0.0020183\ttotal: 15.6s\tremaining: 10.2s\n",
      "1211:\tlearn: 0.0020177\ttotal: 15.6s\tremaining: 10.2s\n",
      "1212:\tlearn: 0.0020149\ttotal: 15.6s\tremaining: 10.1s\n",
      "1213:\tlearn: 0.0020126\ttotal: 15.6s\tremaining: 10.1s\n",
      "1214:\tlearn: 0.0020088\ttotal: 15.7s\tremaining: 10.1s\n",
      "1215:\tlearn: 0.0020039\ttotal: 15.7s\tremaining: 10.1s\n",
      "1216:\tlearn: 0.0019983\ttotal: 15.7s\tremaining: 10.1s\n",
      "1217:\tlearn: 0.0019949\ttotal: 15.7s\tremaining: 10.1s\n",
      "1218:\tlearn: 0.0019945\ttotal: 15.7s\tremaining: 10.1s\n",
      "1219:\tlearn: 0.0019869\ttotal: 15.7s\tremaining: 10.1s\n",
      "1220:\tlearn: 0.0019851\ttotal: 15.7s\tremaining: 10s\n",
      "1221:\tlearn: 0.0019735\ttotal: 15.8s\tremaining: 10s\n",
      "1222:\tlearn: 0.0019725\ttotal: 15.8s\tremaining: 10s\n",
      "1223:\tlearn: 0.0019689\ttotal: 15.8s\tremaining: 10s\n",
      "1224:\tlearn: 0.0019664\ttotal: 15.8s\tremaining: 9.99s\n",
      "1225:\tlearn: 0.0019635\ttotal: 15.8s\tremaining: 9.98s\n",
      "1226:\tlearn: 0.0019628\ttotal: 15.8s\tremaining: 9.96s\n",
      "1227:\tlearn: 0.0019612\ttotal: 15.8s\tremaining: 9.95s\n",
      "1228:\tlearn: 0.0019602\ttotal: 15.8s\tremaining: 9.94s\n",
      "1229:\tlearn: 0.0019547\ttotal: 15.9s\tremaining: 9.93s\n",
      "1230:\tlearn: 0.0019532\ttotal: 15.9s\tremaining: 9.91s\n",
      "1231:\tlearn: 0.0019504\ttotal: 15.9s\tremaining: 9.9s\n",
      "1232:\tlearn: 0.0019494\ttotal: 15.9s\tremaining: 9.88s\n",
      "1233:\tlearn: 0.0019491\ttotal: 15.9s\tremaining: 9.88s\n",
      "1234:\tlearn: 0.0019452\ttotal: 15.9s\tremaining: 9.87s\n",
      "1235:\tlearn: 0.0019415\ttotal: 15.9s\tremaining: 9.86s\n",
      "1236:\tlearn: 0.0019404\ttotal: 16s\tremaining: 9.84s\n",
      "1237:\tlearn: 0.0019399\ttotal: 16s\tremaining: 9.83s\n",
      "1238:\tlearn: 0.0019355\ttotal: 16s\tremaining: 9.81s\n",
      "1239:\tlearn: 0.0019348\ttotal: 16s\tremaining: 9.8s\n",
      "1240:\tlearn: 0.0019332\ttotal: 16s\tremaining: 9.79s\n",
      "1241:\tlearn: 0.0019328\ttotal: 16s\tremaining: 9.78s\n",
      "1242:\tlearn: 0.0019323\ttotal: 16s\tremaining: 9.76s\n",
      "1243:\tlearn: 0.0019294\ttotal: 16s\tremaining: 9.75s\n",
      "1244:\tlearn: 0.0019252\ttotal: 16.1s\tremaining: 9.74s\n",
      "1245:\tlearn: 0.0019241\ttotal: 16.1s\tremaining: 9.73s\n",
      "1246:\tlearn: 0.0019221\ttotal: 16.1s\tremaining: 9.72s\n",
      "1247:\tlearn: 0.0019213\ttotal: 16.1s\tremaining: 9.71s\n",
      "1248:\tlearn: 0.0019208\ttotal: 16.1s\tremaining: 9.7s\n",
      "1249:\tlearn: 0.0019180\ttotal: 16.1s\tremaining: 9.69s\n",
      "1250:\tlearn: 0.0019164\ttotal: 16.2s\tremaining: 9.67s\n",
      "1251:\tlearn: 0.0019159\ttotal: 16.2s\tremaining: 9.66s\n",
      "1252:\tlearn: 0.0019144\ttotal: 16.2s\tremaining: 9.64s\n",
      "1253:\tlearn: 0.0019142\ttotal: 16.2s\tremaining: 9.63s\n",
      "1254:\tlearn: 0.0019047\ttotal: 16.2s\tremaining: 9.62s\n",
      "1255:\tlearn: 0.0018995\ttotal: 16.2s\tremaining: 9.6s\n",
      "1256:\tlearn: 0.0018986\ttotal: 16.2s\tremaining: 9.59s\n",
      "1257:\tlearn: 0.0018966\ttotal: 16.2s\tremaining: 9.58s\n",
      "1258:\tlearn: 0.0018925\ttotal: 16.2s\tremaining: 9.56s\n",
      "1259:\tlearn: 0.0018911\ttotal: 16.3s\tremaining: 9.55s\n",
      "1260:\tlearn: 0.0018889\ttotal: 16.3s\tremaining: 9.54s\n",
      "1261:\tlearn: 0.0018874\ttotal: 16.3s\tremaining: 9.52s\n",
      "1262:\tlearn: 0.0018778\ttotal: 16.3s\tremaining: 9.51s\n",
      "1263:\tlearn: 0.0018765\ttotal: 16.3s\tremaining: 9.49s\n",
      "1264:\tlearn: 0.0018748\ttotal: 16.3s\tremaining: 9.48s\n",
      "1265:\tlearn: 0.0018739\ttotal: 16.3s\tremaining: 9.47s\n",
      "1266:\tlearn: 0.0018688\ttotal: 16.3s\tremaining: 9.45s\n",
      "1267:\tlearn: 0.0018646\ttotal: 16.4s\tremaining: 9.44s\n",
      "1268:\tlearn: 0.0018612\ttotal: 16.4s\tremaining: 9.43s\n",
      "1269:\tlearn: 0.0018583\ttotal: 16.4s\tremaining: 9.41s\n",
      "1270:\tlearn: 0.0018557\ttotal: 16.4s\tremaining: 9.4s\n",
      "1271:\tlearn: 0.0018536\ttotal: 16.4s\tremaining: 9.38s\n",
      "1272:\tlearn: 0.0018532\ttotal: 16.4s\tremaining: 9.37s\n",
      "1273:\tlearn: 0.0018525\ttotal: 16.4s\tremaining: 9.36s\n",
      "1274:\tlearn: 0.0018513\ttotal: 16.4s\tremaining: 9.34s\n",
      "1275:\tlearn: 0.0018503\ttotal: 16.4s\tremaining: 9.33s\n",
      "1276:\tlearn: 0.0018473\ttotal: 16.5s\tremaining: 9.32s\n",
      "1277:\tlearn: 0.0018470\ttotal: 16.5s\tremaining: 9.3s\n",
      "1278:\tlearn: 0.0018449\ttotal: 16.5s\tremaining: 9.29s\n",
      "1279:\tlearn: 0.0018419\ttotal: 16.5s\tremaining: 9.28s\n",
      "1280:\tlearn: 0.0018406\ttotal: 16.5s\tremaining: 9.26s\n",
      "1281:\tlearn: 0.0018402\ttotal: 16.5s\tremaining: 9.25s\n",
      "1282:\tlearn: 0.0018389\ttotal: 16.5s\tremaining: 9.23s\n",
      "1283:\tlearn: 0.0018347\ttotal: 16.5s\tremaining: 9.22s\n",
      "1284:\tlearn: 0.0018315\ttotal: 16.5s\tremaining: 9.21s\n",
      "1285:\tlearn: 0.0018289\ttotal: 16.6s\tremaining: 9.19s\n",
      "1286:\tlearn: 0.0018281\ttotal: 16.6s\tremaining: 9.18s\n",
      "1287:\tlearn: 0.0018230\ttotal: 16.6s\tremaining: 9.17s\n",
      "1288:\tlearn: 0.0018215\ttotal: 16.6s\tremaining: 9.15s\n",
      "1289:\tlearn: 0.0018213\ttotal: 16.6s\tremaining: 9.14s\n",
      "1290:\tlearn: 0.0018204\ttotal: 16.6s\tremaining: 9.13s\n",
      "1291:\tlearn: 0.0018198\ttotal: 16.6s\tremaining: 9.12s\n",
      "1292:\tlearn: 0.0018168\ttotal: 16.6s\tremaining: 9.1s\n",
      "1293:\tlearn: 0.0018138\ttotal: 16.7s\tremaining: 9.09s\n",
      "1294:\tlearn: 0.0018133\ttotal: 16.7s\tremaining: 9.08s\n",
      "1295:\tlearn: 0.0018123\ttotal: 16.7s\tremaining: 9.06s\n",
      "1296:\tlearn: 0.0018068\ttotal: 16.7s\tremaining: 9.05s\n",
      "1297:\tlearn: 0.0018041\ttotal: 16.7s\tremaining: 9.04s\n",
      "1298:\tlearn: 0.0017957\ttotal: 16.7s\tremaining: 9.03s\n",
      "1299:\tlearn: 0.0017948\ttotal: 16.7s\tremaining: 9.01s\n",
      "1300:\tlearn: 0.0017933\ttotal: 16.7s\tremaining: 9s\n",
      "1301:\tlearn: 0.0017924\ttotal: 16.8s\tremaining: 8.98s\n",
      "1302:\tlearn: 0.0017915\ttotal: 16.8s\tremaining: 8.97s\n",
      "1303:\tlearn: 0.0017895\ttotal: 16.8s\tremaining: 8.96s\n",
      "1304:\tlearn: 0.0017890\ttotal: 16.8s\tremaining: 8.95s\n",
      "1305:\tlearn: 0.0017848\ttotal: 16.8s\tremaining: 8.93s\n",
      "1306:\tlearn: 0.0017805\ttotal: 16.8s\tremaining: 8.92s\n",
      "1307:\tlearn: 0.0017794\ttotal: 16.8s\tremaining: 8.91s\n",
      "1308:\tlearn: 0.0017788\ttotal: 16.8s\tremaining: 8.89s\n",
      "1309:\tlearn: 0.0017779\ttotal: 16.9s\tremaining: 8.88s\n",
      "1310:\tlearn: 0.0017764\ttotal: 16.9s\tremaining: 8.87s\n",
      "1311:\tlearn: 0.0017759\ttotal: 16.9s\tremaining: 8.85s\n",
      "1312:\tlearn: 0.0017751\ttotal: 16.9s\tremaining: 8.84s\n",
      "1313:\tlearn: 0.0017743\ttotal: 16.9s\tremaining: 8.82s\n",
      "1314:\tlearn: 0.0017741\ttotal: 16.9s\tremaining: 8.81s\n",
      "1315:\tlearn: 0.0017712\ttotal: 16.9s\tremaining: 8.8s\n",
      "1316:\tlearn: 0.0017687\ttotal: 16.9s\tremaining: 8.78s\n",
      "1317:\tlearn: 0.0017654\ttotal: 16.9s\tremaining: 8.77s\n",
      "1318:\tlearn: 0.0017647\ttotal: 17s\tremaining: 8.76s\n",
      "1319:\tlearn: 0.0017614\ttotal: 17s\tremaining: 8.74s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320:\tlearn: 0.0017603\ttotal: 17s\tremaining: 8.73s\n",
      "1321:\tlearn: 0.0017588\ttotal: 17s\tremaining: 8.72s\n",
      "1322:\tlearn: 0.0017585\ttotal: 17s\tremaining: 8.7s\n",
      "1323:\tlearn: 0.0017577\ttotal: 17s\tremaining: 8.69s\n",
      "1324:\tlearn: 0.0017545\ttotal: 17s\tremaining: 8.68s\n",
      "1325:\tlearn: 0.0017541\ttotal: 17s\tremaining: 8.66s\n",
      "1326:\tlearn: 0.0017508\ttotal: 17.1s\tremaining: 8.65s\n",
      "1327:\tlearn: 0.0017494\ttotal: 17.1s\tremaining: 8.63s\n",
      "1328:\tlearn: 0.0017465\ttotal: 17.1s\tremaining: 8.62s\n",
      "1329:\tlearn: 0.0017410\ttotal: 17.1s\tremaining: 8.61s\n",
      "1330:\tlearn: 0.0017384\ttotal: 17.1s\tremaining: 8.6s\n",
      "1331:\tlearn: 0.0017368\ttotal: 17.1s\tremaining: 8.58s\n",
      "1332:\tlearn: 0.0017366\ttotal: 17.1s\tremaining: 8.57s\n",
      "1333:\tlearn: 0.0017336\ttotal: 17.1s\tremaining: 8.55s\n",
      "1334:\tlearn: 0.0017291\ttotal: 17.1s\tremaining: 8.54s\n",
      "1335:\tlearn: 0.0017275\ttotal: 17.2s\tremaining: 8.53s\n",
      "1336:\tlearn: 0.0017265\ttotal: 17.2s\tremaining: 8.51s\n",
      "1337:\tlearn: 0.0017253\ttotal: 17.2s\tremaining: 8.5s\n",
      "1338:\tlearn: 0.0017241\ttotal: 17.2s\tremaining: 8.49s\n",
      "1339:\tlearn: 0.0017236\ttotal: 17.2s\tremaining: 8.47s\n",
      "1340:\tlearn: 0.0017231\ttotal: 17.2s\tremaining: 8.46s\n",
      "1341:\tlearn: 0.0017212\ttotal: 17.2s\tremaining: 8.45s\n",
      "1342:\tlearn: 0.0017195\ttotal: 17.2s\tremaining: 8.43s\n",
      "1343:\tlearn: 0.0017190\ttotal: 17.2s\tremaining: 8.42s\n",
      "1344:\tlearn: 0.0017183\ttotal: 17.3s\tremaining: 8.41s\n",
      "1345:\tlearn: 0.0017154\ttotal: 17.3s\tremaining: 8.39s\n",
      "1346:\tlearn: 0.0017142\ttotal: 17.3s\tremaining: 8.38s\n",
      "1347:\tlearn: 0.0017131\ttotal: 17.3s\tremaining: 8.36s\n",
      "1348:\tlearn: 0.0017113\ttotal: 17.3s\tremaining: 8.35s\n",
      "1349:\tlearn: 0.0017103\ttotal: 17.3s\tremaining: 8.34s\n",
      "1350:\tlearn: 0.0017091\ttotal: 17.3s\tremaining: 8.32s\n",
      "1351:\tlearn: 0.0017081\ttotal: 17.3s\tremaining: 8.31s\n",
      "1352:\tlearn: 0.0017074\ttotal: 17.4s\tremaining: 8.3s\n",
      "1353:\tlearn: 0.0017067\ttotal: 17.4s\tremaining: 8.28s\n",
      "1354:\tlearn: 0.0017034\ttotal: 17.4s\tremaining: 8.27s\n",
      "1355:\tlearn: 0.0017000\ttotal: 17.4s\tremaining: 8.26s\n",
      "1356:\tlearn: 0.0016969\ttotal: 17.4s\tremaining: 8.24s\n",
      "1357:\tlearn: 0.0016946\ttotal: 17.4s\tremaining: 8.23s\n",
      "1358:\tlearn: 0.0016935\ttotal: 17.4s\tremaining: 8.22s\n",
      "1359:\tlearn: 0.0016907\ttotal: 17.4s\tremaining: 8.2s\n",
      "1360:\tlearn: 0.0016870\ttotal: 17.4s\tremaining: 8.19s\n",
      "1361:\tlearn: 0.0016853\ttotal: 17.5s\tremaining: 8.18s\n",
      "1362:\tlearn: 0.0016843\ttotal: 17.5s\tremaining: 8.16s\n",
      "1363:\tlearn: 0.0016815\ttotal: 17.5s\tremaining: 8.15s\n",
      "1364:\tlearn: 0.0016814\ttotal: 17.5s\tremaining: 8.14s\n",
      "1365:\tlearn: 0.0016794\ttotal: 17.5s\tremaining: 8.12s\n",
      "1366:\tlearn: 0.0016786\ttotal: 17.5s\tremaining: 8.11s\n",
      "1367:\tlearn: 0.0016778\ttotal: 17.5s\tremaining: 8.1s\n",
      "1368:\tlearn: 0.0016768\ttotal: 17.5s\tremaining: 8.08s\n",
      "1369:\tlearn: 0.0016716\ttotal: 17.5s\tremaining: 8.07s\n",
      "1370:\tlearn: 0.0016669\ttotal: 17.6s\tremaining: 8.06s\n",
      "1371:\tlearn: 0.0016662\ttotal: 17.6s\tremaining: 8.04s\n",
      "1372:\tlearn: 0.0016648\ttotal: 17.6s\tremaining: 8.03s\n",
      "1373:\tlearn: 0.0016643\ttotal: 17.6s\tremaining: 8.02s\n",
      "1374:\tlearn: 0.0016635\ttotal: 17.6s\tremaining: 8s\n",
      "1375:\tlearn: 0.0016596\ttotal: 17.6s\tremaining: 7.99s\n",
      "1376:\tlearn: 0.0016566\ttotal: 17.6s\tremaining: 7.98s\n",
      "1377:\tlearn: 0.0016525\ttotal: 17.6s\tremaining: 7.96s\n",
      "1378:\tlearn: 0.0016516\ttotal: 17.7s\tremaining: 7.95s\n",
      "1379:\tlearn: 0.0016495\ttotal: 17.7s\tremaining: 7.93s\n",
      "1380:\tlearn: 0.0016486\ttotal: 17.7s\tremaining: 7.92s\n",
      "1381:\tlearn: 0.0016482\ttotal: 17.7s\tremaining: 7.91s\n",
      "1382:\tlearn: 0.0016473\ttotal: 17.7s\tremaining: 7.89s\n",
      "1383:\tlearn: 0.0016468\ttotal: 17.7s\tremaining: 7.88s\n",
      "1384:\tlearn: 0.0016435\ttotal: 17.7s\tremaining: 7.87s\n",
      "1385:\tlearn: 0.0016403\ttotal: 17.7s\tremaining: 7.86s\n",
      "1386:\tlearn: 0.0016382\ttotal: 17.7s\tremaining: 7.84s\n",
      "1387:\tlearn: 0.0016323\ttotal: 17.8s\tremaining: 7.83s\n",
      "1388:\tlearn: 0.0016315\ttotal: 17.8s\tremaining: 7.82s\n",
      "1389:\tlearn: 0.0016284\ttotal: 17.8s\tremaining: 7.8s\n",
      "1390:\tlearn: 0.0016241\ttotal: 17.8s\tremaining: 7.79s\n",
      "1391:\tlearn: 0.0016221\ttotal: 17.8s\tremaining: 7.78s\n",
      "1392:\tlearn: 0.0016203\ttotal: 17.8s\tremaining: 7.76s\n",
      "1393:\tlearn: 0.0016195\ttotal: 17.8s\tremaining: 7.75s\n",
      "1394:\tlearn: 0.0016170\ttotal: 17.8s\tremaining: 7.74s\n",
      "1395:\tlearn: 0.0016154\ttotal: 17.8s\tremaining: 7.72s\n",
      "1396:\tlearn: 0.0016148\ttotal: 17.9s\tremaining: 7.71s\n",
      "1397:\tlearn: 0.0016128\ttotal: 17.9s\tremaining: 7.69s\n",
      "1398:\tlearn: 0.0016111\ttotal: 17.9s\tremaining: 7.68s\n",
      "1399:\tlearn: 0.0016109\ttotal: 17.9s\tremaining: 7.67s\n",
      "1400:\tlearn: 0.0016092\ttotal: 17.9s\tremaining: 7.66s\n",
      "1401:\tlearn: 0.0016078\ttotal: 17.9s\tremaining: 7.64s\n",
      "1402:\tlearn: 0.0016073\ttotal: 17.9s\tremaining: 7.63s\n",
      "1403:\tlearn: 0.0016064\ttotal: 17.9s\tremaining: 7.62s\n",
      "1404:\tlearn: 0.0016050\ttotal: 18s\tremaining: 7.6s\n",
      "1405:\tlearn: 0.0016047\ttotal: 18s\tremaining: 7.59s\n",
      "1406:\tlearn: 0.0016003\ttotal: 18s\tremaining: 7.58s\n",
      "1407:\tlearn: 0.0015995\ttotal: 18s\tremaining: 7.56s\n",
      "1408:\tlearn: 0.0015991\ttotal: 18s\tremaining: 7.55s\n",
      "1409:\tlearn: 0.0015968\ttotal: 18s\tremaining: 7.54s\n",
      "1410:\tlearn: 0.0015962\ttotal: 18s\tremaining: 7.52s\n",
      "1411:\tlearn: 0.0015951\ttotal: 18s\tremaining: 7.51s\n",
      "1412:\tlearn: 0.0015938\ttotal: 18s\tremaining: 7.5s\n",
      "1413:\tlearn: 0.0015934\ttotal: 18.1s\tremaining: 7.48s\n",
      "1414:\tlearn: 0.0015925\ttotal: 18.1s\tremaining: 7.47s\n",
      "1415:\tlearn: 0.0015915\ttotal: 18.1s\tremaining: 7.46s\n",
      "1416:\tlearn: 0.0015905\ttotal: 18.1s\tremaining: 7.44s\n",
      "1417:\tlearn: 0.0015902\ttotal: 18.1s\tremaining: 7.43s\n",
      "1418:\tlearn: 0.0015886\ttotal: 18.1s\tremaining: 7.42s\n",
      "1419:\tlearn: 0.0015850\ttotal: 18.1s\tremaining: 7.4s\n",
      "1420:\tlearn: 0.0015847\ttotal: 18.1s\tremaining: 7.39s\n",
      "1421:\tlearn: 0.0015827\ttotal: 18.1s\tremaining: 7.38s\n",
      "1422:\tlearn: 0.0015822\ttotal: 18.2s\tremaining: 7.36s\n",
      "1423:\tlearn: 0.0015793\ttotal: 18.2s\tremaining: 7.35s\n",
      "1424:\tlearn: 0.0015754\ttotal: 18.2s\tremaining: 7.34s\n",
      "1425:\tlearn: 0.0015746\ttotal: 18.2s\tremaining: 7.33s\n",
      "1426:\tlearn: 0.0015742\ttotal: 18.2s\tremaining: 7.31s\n",
      "1427:\tlearn: 0.0015727\ttotal: 18.2s\tremaining: 7.3s\n",
      "1428:\tlearn: 0.0015706\ttotal: 18.2s\tremaining: 7.29s\n",
      "1429:\tlearn: 0.0015703\ttotal: 18.3s\tremaining: 7.27s\n",
      "1430:\tlearn: 0.0015685\ttotal: 18.3s\tremaining: 7.26s\n",
      "1431:\tlearn: 0.0015683\ttotal: 18.3s\tremaining: 7.25s\n",
      "1432:\tlearn: 0.0015680\ttotal: 18.3s\tremaining: 7.24s\n",
      "1433:\tlearn: 0.0015675\ttotal: 18.3s\tremaining: 7.22s\n",
      "1434:\tlearn: 0.0015657\ttotal: 18.3s\tremaining: 7.21s\n",
      "1435:\tlearn: 0.0015641\ttotal: 18.3s\tremaining: 7.2s\n",
      "1436:\tlearn: 0.0015636\ttotal: 18.3s\tremaining: 7.18s\n",
      "1437:\tlearn: 0.0015624\ttotal: 18.4s\tremaining: 7.17s\n",
      "1438:\tlearn: 0.0015605\ttotal: 18.4s\tremaining: 7.16s\n",
      "1439:\tlearn: 0.0015575\ttotal: 18.4s\tremaining: 7.15s\n",
      "1440:\tlearn: 0.0015560\ttotal: 18.4s\tremaining: 7.13s\n",
      "1441:\tlearn: 0.0015542\ttotal: 18.4s\tremaining: 7.12s\n",
      "1442:\tlearn: 0.0015479\ttotal: 18.4s\tremaining: 7.11s\n",
      "1443:\tlearn: 0.0015460\ttotal: 18.4s\tremaining: 7.1s\n",
      "1444:\tlearn: 0.0015450\ttotal: 18.4s\tremaining: 7.08s\n",
      "1445:\tlearn: 0.0015433\ttotal: 18.5s\tremaining: 7.07s\n",
      "1446:\tlearn: 0.0015399\ttotal: 18.5s\tremaining: 7.06s\n",
      "1447:\tlearn: 0.0015350\ttotal: 18.5s\tremaining: 7.04s\n",
      "1448:\tlearn: 0.0015327\ttotal: 18.5s\tremaining: 7.03s\n",
      "1449:\tlearn: 0.0015322\ttotal: 18.5s\tremaining: 7.02s\n",
      "1450:\tlearn: 0.0015314\ttotal: 18.5s\tremaining: 7.01s\n",
      "1451:\tlearn: 0.0015305\ttotal: 18.5s\tremaining: 6.99s\n",
      "1452:\tlearn: 0.0015301\ttotal: 18.5s\tremaining: 6.98s\n",
      "1453:\tlearn: 0.0015298\ttotal: 18.6s\tremaining: 6.97s\n",
      "1454:\tlearn: 0.0015278\ttotal: 18.6s\tremaining: 6.95s\n",
      "1455:\tlearn: 0.0015274\ttotal: 18.6s\tremaining: 6.94s\n",
      "1456:\tlearn: 0.0015269\ttotal: 18.6s\tremaining: 6.93s\n",
      "1457:\tlearn: 0.0015224\ttotal: 18.6s\tremaining: 6.92s\n",
      "1458:\tlearn: 0.0015217\ttotal: 18.6s\tremaining: 6.9s\n",
      "1459:\tlearn: 0.0015214\ttotal: 18.6s\tremaining: 6.89s\n",
      "1460:\tlearn: 0.0015184\ttotal: 18.6s\tremaining: 6.88s\n",
      "1461:\tlearn: 0.0015178\ttotal: 18.7s\tremaining: 6.86s\n",
      "1462:\tlearn: 0.0015173\ttotal: 18.7s\tremaining: 6.85s\n",
      "1463:\tlearn: 0.0015143\ttotal: 18.7s\tremaining: 6.84s\n",
      "1464:\tlearn: 0.0015117\ttotal: 18.7s\tremaining: 6.82s\n",
      "1465:\tlearn: 0.0015105\ttotal: 18.7s\tremaining: 6.81s\n",
      "1466:\tlearn: 0.0015096\ttotal: 18.7s\tremaining: 6.8s\n",
      "1467:\tlearn: 0.0015089\ttotal: 18.7s\tremaining: 6.79s\n",
      "1468:\tlearn: 0.0015077\ttotal: 18.7s\tremaining: 6.77s\n",
      "1469:\tlearn: 0.0015071\ttotal: 18.7s\tremaining: 6.76s\n",
      "1470:\tlearn: 0.0015065\ttotal: 18.8s\tremaining: 6.75s\n",
      "1471:\tlearn: 0.0015036\ttotal: 18.8s\tremaining: 6.73s\n",
      "1472:\tlearn: 0.0015033\ttotal: 18.8s\tremaining: 6.72s\n",
      "1473:\tlearn: 0.0015028\ttotal: 18.8s\tremaining: 6.71s\n",
      "1474:\tlearn: 0.0015010\ttotal: 18.8s\tremaining: 6.7s\n",
      "1475:\tlearn: 0.0015008\ttotal: 18.8s\tremaining: 6.68s\n",
      "1476:\tlearn: 0.0015006\ttotal: 18.8s\tremaining: 6.67s\n",
      "1477:\tlearn: 0.0015004\ttotal: 18.8s\tremaining: 6.66s\n",
      "1478:\tlearn: 0.0014997\ttotal: 18.9s\tremaining: 6.64s\n",
      "1479:\tlearn: 0.0014987\ttotal: 18.9s\tremaining: 6.63s\n",
      "1480:\tlearn: 0.0014979\ttotal: 18.9s\tremaining: 6.62s\n",
      "1481:\tlearn: 0.0014954\ttotal: 18.9s\tremaining: 6.61s\n",
      "1482:\tlearn: 0.0014943\ttotal: 18.9s\tremaining: 6.59s\n",
      "1483:\tlearn: 0.0014940\ttotal: 18.9s\tremaining: 6.58s\n",
      "1484:\tlearn: 0.0014931\ttotal: 18.9s\tremaining: 6.57s\n",
      "1485:\tlearn: 0.0014925\ttotal: 18.9s\tremaining: 6.55s\n",
      "1486:\tlearn: 0.0014919\ttotal: 19s\tremaining: 6.54s\n",
      "1487:\tlearn: 0.0014914\ttotal: 19s\tremaining: 6.53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1488:\tlearn: 0.0014907\ttotal: 19s\tremaining: 6.51s\n",
      "1489:\tlearn: 0.0014892\ttotal: 19s\tremaining: 6.5s\n",
      "1490:\tlearn: 0.0014891\ttotal: 19s\tremaining: 6.49s\n",
      "1491:\tlearn: 0.0014888\ttotal: 19s\tremaining: 6.47s\n",
      "1492:\tlearn: 0.0014863\ttotal: 19s\tremaining: 6.46s\n",
      "1493:\tlearn: 0.0014839\ttotal: 19s\tremaining: 6.45s\n",
      "1494:\tlearn: 0.0014835\ttotal: 19.1s\tremaining: 6.44s\n",
      "1495:\tlearn: 0.0014827\ttotal: 19.1s\tremaining: 6.42s\n",
      "1496:\tlearn: 0.0014801\ttotal: 19.1s\tremaining: 6.41s\n",
      "1497:\tlearn: 0.0014799\ttotal: 19.1s\tremaining: 6.4s\n",
      "1498:\tlearn: 0.0014787\ttotal: 19.1s\tremaining: 6.38s\n",
      "1499:\tlearn: 0.0014778\ttotal: 19.1s\tremaining: 6.37s\n",
      "1500:\tlearn: 0.0014760\ttotal: 19.1s\tremaining: 6.36s\n",
      "1501:\tlearn: 0.0014758\ttotal: 19.1s\tremaining: 6.34s\n",
      "1502:\tlearn: 0.0014749\ttotal: 19.1s\tremaining: 6.33s\n",
      "1503:\tlearn: 0.0014745\ttotal: 19.2s\tremaining: 6.32s\n",
      "1504:\tlearn: 0.0014739\ttotal: 19.2s\tremaining: 6.3s\n",
      "1505:\tlearn: 0.0014719\ttotal: 19.2s\tremaining: 6.29s\n",
      "1506:\tlearn: 0.0014701\ttotal: 19.2s\tremaining: 6.28s\n",
      "1507:\tlearn: 0.0014663\ttotal: 19.2s\tremaining: 6.26s\n",
      "1508:\tlearn: 0.0014647\ttotal: 19.2s\tremaining: 6.25s\n",
      "1509:\tlearn: 0.0014623\ttotal: 19.2s\tremaining: 6.24s\n",
      "1510:\tlearn: 0.0014610\ttotal: 19.2s\tremaining: 6.23s\n",
      "1511:\tlearn: 0.0014589\ttotal: 19.3s\tremaining: 6.21s\n",
      "1512:\tlearn: 0.0014576\ttotal: 19.3s\tremaining: 6.2s\n",
      "1513:\tlearn: 0.0014570\ttotal: 19.3s\tremaining: 6.19s\n",
      "1514:\tlearn: 0.0014544\ttotal: 19.3s\tremaining: 6.17s\n",
      "1515:\tlearn: 0.0014459\ttotal: 19.3s\tremaining: 6.16s\n",
      "1516:\tlearn: 0.0014445\ttotal: 19.3s\tremaining: 6.15s\n",
      "1517:\tlearn: 0.0014407\ttotal: 19.3s\tremaining: 6.13s\n",
      "1518:\tlearn: 0.0014341\ttotal: 19.3s\tremaining: 6.12s\n",
      "1519:\tlearn: 0.0014324\ttotal: 19.3s\tremaining: 6.11s\n",
      "1520:\tlearn: 0.0014320\ttotal: 19.4s\tremaining: 6.09s\n",
      "1521:\tlearn: 0.0014318\ttotal: 19.4s\tremaining: 6.08s\n",
      "1522:\tlearn: 0.0014295\ttotal: 19.4s\tremaining: 6.07s\n",
      "1523:\tlearn: 0.0014290\ttotal: 19.4s\tremaining: 6.05s\n",
      "1524:\tlearn: 0.0014285\ttotal: 19.4s\tremaining: 6.04s\n",
      "1525:\tlearn: 0.0014276\ttotal: 19.4s\tremaining: 6.03s\n",
      "1526:\tlearn: 0.0014235\ttotal: 19.4s\tremaining: 6.01s\n",
      "1527:\tlearn: 0.0014227\ttotal: 19.4s\tremaining: 6s\n",
      "1528:\tlearn: 0.0014220\ttotal: 19.4s\tremaining: 5.99s\n",
      "1529:\tlearn: 0.0014197\ttotal: 19.4s\tremaining: 5.97s\n",
      "1530:\tlearn: 0.0014189\ttotal: 19.5s\tremaining: 5.96s\n",
      "1531:\tlearn: 0.0014187\ttotal: 19.5s\tremaining: 5.95s\n",
      "1532:\tlearn: 0.0014174\ttotal: 19.5s\tremaining: 5.93s\n",
      "1533:\tlearn: 0.0014163\ttotal: 19.5s\tremaining: 5.92s\n",
      "1534:\tlearn: 0.0014146\ttotal: 19.5s\tremaining: 5.91s\n",
      "1535:\tlearn: 0.0014126\ttotal: 19.5s\tremaining: 5.89s\n",
      "1536:\tlearn: 0.0014110\ttotal: 19.5s\tremaining: 5.88s\n",
      "1537:\tlearn: 0.0014094\ttotal: 19.5s\tremaining: 5.87s\n",
      "1538:\tlearn: 0.0014077\ttotal: 19.5s\tremaining: 5.85s\n",
      "1539:\tlearn: 0.0014068\ttotal: 19.6s\tremaining: 5.84s\n",
      "1540:\tlearn: 0.0014059\ttotal: 19.6s\tremaining: 5.83s\n",
      "1541:\tlearn: 0.0014058\ttotal: 19.6s\tremaining: 5.82s\n",
      "1542:\tlearn: 0.0014025\ttotal: 19.6s\tremaining: 5.8s\n",
      "1543:\tlearn: 0.0013989\ttotal: 19.6s\tremaining: 5.79s\n",
      "1544:\tlearn: 0.0013973\ttotal: 19.6s\tremaining: 5.78s\n",
      "1545:\tlearn: 0.0013946\ttotal: 19.6s\tremaining: 5.76s\n",
      "1546:\tlearn: 0.0013936\ttotal: 19.6s\tremaining: 5.75s\n",
      "1547:\tlearn: 0.0013929\ttotal: 19.6s\tremaining: 5.74s\n",
      "1548:\tlearn: 0.0013927\ttotal: 19.7s\tremaining: 5.72s\n",
      "1549:\tlearn: 0.0013907\ttotal: 19.7s\tremaining: 5.71s\n",
      "1550:\tlearn: 0.0013896\ttotal: 19.7s\tremaining: 5.7s\n",
      "1551:\tlearn: 0.0013894\ttotal: 19.7s\tremaining: 5.68s\n",
      "1552:\tlearn: 0.0013885\ttotal: 19.7s\tremaining: 5.67s\n",
      "1553:\tlearn: 0.0013868\ttotal: 19.7s\tremaining: 5.66s\n",
      "1554:\tlearn: 0.0013823\ttotal: 19.7s\tremaining: 5.65s\n",
      "1555:\tlearn: 0.0013802\ttotal: 19.7s\tremaining: 5.63s\n",
      "1556:\tlearn: 0.0013783\ttotal: 19.8s\tremaining: 5.62s\n",
      "1557:\tlearn: 0.0013727\ttotal: 19.8s\tremaining: 5.61s\n",
      "1558:\tlearn: 0.0013679\ttotal: 19.8s\tremaining: 5.59s\n",
      "1559:\tlearn: 0.0013673\ttotal: 19.8s\tremaining: 5.58s\n",
      "1560:\tlearn: 0.0013647\ttotal: 19.8s\tremaining: 5.57s\n",
      "1561:\tlearn: 0.0013632\ttotal: 19.8s\tremaining: 5.55s\n",
      "1562:\tlearn: 0.0013617\ttotal: 19.8s\tremaining: 5.54s\n",
      "1563:\tlearn: 0.0013613\ttotal: 19.8s\tremaining: 5.53s\n",
      "1564:\tlearn: 0.0013600\ttotal: 19.8s\tremaining: 5.52s\n",
      "1565:\tlearn: 0.0013581\ttotal: 19.9s\tremaining: 5.5s\n",
      "1566:\tlearn: 0.0013576\ttotal: 19.9s\tremaining: 5.49s\n",
      "1567:\tlearn: 0.0013559\ttotal: 19.9s\tremaining: 5.48s\n",
      "1568:\tlearn: 0.0013555\ttotal: 19.9s\tremaining: 5.46s\n",
      "1569:\tlearn: 0.0013551\ttotal: 19.9s\tremaining: 5.45s\n",
      "1570:\tlearn: 0.0013546\ttotal: 19.9s\tremaining: 5.44s\n",
      "1571:\tlearn: 0.0013540\ttotal: 19.9s\tremaining: 5.42s\n",
      "1572:\tlearn: 0.0013535\ttotal: 19.9s\tremaining: 5.41s\n",
      "1573:\tlearn: 0.0013514\ttotal: 19.9s\tremaining: 5.4s\n",
      "1574:\tlearn: 0.0013506\ttotal: 20s\tremaining: 5.38s\n",
      "1575:\tlearn: 0.0013505\ttotal: 20s\tremaining: 5.37s\n",
      "1576:\tlearn: 0.0013481\ttotal: 20s\tremaining: 5.36s\n",
      "1577:\tlearn: 0.0013473\ttotal: 20s\tremaining: 5.35s\n",
      "1578:\tlearn: 0.0013463\ttotal: 20s\tremaining: 5.33s\n",
      "1579:\tlearn: 0.0013440\ttotal: 20s\tremaining: 5.32s\n",
      "1580:\tlearn: 0.0013432\ttotal: 20s\tremaining: 5.31s\n",
      "1581:\tlearn: 0.0013400\ttotal: 20s\tremaining: 5.29s\n",
      "1582:\tlearn: 0.0013392\ttotal: 20.1s\tremaining: 5.28s\n",
      "1583:\tlearn: 0.0013371\ttotal: 20.1s\tremaining: 5.27s\n",
      "1584:\tlearn: 0.0013367\ttotal: 20.1s\tremaining: 5.25s\n",
      "1585:\tlearn: 0.0013358\ttotal: 20.1s\tremaining: 5.24s\n",
      "1586:\tlearn: 0.0013332\ttotal: 20.1s\tremaining: 5.23s\n",
      "1587:\tlearn: 0.0013314\ttotal: 20.1s\tremaining: 5.22s\n",
      "1588:\tlearn: 0.0013313\ttotal: 20.1s\tremaining: 5.2s\n",
      "1589:\tlearn: 0.0013308\ttotal: 20.1s\tremaining: 5.19s\n",
      "1590:\tlearn: 0.0013286\ttotal: 20.1s\tremaining: 5.18s\n",
      "1591:\tlearn: 0.0013260\ttotal: 20.2s\tremaining: 5.16s\n",
      "1592:\tlearn: 0.0013252\ttotal: 20.2s\tremaining: 5.15s\n",
      "1593:\tlearn: 0.0013234\ttotal: 20.2s\tremaining: 5.14s\n",
      "1594:\tlearn: 0.0013219\ttotal: 20.2s\tremaining: 5.13s\n",
      "1595:\tlearn: 0.0013211\ttotal: 20.2s\tremaining: 5.11s\n",
      "1596:\tlearn: 0.0013200\ttotal: 20.2s\tremaining: 5.1s\n",
      "1597:\tlearn: 0.0013193\ttotal: 20.2s\tremaining: 5.09s\n",
      "1598:\tlearn: 0.0013187\ttotal: 20.2s\tremaining: 5.07s\n",
      "1599:\tlearn: 0.0013177\ttotal: 20.2s\tremaining: 5.06s\n",
      "1600:\tlearn: 0.0013151\ttotal: 20.3s\tremaining: 5.05s\n",
      "1601:\tlearn: 0.0013147\ttotal: 20.3s\tremaining: 5.04s\n",
      "1602:\tlearn: 0.0013145\ttotal: 20.3s\tremaining: 5.02s\n",
      "1603:\tlearn: 0.0013129\ttotal: 20.3s\tremaining: 5.01s\n",
      "1604:\tlearn: 0.0013118\ttotal: 20.3s\tremaining: 5s\n",
      "1605:\tlearn: 0.0013114\ttotal: 20.3s\tremaining: 4.99s\n",
      "1606:\tlearn: 0.0013109\ttotal: 20.3s\tremaining: 4.97s\n",
      "1607:\tlearn: 0.0013099\ttotal: 20.3s\tremaining: 4.96s\n",
      "1608:\tlearn: 0.0013095\ttotal: 20.4s\tremaining: 4.95s\n",
      "1609:\tlearn: 0.0013092\ttotal: 20.4s\tremaining: 4.93s\n",
      "1610:\tlearn: 0.0013084\ttotal: 20.4s\tremaining: 4.92s\n",
      "1611:\tlearn: 0.0013068\ttotal: 20.4s\tremaining: 4.91s\n",
      "1612:\tlearn: 0.0013047\ttotal: 20.4s\tremaining: 4.89s\n",
      "1613:\tlearn: 0.0013037\ttotal: 20.4s\tremaining: 4.88s\n",
      "1614:\tlearn: 0.0013035\ttotal: 20.4s\tremaining: 4.87s\n",
      "1615:\tlearn: 0.0013023\ttotal: 20.4s\tremaining: 4.85s\n",
      "1616:\tlearn: 0.0012967\ttotal: 20.4s\tremaining: 4.84s\n",
      "1617:\tlearn: 0.0012957\ttotal: 20.5s\tremaining: 4.83s\n",
      "1618:\tlearn: 0.0012932\ttotal: 20.5s\tremaining: 4.82s\n",
      "1619:\tlearn: 0.0012928\ttotal: 20.5s\tremaining: 4.8s\n",
      "1620:\tlearn: 0.0012916\ttotal: 20.5s\tremaining: 4.79s\n",
      "1621:\tlearn: 0.0012912\ttotal: 20.5s\tremaining: 4.78s\n",
      "1622:\tlearn: 0.0012899\ttotal: 20.5s\tremaining: 4.76s\n",
      "1623:\tlearn: 0.0012874\ttotal: 20.5s\tremaining: 4.75s\n",
      "1624:\tlearn: 0.0012871\ttotal: 20.5s\tremaining: 4.74s\n",
      "1625:\tlearn: 0.0012860\ttotal: 20.5s\tremaining: 4.72s\n",
      "1626:\tlearn: 0.0012855\ttotal: 20.6s\tremaining: 4.71s\n",
      "1627:\tlearn: 0.0012850\ttotal: 20.6s\tremaining: 4.7s\n",
      "1628:\tlearn: 0.0012846\ttotal: 20.6s\tremaining: 4.69s\n",
      "1629:\tlearn: 0.0012834\ttotal: 20.6s\tremaining: 4.67s\n",
      "1630:\tlearn: 0.0012822\ttotal: 20.6s\tremaining: 4.66s\n",
      "1631:\tlearn: 0.0012815\ttotal: 20.6s\tremaining: 4.65s\n",
      "1632:\tlearn: 0.0012799\ttotal: 20.6s\tremaining: 4.64s\n",
      "1633:\tlearn: 0.0012790\ttotal: 20.6s\tremaining: 4.62s\n",
      "1634:\tlearn: 0.0012789\ttotal: 20.7s\tremaining: 4.61s\n",
      "1635:\tlearn: 0.0012780\ttotal: 20.7s\tremaining: 4.6s\n",
      "1636:\tlearn: 0.0012776\ttotal: 20.7s\tremaining: 4.58s\n",
      "1637:\tlearn: 0.0012767\ttotal: 20.7s\tremaining: 4.57s\n",
      "1638:\tlearn: 0.0012761\ttotal: 20.7s\tremaining: 4.56s\n",
      "1639:\tlearn: 0.0012760\ttotal: 20.7s\tremaining: 4.55s\n",
      "1640:\tlearn: 0.0012737\ttotal: 20.7s\tremaining: 4.53s\n",
      "1641:\tlearn: 0.0012723\ttotal: 20.7s\tremaining: 4.52s\n",
      "1642:\tlearn: 0.0012687\ttotal: 20.8s\tremaining: 4.51s\n",
      "1643:\tlearn: 0.0012676\ttotal: 20.8s\tremaining: 4.5s\n",
      "1644:\tlearn: 0.0012670\ttotal: 20.8s\tremaining: 4.48s\n",
      "1645:\tlearn: 0.0012662\ttotal: 20.8s\tremaining: 4.47s\n",
      "1646:\tlearn: 0.0012650\ttotal: 20.8s\tremaining: 4.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647:\tlearn: 0.0012643\ttotal: 20.8s\tremaining: 4.45s\n",
      "1648:\tlearn: 0.0012640\ttotal: 20.8s\tremaining: 4.43s\n",
      "1649:\tlearn: 0.0012605\ttotal: 20.8s\tremaining: 4.42s\n",
      "1650:\tlearn: 0.0012598\ttotal: 20.9s\tremaining: 4.41s\n",
      "1651:\tlearn: 0.0012581\ttotal: 20.9s\tremaining: 4.4s\n",
      "1652:\tlearn: 0.0012573\ttotal: 20.9s\tremaining: 4.38s\n",
      "1653:\tlearn: 0.0012552\ttotal: 20.9s\tremaining: 4.37s\n",
      "1654:\tlearn: 0.0012548\ttotal: 20.9s\tremaining: 4.36s\n",
      "1655:\tlearn: 0.0012540\ttotal: 20.9s\tremaining: 4.34s\n",
      "1656:\tlearn: 0.0012538\ttotal: 20.9s\tremaining: 4.33s\n",
      "1657:\tlearn: 0.0012536\ttotal: 20.9s\tremaining: 4.32s\n",
      "1658:\tlearn: 0.0012527\ttotal: 21s\tremaining: 4.31s\n",
      "1659:\tlearn: 0.0012520\ttotal: 21s\tremaining: 4.29s\n",
      "1660:\tlearn: 0.0012519\ttotal: 21s\tremaining: 4.28s\n",
      "1661:\tlearn: 0.0012504\ttotal: 21s\tremaining: 4.27s\n",
      "1662:\tlearn: 0.0012499\ttotal: 21s\tremaining: 4.26s\n",
      "1663:\tlearn: 0.0012494\ttotal: 21s\tremaining: 4.24s\n",
      "1664:\tlearn: 0.0012480\ttotal: 21s\tremaining: 4.23s\n",
      "1665:\tlearn: 0.0012474\ttotal: 21s\tremaining: 4.22s\n",
      "1666:\tlearn: 0.0012448\ttotal: 21.1s\tremaining: 4.21s\n",
      "1667:\tlearn: 0.0012438\ttotal: 21.1s\tremaining: 4.19s\n",
      "1668:\tlearn: 0.0012428\ttotal: 21.1s\tremaining: 4.18s\n",
      "1669:\tlearn: 0.0012407\ttotal: 21.1s\tremaining: 4.17s\n",
      "1670:\tlearn: 0.0012386\ttotal: 21.1s\tremaining: 4.16s\n",
      "1671:\tlearn: 0.0012381\ttotal: 21.1s\tremaining: 4.14s\n",
      "1672:\tlearn: 0.0012374\ttotal: 21.1s\tremaining: 4.13s\n",
      "1673:\tlearn: 0.0012366\ttotal: 21.2s\tremaining: 4.12s\n",
      "1674:\tlearn: 0.0012361\ttotal: 21.2s\tremaining: 4.11s\n",
      "1675:\tlearn: 0.0012355\ttotal: 21.2s\tremaining: 4.09s\n",
      "1676:\tlearn: 0.0012351\ttotal: 21.2s\tremaining: 4.08s\n",
      "1677:\tlearn: 0.0012345\ttotal: 21.2s\tremaining: 4.07s\n",
      "1678:\tlearn: 0.0012341\ttotal: 21.2s\tremaining: 4.06s\n",
      "1679:\tlearn: 0.0012330\ttotal: 21.2s\tremaining: 4.04s\n",
      "1680:\tlearn: 0.0012327\ttotal: 21.2s\tremaining: 4.03s\n",
      "1681:\tlearn: 0.0012299\ttotal: 21.3s\tremaining: 4.02s\n",
      "1682:\tlearn: 0.0012285\ttotal: 21.3s\tremaining: 4.01s\n",
      "1683:\tlearn: 0.0012275\ttotal: 21.3s\tremaining: 3.99s\n",
      "1684:\tlearn: 0.0012260\ttotal: 21.3s\tremaining: 3.98s\n",
      "1685:\tlearn: 0.0012260\ttotal: 21.3s\tremaining: 3.97s\n",
      "1686:\tlearn: 0.0012253\ttotal: 21.3s\tremaining: 3.96s\n",
      "1687:\tlearn: 0.0012251\ttotal: 21.3s\tremaining: 3.94s\n",
      "1688:\tlearn: 0.0012239\ttotal: 21.4s\tremaining: 3.93s\n",
      "1689:\tlearn: 0.0012192\ttotal: 21.4s\tremaining: 3.92s\n",
      "1690:\tlearn: 0.0012173\ttotal: 21.4s\tremaining: 3.91s\n",
      "1691:\tlearn: 0.0012169\ttotal: 21.4s\tremaining: 3.89s\n",
      "1692:\tlearn: 0.0012167\ttotal: 21.4s\tremaining: 3.88s\n",
      "1693:\tlearn: 0.0012159\ttotal: 21.4s\tremaining: 3.87s\n",
      "1694:\tlearn: 0.0012154\ttotal: 21.4s\tremaining: 3.85s\n",
      "1695:\tlearn: 0.0012146\ttotal: 21.4s\tremaining: 3.84s\n",
      "1696:\tlearn: 0.0012134\ttotal: 21.4s\tremaining: 3.83s\n",
      "1697:\tlearn: 0.0012119\ttotal: 21.5s\tremaining: 3.82s\n",
      "1698:\tlearn: 0.0012108\ttotal: 21.5s\tremaining: 3.8s\n",
      "1699:\tlearn: 0.0012097\ttotal: 21.5s\tremaining: 3.79s\n",
      "1700:\tlearn: 0.0012089\ttotal: 21.5s\tremaining: 3.78s\n",
      "1701:\tlearn: 0.0012085\ttotal: 21.5s\tremaining: 3.77s\n",
      "1702:\tlearn: 0.0012083\ttotal: 21.5s\tremaining: 3.75s\n",
      "1703:\tlearn: 0.0012077\ttotal: 21.5s\tremaining: 3.74s\n",
      "1704:\tlearn: 0.0012073\ttotal: 21.6s\tremaining: 3.73s\n",
      "1705:\tlearn: 0.0012072\ttotal: 21.6s\tremaining: 3.72s\n",
      "1706:\tlearn: 0.0012067\ttotal: 21.6s\tremaining: 3.71s\n",
      "1707:\tlearn: 0.0012045\ttotal: 21.6s\tremaining: 3.69s\n",
      "1708:\tlearn: 0.0012042\ttotal: 21.6s\tremaining: 3.68s\n",
      "1709:\tlearn: 0.0012029\ttotal: 21.6s\tremaining: 3.67s\n",
      "1710:\tlearn: 0.0012023\ttotal: 21.6s\tremaining: 3.65s\n",
      "1711:\tlearn: 0.0012009\ttotal: 21.7s\tremaining: 3.64s\n",
      "1712:\tlearn: 0.0011993\ttotal: 21.7s\tremaining: 3.63s\n",
      "1713:\tlearn: 0.0011980\ttotal: 21.7s\tremaining: 3.62s\n",
      "1714:\tlearn: 0.0011968\ttotal: 21.7s\tremaining: 3.6s\n",
      "1715:\tlearn: 0.0011951\ttotal: 21.7s\tremaining: 3.59s\n",
      "1716:\tlearn: 0.0011941\ttotal: 21.7s\tremaining: 3.58s\n",
      "1717:\tlearn: 0.0011929\ttotal: 21.7s\tremaining: 3.57s\n",
      "1718:\tlearn: 0.0011913\ttotal: 21.8s\tremaining: 3.56s\n",
      "1719:\tlearn: 0.0011905\ttotal: 21.8s\tremaining: 3.54s\n",
      "1720:\tlearn: 0.0011897\ttotal: 21.8s\tremaining: 3.53s\n",
      "1721:\tlearn: 0.0011889\ttotal: 21.8s\tremaining: 3.52s\n",
      "1722:\tlearn: 0.0011871\ttotal: 21.8s\tremaining: 3.51s\n",
      "1723:\tlearn: 0.0011851\ttotal: 21.8s\tremaining: 3.49s\n",
      "1724:\tlearn: 0.0011841\ttotal: 21.8s\tremaining: 3.48s\n",
      "1725:\tlearn: 0.0011831\ttotal: 21.9s\tremaining: 3.47s\n",
      "1726:\tlearn: 0.0011825\ttotal: 21.9s\tremaining: 3.46s\n",
      "1727:\tlearn: 0.0011810\ttotal: 21.9s\tremaining: 3.44s\n",
      "1728:\tlearn: 0.0011805\ttotal: 21.9s\tremaining: 3.43s\n",
      "1729:\tlearn: 0.0011797\ttotal: 21.9s\tremaining: 3.42s\n",
      "1730:\tlearn: 0.0011784\ttotal: 21.9s\tremaining: 3.41s\n",
      "1731:\tlearn: 0.0011773\ttotal: 21.9s\tremaining: 3.39s\n",
      "1732:\tlearn: 0.0011772\ttotal: 21.9s\tremaining: 3.38s\n",
      "1733:\tlearn: 0.0011766\ttotal: 22s\tremaining: 3.37s\n",
      "1734:\tlearn: 0.0011764\ttotal: 22s\tremaining: 3.36s\n",
      "1735:\tlearn: 0.0011760\ttotal: 22s\tremaining: 3.34s\n",
      "1736:\tlearn: 0.0011751\ttotal: 22s\tremaining: 3.33s\n",
      "1737:\tlearn: 0.0011749\ttotal: 22s\tremaining: 3.32s\n",
      "1738:\tlearn: 0.0011747\ttotal: 22s\tremaining: 3.31s\n",
      "1739:\tlearn: 0.0011744\ttotal: 22s\tremaining: 3.29s\n",
      "1740:\tlearn: 0.0011744\ttotal: 22.1s\tremaining: 3.28s\n",
      "1741:\tlearn: 0.0011739\ttotal: 22.1s\tremaining: 3.27s\n",
      "1742:\tlearn: 0.0011738\ttotal: 22.1s\tremaining: 3.26s\n",
      "1743:\tlearn: 0.0011727\ttotal: 22.1s\tremaining: 3.24s\n",
      "1744:\tlearn: 0.0011726\ttotal: 22.1s\tremaining: 3.23s\n",
      "1745:\tlearn: 0.0011718\ttotal: 22.1s\tremaining: 3.22s\n",
      "1746:\tlearn: 0.0011710\ttotal: 22.1s\tremaining: 3.21s\n",
      "1747:\tlearn: 0.0011704\ttotal: 22.1s\tremaining: 3.19s\n",
      "1748:\tlearn: 0.0011674\ttotal: 22.2s\tremaining: 3.18s\n",
      "1749:\tlearn: 0.0011670\ttotal: 22.2s\tremaining: 3.17s\n",
      "1750:\tlearn: 0.0011665\ttotal: 22.2s\tremaining: 3.15s\n",
      "1751:\tlearn: 0.0011648\ttotal: 22.2s\tremaining: 3.14s\n",
      "1752:\tlearn: 0.0011645\ttotal: 22.2s\tremaining: 3.13s\n",
      "1753:\tlearn: 0.0011638\ttotal: 22.2s\tremaining: 3.12s\n",
      "1754:\tlearn: 0.0011605\ttotal: 22.2s\tremaining: 3.1s\n",
      "1755:\tlearn: 0.0011602\ttotal: 22.2s\tremaining: 3.09s\n",
      "1756:\tlearn: 0.0011599\ttotal: 22.2s\tremaining: 3.08s\n",
      "1757:\tlearn: 0.0011595\ttotal: 22.3s\tremaining: 3.06s\n",
      "1758:\tlearn: 0.0011594\ttotal: 22.3s\tremaining: 3.05s\n",
      "1759:\tlearn: 0.0011582\ttotal: 22.3s\tremaining: 3.04s\n",
      "1760:\tlearn: 0.0011575\ttotal: 22.3s\tremaining: 3.02s\n",
      "1761:\tlearn: 0.0011564\ttotal: 22.3s\tremaining: 3.01s\n",
      "1762:\tlearn: 0.0011554\ttotal: 22.3s\tremaining: 3s\n",
      "1763:\tlearn: 0.0011549\ttotal: 22.3s\tremaining: 2.99s\n",
      "1764:\tlearn: 0.0011548\ttotal: 22.3s\tremaining: 2.97s\n",
      "1765:\tlearn: 0.0011545\ttotal: 22.3s\tremaining: 2.96s\n",
      "1766:\tlearn: 0.0011525\ttotal: 22.4s\tremaining: 2.95s\n",
      "1767:\tlearn: 0.0011520\ttotal: 22.4s\tremaining: 2.94s\n",
      "1768:\tlearn: 0.0011513\ttotal: 22.4s\tremaining: 2.92s\n",
      "1769:\tlearn: 0.0011504\ttotal: 22.4s\tremaining: 2.91s\n",
      "1770:\tlearn: 0.0011487\ttotal: 22.4s\tremaining: 2.9s\n",
      "1771:\tlearn: 0.0011481\ttotal: 22.4s\tremaining: 2.88s\n",
      "1772:\tlearn: 0.0011474\ttotal: 22.4s\tremaining: 2.87s\n",
      "1773:\tlearn: 0.0011467\ttotal: 22.4s\tremaining: 2.86s\n",
      "1774:\tlearn: 0.0011459\ttotal: 22.4s\tremaining: 2.85s\n",
      "1775:\tlearn: 0.0011453\ttotal: 22.5s\tremaining: 2.83s\n",
      "1776:\tlearn: 0.0011447\ttotal: 22.5s\tremaining: 2.82s\n",
      "1777:\tlearn: 0.0011440\ttotal: 22.5s\tremaining: 2.81s\n",
      "1778:\tlearn: 0.0011437\ttotal: 22.5s\tremaining: 2.79s\n",
      "1779:\tlearn: 0.0011432\ttotal: 22.5s\tremaining: 2.78s\n",
      "1780:\tlearn: 0.0011429\ttotal: 22.5s\tremaining: 2.77s\n",
      "1781:\tlearn: 0.0011421\ttotal: 22.5s\tremaining: 2.75s\n",
      "1782:\tlearn: 0.0011410\ttotal: 22.5s\tremaining: 2.74s\n",
      "1783:\tlearn: 0.0011401\ttotal: 22.6s\tremaining: 2.73s\n",
      "1784:\tlearn: 0.0011391\ttotal: 22.6s\tremaining: 2.72s\n",
      "1785:\tlearn: 0.0011385\ttotal: 22.6s\tremaining: 2.71s\n",
      "1786:\tlearn: 0.0011373\ttotal: 22.6s\tremaining: 2.69s\n",
      "1787:\tlearn: 0.0011366\ttotal: 22.6s\tremaining: 2.68s\n",
      "1788:\tlearn: 0.0011345\ttotal: 22.6s\tremaining: 2.67s\n",
      "1789:\tlearn: 0.0011344\ttotal: 22.6s\tremaining: 2.65s\n",
      "1790:\tlearn: 0.0011342\ttotal: 22.6s\tremaining: 2.64s\n",
      "1791:\tlearn: 0.0011333\ttotal: 22.6s\tremaining: 2.63s\n",
      "1792:\tlearn: 0.0011326\ttotal: 22.7s\tremaining: 2.62s\n",
      "1793:\tlearn: 0.0011264\ttotal: 22.7s\tremaining: 2.6s\n",
      "1794:\tlearn: 0.0011262\ttotal: 22.7s\tremaining: 2.59s\n",
      "1795:\tlearn: 0.0011258\ttotal: 22.7s\tremaining: 2.58s\n",
      "1796:\tlearn: 0.0011253\ttotal: 22.7s\tremaining: 2.56s\n",
      "1797:\tlearn: 0.0011251\ttotal: 22.7s\tremaining: 2.55s\n",
      "1798:\tlearn: 0.0011243\ttotal: 22.7s\tremaining: 2.54s\n",
      "1799:\tlearn: 0.0011240\ttotal: 22.7s\tremaining: 2.53s\n",
      "1800:\tlearn: 0.0011239\ttotal: 22.7s\tremaining: 2.51s\n",
      "1801:\tlearn: 0.0011234\ttotal: 22.8s\tremaining: 2.5s\n",
      "1802:\tlearn: 0.0011226\ttotal: 22.8s\tremaining: 2.49s\n",
      "1803:\tlearn: 0.0011224\ttotal: 22.8s\tremaining: 2.47s\n",
      "1804:\tlearn: 0.0011222\ttotal: 22.8s\tremaining: 2.46s\n",
      "1805:\tlearn: 0.0011217\ttotal: 22.8s\tremaining: 2.45s\n",
      "1806:\tlearn: 0.0011215\ttotal: 22.8s\tremaining: 2.44s\n",
      "1807:\tlearn: 0.0011211\ttotal: 22.8s\tremaining: 2.42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808:\tlearn: 0.0011196\ttotal: 22.8s\tremaining: 2.41s\n",
      "1809:\tlearn: 0.0011188\ttotal: 22.8s\tremaining: 2.4s\n",
      "1810:\tlearn: 0.0011170\ttotal: 22.8s\tremaining: 2.38s\n",
      "1811:\tlearn: 0.0011160\ttotal: 22.9s\tremaining: 2.37s\n",
      "1812:\tlearn: 0.0011159\ttotal: 22.9s\tremaining: 2.36s\n",
      "1813:\tlearn: 0.0011128\ttotal: 22.9s\tremaining: 2.35s\n",
      "1814:\tlearn: 0.0011119\ttotal: 22.9s\tremaining: 2.33s\n",
      "1815:\tlearn: 0.0011115\ttotal: 22.9s\tremaining: 2.32s\n",
      "1816:\tlearn: 0.0011106\ttotal: 22.9s\tremaining: 2.31s\n",
      "1817:\tlearn: 0.0011101\ttotal: 22.9s\tremaining: 2.29s\n",
      "1818:\tlearn: 0.0011098\ttotal: 22.9s\tremaining: 2.28s\n",
      "1819:\tlearn: 0.0011084\ttotal: 22.9s\tremaining: 2.27s\n",
      "1820:\tlearn: 0.0011082\ttotal: 23s\tremaining: 2.26s\n",
      "1821:\tlearn: 0.0011071\ttotal: 23s\tremaining: 2.24s\n",
      "1822:\tlearn: 0.0011068\ttotal: 23s\tremaining: 2.23s\n",
      "1823:\tlearn: 0.0011043\ttotal: 23s\tremaining: 2.22s\n",
      "1824:\tlearn: 0.0011039\ttotal: 23s\tremaining: 2.2s\n",
      "1825:\tlearn: 0.0011034\ttotal: 23s\tremaining: 2.19s\n",
      "1826:\tlearn: 0.0011028\ttotal: 23s\tremaining: 2.18s\n",
      "1827:\tlearn: 0.0011019\ttotal: 23s\tremaining: 2.17s\n",
      "1828:\tlearn: 0.0011013\ttotal: 23s\tremaining: 2.15s\n",
      "1829:\tlearn: 0.0011011\ttotal: 23s\tremaining: 2.14s\n",
      "1830:\tlearn: 0.0011010\ttotal: 23.1s\tremaining: 2.13s\n",
      "1831:\tlearn: 0.0010991\ttotal: 23.1s\tremaining: 2.12s\n",
      "1832:\tlearn: 0.0010989\ttotal: 23.1s\tremaining: 2.1s\n",
      "1833:\tlearn: 0.0010975\ttotal: 23.1s\tremaining: 2.09s\n",
      "1834:\tlearn: 0.0010968\ttotal: 23.1s\tremaining: 2.08s\n",
      "1835:\tlearn: 0.0010964\ttotal: 23.1s\tremaining: 2.06s\n",
      "1836:\tlearn: 0.0010940\ttotal: 23.1s\tremaining: 2.05s\n",
      "1837:\tlearn: 0.0010935\ttotal: 23.1s\tremaining: 2.04s\n",
      "1838:\tlearn: 0.0010932\ttotal: 23.1s\tremaining: 2.02s\n",
      "1839:\tlearn: 0.0010931\ttotal: 23.1s\tremaining: 2.01s\n",
      "1840:\tlearn: 0.0010899\ttotal: 23.2s\tremaining: 2s\n",
      "1841:\tlearn: 0.0010895\ttotal: 23.2s\tremaining: 1.99s\n",
      "1842:\tlearn: 0.0010891\ttotal: 23.2s\tremaining: 1.97s\n",
      "1843:\tlearn: 0.0010878\ttotal: 23.2s\tremaining: 1.96s\n",
      "1844:\tlearn: 0.0010875\ttotal: 23.2s\tremaining: 1.95s\n",
      "1845:\tlearn: 0.0010871\ttotal: 23.2s\tremaining: 1.94s\n",
      "1846:\tlearn: 0.0010860\ttotal: 23.2s\tremaining: 1.92s\n",
      "1847:\tlearn: 0.0010859\ttotal: 23.2s\tremaining: 1.91s\n",
      "1848:\tlearn: 0.0010854\ttotal: 23.2s\tremaining: 1.9s\n",
      "1849:\tlearn: 0.0010847\ttotal: 23.3s\tremaining: 1.89s\n",
      "1850:\tlearn: 0.0010842\ttotal: 23.3s\tremaining: 1.87s\n",
      "1851:\tlearn: 0.0010824\ttotal: 23.3s\tremaining: 1.86s\n",
      "1852:\tlearn: 0.0010816\ttotal: 23.3s\tremaining: 1.85s\n",
      "1853:\tlearn: 0.0010765\ttotal: 23.3s\tremaining: 1.83s\n",
      "1854:\tlearn: 0.0010753\ttotal: 23.3s\tremaining: 1.82s\n",
      "1855:\tlearn: 0.0010749\ttotal: 23.3s\tremaining: 1.81s\n",
      "1856:\tlearn: 0.0010732\ttotal: 23.3s\tremaining: 1.79s\n",
      "1857:\tlearn: 0.0010723\ttotal: 23.3s\tremaining: 1.78s\n",
      "1858:\tlearn: 0.0010720\ttotal: 23.3s\tremaining: 1.77s\n",
      "1859:\tlearn: 0.0010715\ttotal: 23.4s\tremaining: 1.76s\n",
      "1860:\tlearn: 0.0010711\ttotal: 23.4s\tremaining: 1.74s\n",
      "1861:\tlearn: 0.0010707\ttotal: 23.4s\tremaining: 1.73s\n",
      "1862:\tlearn: 0.0010703\ttotal: 23.4s\tremaining: 1.72s\n",
      "1863:\tlearn: 0.0010698\ttotal: 23.4s\tremaining: 1.71s\n",
      "1864:\tlearn: 0.0010697\ttotal: 23.4s\tremaining: 1.69s\n",
      "1865:\tlearn: 0.0010686\ttotal: 23.4s\tremaining: 1.68s\n",
      "1866:\tlearn: 0.0010682\ttotal: 23.4s\tremaining: 1.67s\n",
      "1867:\tlearn: 0.0010654\ttotal: 23.4s\tremaining: 1.66s\n",
      "1868:\tlearn: 0.0010642\ttotal: 23.4s\tremaining: 1.64s\n",
      "1869:\tlearn: 0.0010639\ttotal: 23.5s\tremaining: 1.63s\n",
      "1870:\tlearn: 0.0010629\ttotal: 23.5s\tremaining: 1.62s\n",
      "1871:\tlearn: 0.0010623\ttotal: 23.5s\tremaining: 1.6s\n",
      "1872:\tlearn: 0.0010619\ttotal: 23.5s\tremaining: 1.59s\n",
      "1873:\tlearn: 0.0010617\ttotal: 23.5s\tremaining: 1.58s\n",
      "1874:\tlearn: 0.0010610\ttotal: 23.5s\tremaining: 1.57s\n",
      "1875:\tlearn: 0.0010604\ttotal: 23.5s\tremaining: 1.55s\n",
      "1876:\tlearn: 0.0010587\ttotal: 23.5s\tremaining: 1.54s\n",
      "1877:\tlearn: 0.0010584\ttotal: 23.5s\tremaining: 1.53s\n",
      "1878:\tlearn: 0.0010561\ttotal: 23.6s\tremaining: 1.52s\n",
      "1879:\tlearn: 0.0010558\ttotal: 23.6s\tremaining: 1.5s\n",
      "1880:\tlearn: 0.0010557\ttotal: 23.6s\tremaining: 1.49s\n",
      "1881:\tlearn: 0.0010535\ttotal: 23.6s\tremaining: 1.48s\n",
      "1882:\tlearn: 0.0010533\ttotal: 23.6s\tremaining: 1.47s\n",
      "1883:\tlearn: 0.0010530\ttotal: 23.6s\tremaining: 1.45s\n",
      "1884:\tlearn: 0.0010528\ttotal: 23.6s\tremaining: 1.44s\n",
      "1885:\tlearn: 0.0010526\ttotal: 23.6s\tremaining: 1.43s\n",
      "1886:\tlearn: 0.0010521\ttotal: 23.6s\tremaining: 1.42s\n",
      "1887:\tlearn: 0.0010499\ttotal: 23.6s\tremaining: 1.4s\n",
      "1888:\tlearn: 0.0010495\ttotal: 23.7s\tremaining: 1.39s\n",
      "1889:\tlearn: 0.0010492\ttotal: 23.7s\tremaining: 1.38s\n",
      "1890:\tlearn: 0.0010487\ttotal: 23.7s\tremaining: 1.36s\n",
      "1891:\tlearn: 0.0010478\ttotal: 23.7s\tremaining: 1.35s\n",
      "1892:\tlearn: 0.0010473\ttotal: 23.7s\tremaining: 1.34s\n",
      "1893:\tlearn: 0.0010462\ttotal: 23.7s\tremaining: 1.33s\n",
      "1894:\tlearn: 0.0010450\ttotal: 23.7s\tremaining: 1.31s\n",
      "1895:\tlearn: 0.0010448\ttotal: 23.7s\tremaining: 1.3s\n",
      "1896:\tlearn: 0.0010440\ttotal: 23.7s\tremaining: 1.29s\n",
      "1897:\tlearn: 0.0010437\ttotal: 23.7s\tremaining: 1.28s\n",
      "1898:\tlearn: 0.0010435\ttotal: 23.8s\tremaining: 1.26s\n",
      "1899:\tlearn: 0.0010428\ttotal: 23.8s\tremaining: 1.25s\n",
      "1900:\tlearn: 0.0010420\ttotal: 23.8s\tremaining: 1.24s\n",
      "1901:\tlearn: 0.0010417\ttotal: 23.8s\tremaining: 1.23s\n",
      "1902:\tlearn: 0.0010402\ttotal: 23.8s\tremaining: 1.21s\n",
      "1903:\tlearn: 0.0010376\ttotal: 23.8s\tremaining: 1.2s\n",
      "1904:\tlearn: 0.0010371\ttotal: 23.8s\tremaining: 1.19s\n",
      "1905:\tlearn: 0.0010366\ttotal: 23.8s\tremaining: 1.18s\n",
      "1906:\tlearn: 0.0010358\ttotal: 23.8s\tremaining: 1.16s\n",
      "1907:\tlearn: 0.0010351\ttotal: 23.8s\tremaining: 1.15s\n",
      "1908:\tlearn: 0.0010346\ttotal: 23.9s\tremaining: 1.14s\n",
      "1909:\tlearn: 0.0010345\ttotal: 23.9s\tremaining: 1.12s\n",
      "1910:\tlearn: 0.0010338\ttotal: 23.9s\tremaining: 1.11s\n",
      "1911:\tlearn: 0.0010321\ttotal: 23.9s\tremaining: 1.1s\n",
      "1912:\tlearn: 0.0010315\ttotal: 23.9s\tremaining: 1.09s\n",
      "1913:\tlearn: 0.0010305\ttotal: 23.9s\tremaining: 1.07s\n",
      "1914:\tlearn: 0.0010291\ttotal: 23.9s\tremaining: 1.06s\n",
      "1915:\tlearn: 0.0010285\ttotal: 23.9s\tremaining: 1.05s\n",
      "1916:\tlearn: 0.0010279\ttotal: 23.9s\tremaining: 1.04s\n",
      "1917:\tlearn: 0.0010261\ttotal: 24s\tremaining: 1.02s\n",
      "1918:\tlearn: 0.0010259\ttotal: 24s\tremaining: 1.01s\n",
      "1919:\tlearn: 0.0010255\ttotal: 24s\tremaining: 999ms\n",
      "1920:\tlearn: 0.0010253\ttotal: 24s\tremaining: 987ms\n",
      "1921:\tlearn: 0.0010244\ttotal: 24s\tremaining: 974ms\n",
      "1922:\tlearn: 0.0010239\ttotal: 24s\tremaining: 962ms\n",
      "1923:\tlearn: 0.0010231\ttotal: 24s\tremaining: 949ms\n",
      "1924:\tlearn: 0.0010229\ttotal: 24s\tremaining: 936ms\n",
      "1925:\tlearn: 0.0010228\ttotal: 24s\tremaining: 924ms\n",
      "1926:\tlearn: 0.0010224\ttotal: 24.1s\tremaining: 911ms\n",
      "1927:\tlearn: 0.0010218\ttotal: 24.1s\tremaining: 899ms\n",
      "1928:\tlearn: 0.0010185\ttotal: 24.1s\tremaining: 886ms\n",
      "1929:\tlearn: 0.0010180\ttotal: 24.1s\tremaining: 874ms\n",
      "1930:\tlearn: 0.0010176\ttotal: 24.1s\tremaining: 861ms\n",
      "1931:\tlearn: 0.0010175\ttotal: 24.1s\tremaining: 849ms\n",
      "1932:\tlearn: 0.0010165\ttotal: 24.1s\tremaining: 836ms\n",
      "1933:\tlearn: 0.0010159\ttotal: 24.1s\tremaining: 824ms\n",
      "1934:\tlearn: 0.0010158\ttotal: 24.1s\tremaining: 811ms\n",
      "1935:\tlearn: 0.0010146\ttotal: 24.2s\tremaining: 799ms\n",
      "1936:\tlearn: 0.0010146\ttotal: 24.2s\tremaining: 786ms\n",
      "1937:\tlearn: 0.0010129\ttotal: 24.2s\tremaining: 773ms\n",
      "1938:\tlearn: 0.0010126\ttotal: 24.2s\tremaining: 761ms\n",
      "1939:\tlearn: 0.0010125\ttotal: 24.2s\tremaining: 748ms\n",
      "1940:\tlearn: 0.0010119\ttotal: 24.2s\tremaining: 736ms\n",
      "1941:\tlearn: 0.0010118\ttotal: 24.2s\tremaining: 723ms\n",
      "1942:\tlearn: 0.0010113\ttotal: 24.2s\tremaining: 711ms\n",
      "1943:\tlearn: 0.0010109\ttotal: 24.2s\tremaining: 698ms\n",
      "1944:\tlearn: 0.0010099\ttotal: 24.2s\tremaining: 686ms\n",
      "1945:\tlearn: 0.0010094\ttotal: 24.3s\tremaining: 673ms\n",
      "1946:\tlearn: 0.0010074\ttotal: 24.3s\tremaining: 661ms\n",
      "1947:\tlearn: 0.0010073\ttotal: 24.3s\tremaining: 648ms\n",
      "1948:\tlearn: 0.0010068\ttotal: 24.3s\tremaining: 636ms\n",
      "1949:\tlearn: 0.0010060\ttotal: 24.3s\tremaining: 623ms\n",
      "1950:\tlearn: 0.0010058\ttotal: 24.3s\tremaining: 611ms\n",
      "1951:\tlearn: 0.0010056\ttotal: 24.3s\tremaining: 598ms\n",
      "1952:\tlearn: 0.0010043\ttotal: 24.3s\tremaining: 586ms\n",
      "1953:\tlearn: 0.0010037\ttotal: 24.3s\tremaining: 573ms\n",
      "1954:\tlearn: 0.0010034\ttotal: 24.4s\tremaining: 561ms\n",
      "1955:\tlearn: 0.0010029\ttotal: 24.4s\tremaining: 548ms\n",
      "1956:\tlearn: 0.0010025\ttotal: 24.4s\tremaining: 535ms\n",
      "1957:\tlearn: 0.0010022\ttotal: 24.4s\tremaining: 523ms\n",
      "1958:\tlearn: 0.0010016\ttotal: 24.4s\tremaining: 510ms\n",
      "1959:\tlearn: 0.0010011\ttotal: 24.4s\tremaining: 498ms\n",
      "1960:\tlearn: 0.0010004\ttotal: 24.4s\tremaining: 485ms\n",
      "1961:\tlearn: 0.0009985\ttotal: 24.4s\tremaining: 473ms\n",
      "1962:\tlearn: 0.0009983\ttotal: 24.4s\tremaining: 460ms\n",
      "1963:\tlearn: 0.0009982\ttotal: 24.4s\tremaining: 448ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964:\tlearn: 0.0009979\ttotal: 24.5s\tremaining: 436ms\n",
      "1965:\tlearn: 0.0009972\ttotal: 24.5s\tremaining: 423ms\n",
      "1966:\tlearn: 0.0009963\ttotal: 24.5s\tremaining: 411ms\n",
      "1967:\tlearn: 0.0009956\ttotal: 24.5s\tremaining: 398ms\n",
      "1968:\tlearn: 0.0009953\ttotal: 24.5s\tremaining: 386ms\n",
      "1969:\tlearn: 0.0009949\ttotal: 24.5s\tremaining: 373ms\n",
      "1970:\tlearn: 0.0009947\ttotal: 24.5s\tremaining: 361ms\n",
      "1971:\tlearn: 0.0009937\ttotal: 24.5s\tremaining: 348ms\n",
      "1972:\tlearn: 0.0009934\ttotal: 24.5s\tremaining: 336ms\n",
      "1973:\tlearn: 0.0009933\ttotal: 24.6s\tremaining: 323ms\n",
      "1974:\tlearn: 0.0009922\ttotal: 24.6s\tremaining: 311ms\n",
      "1975:\tlearn: 0.0009921\ttotal: 24.6s\tremaining: 299ms\n",
      "1976:\tlearn: 0.0009903\ttotal: 24.6s\tremaining: 286ms\n",
      "1977:\tlearn: 0.0009886\ttotal: 24.6s\tremaining: 274ms\n",
      "1978:\tlearn: 0.0009884\ttotal: 24.6s\tremaining: 261ms\n",
      "1979:\tlearn: 0.0009880\ttotal: 24.6s\tremaining: 249ms\n",
      "1980:\tlearn: 0.0009876\ttotal: 24.6s\tremaining: 236ms\n",
      "1981:\tlearn: 0.0009874\ttotal: 24.6s\tremaining: 224ms\n",
      "1982:\tlearn: 0.0009866\ttotal: 24.7s\tremaining: 211ms\n",
      "1983:\tlearn: 0.0009857\ttotal: 24.7s\tremaining: 199ms\n",
      "1984:\tlearn: 0.0009845\ttotal: 24.7s\tremaining: 186ms\n",
      "1985:\tlearn: 0.0009837\ttotal: 24.7s\tremaining: 174ms\n",
      "1986:\tlearn: 0.0009833\ttotal: 24.7s\tremaining: 162ms\n",
      "1987:\tlearn: 0.0009828\ttotal: 24.7s\tremaining: 149ms\n",
      "1988:\tlearn: 0.0009825\ttotal: 24.7s\tremaining: 137ms\n",
      "1989:\tlearn: 0.0009817\ttotal: 24.7s\tremaining: 124ms\n",
      "1990:\tlearn: 0.0009809\ttotal: 24.7s\tremaining: 112ms\n",
      "1991:\tlearn: 0.0009802\ttotal: 24.7s\tremaining: 99.4ms\n",
      "1992:\tlearn: 0.0009798\ttotal: 24.8s\tremaining: 87ms\n",
      "1993:\tlearn: 0.0009782\ttotal: 24.8s\tremaining: 74.5ms\n",
      "1994:\tlearn: 0.0009780\ttotal: 24.8s\tremaining: 62.1ms\n",
      "1995:\tlearn: 0.0009777\ttotal: 24.8s\tremaining: 49.7ms\n",
      "1996:\tlearn: 0.0009775\ttotal: 24.8s\tremaining: 37.3ms\n",
      "1997:\tlearn: 0.0009772\ttotal: 24.8s\tremaining: 24.8ms\n",
      "1998:\tlearn: 0.0009765\ttotal: 24.8s\tremaining: 12.4ms\n",
      "1999:\tlearn: 0.0009761\ttotal: 24.8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9228367831693248"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "clf_cat = CatBoostClassifier(iterations=2000,\n",
    "                           random_state=42,\n",
    "                           learning_rate=0.5,\n",
    "                           depth=3,\n",
    "                           loss_function='MultiClass')\n",
    "clf_cat.fit(X_train_sc, y_train_)\n",
    "pred_cat = clf_cat.predict(X_test_sc)\n",
    "multiclass_roc_auc_score(y_test_, pred_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5406a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
